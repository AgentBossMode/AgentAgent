{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code stub\n",
    "json_dict = \"\"\"{\n",
    "  \"nodes\": {\n",
    "    \"__START__\": {\n",
    "      \"schema_info\": \"None\",\n",
    "      \"input_schema\": \"None\",\n",
    "      \"output_schema\": \"None\",\n",
    "      \"description\": \"The starting point of the graph.\",\n",
    "      \"function_name\": \"start_node\"\n",
    "    },\n",
    "    \"supervisor\": {\n",
    "      \"schema_info\": \"Router: TypedDict with next as a string literal of options.\",\n",
    "      \"input_schema\": \"State\",\n",
    "      \"output_schema\": \"State\",\n",
    "      \"description\": \"This node manages the conversation between workers and decides which worker to route to next.\",\n",
    "      \"function_name\": \"supervisor_node\"\n",
    "    },\n",
    "    \"food_logger\": {\n",
    "      \"schema_info\": \"State: TypedDict with messages as a list of messages.\",\n",
    "      \"input_schema\": \"State\",\n",
    "      \"output_schema\": \"State\",\n",
    "      \"description\": \"This node logs food intake and calculates calories.\",\n",
    "      \"function_name\": \"food_logger_node\"\n",
    "    },\n",
    "    \"workout_tracker\": {\n",
    "      \"schema_info\": \"State: TypedDict with messages as a list of messages.\",\n",
    "      \"input_schema\": \"State\",\n",
    "      \"output_schema\": \"State\",\n",
    "      \"description\": \"This node logs workout details and calculates calories burnt.\",\n",
    "      \"function_name\": \"workout_tracker_node\"\n",
    "    },\n",
    "    \"__END__\": {\n",
    "      \"schema_info\": \"None\",\n",
    "      \"input_schema\": \"None\",\n",
    "      \"output_schema\": \"None\",\n",
    "      \"description\": \"The endpoint of the graph, indicating completion.\",\n",
    "      \"function_name\": \"end_node\"\n",
    "    }\n",
    "  },\n",
    "  \"edges\": {\n",
    "    { \n",
    "      \"source\": \"__START__\", \n",
    "      \"target\": \"supervisor\", \n",
    "      \"routing_conditions\": \"Start the process by routing to the supervisor node.\", \n",
    "      \"conditional\": False \n",
    "    },\n",
    "    { \n",
    "      \"source\": \"supervisor\", \n",
    "      \"target\": \"food_logger\", \n",
    "      \"routing_conditions\": \"If the supervisor decides to route to food_logger based on user input.\", \n",
    "      \"conditional\": True \n",
    "    },\n",
    "    { \n",
    "      \"source\": \"supervisor\", \n",
    "      \"target\": \"workout_tracker\", \n",
    "      \"routing_conditions\": \"If the supervisor decides to route to workout_tracker based on user input.\", \n",
    "      \"conditional\": True \n",
    "    },\n",
    "    { \n",
    "      \"source\": \"supervisor\", \n",
    "      \"target\": \"__END__\", \n",
    "      \"routing_conditions\": \"If the supervisor decides to finish the process.\", \n",
    "      \"conditional\": True\n",
    "    },\n",
    "    { \n",
    "      \"source\": \"food_logger\", \n",
    "      \"target\": \"supervisor\", \n",
    "      \"routing_conditions\": \"After logging food intake, return control to the supervisor.\", \n",
    "      \"conditional\": False \n",
    "    },\n",
    "    { \n",
    "      \"source\": \"workout_tracker\", \n",
    "      \"target\": \"supervisor\", \n",
    "      \"routing_conditions\": \"After logging workout details, return control to the supervisor.\", \n",
    "      \"conditional\": False \n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "code = \"\"\" \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create specialized agents\n",
    "\n",
    "@tool\n",
    "def food_logger_tool(food: str) -> str:\n",
    "    \\\"\\\"\\\"Log food intake in the database\\\"\\\"\\\"\n",
    "    # Parse food input and get nutrition data from Nutritionix API\n",
    "    import requests\n",
    "    import json\n",
    "    from pymongo import MongoClient\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Nutritionix API credentials should be in environment variables\n",
    "    headers = {\n",
    "        \"x-app-id\": os.getenv(\"NUTRITIONIX_APP_ID\"),\n",
    "        \"x-app-key\": os.getenv(\"NUTRITIONIX_API_KEY\"),\n",
    "        \"x-remote-user-id\": \"0\"  # 0 for development\n",
    "    }\n",
    "\n",
    "    # Query Nutritionix API\n",
    "    endpoint = \"https://trackapi.nutritionix.com/v2/natural/nutrients\"\n",
    "    payload = {\"query\": food}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(endpoint, headers=headers, json=payload)\n",
    "        nutrition_data = response.json()\n",
    "\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "        db = client.nutrition_db\n",
    "        food_logs = db.food_logs\n",
    "\n",
    "        # Prepare document for MongoDB\n",
    "        food_entry = {\n",
    "            \"food_name\": food,\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"nutrition_data\": nutrition_data[\"foods\"][0],\n",
    "            \"calories\": nutrition_data[\"foods\"][0][\"nf_calories\"],\n",
    "            \"protein\": nutrition_data[\"foods\"][0][\"nf_protein\"],\n",
    "            \"carbohydrates\": nutrition_data[\"foods\"][0][\"nf_total_carbohydrate\"],\n",
    "            \"fat\": nutrition_data[\"foods\"][0][\"nf_total_fat\"]\n",
    "        }\n",
    "\n",
    "        # Insert into MongoDB\n",
    "        food_logs.insert_one(food_entry)\n",
    "        client.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error logging food: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def workout_tracker_tool(workout: str) -> str:\n",
    "    \\\"\\\"\\\"Log workout details in the database\\\"\\\"\\\"\n",
    "    # Parse workout input and get workout details from Google Fit API\n",
    "    import requests\n",
    "    import json\n",
    "    from pymongo import MongoClient\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Google Fit API credentials should be in environment variables\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('GOOGLE_FIT_TOKEN')}\"\n",
    "    }\n",
    "\n",
    "    # Query Google Fit API\n",
    "    endpoint = \"https://www.googleapis.com/fitness/v1/users/me/dataset:aggregate\"\n",
    "    \n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "        db = client.fitness_db\n",
    "        workout_logs = db.workout_logs\n",
    "\n",
    "        # Prepare document for MongoDB\n",
    "        workout_entry = {\n",
    "            \"workout_type\": workout,\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"duration_minutes\": 30,  # This would come from Google Fit API\n",
    "            \"calories_burned\": 250,  # This would come from Google Fit API\n",
    "            \"heart_rate_avg\": 140,   # This would come from Google Fit API\n",
    "            \"steps\": 4000            # This would come from Google Fit API\n",
    "        }\n",
    "\n",
    "        # Insert into MongoDB\n",
    "        workout_logs.insert_one(workout_entry)\n",
    "        client.close()\n",
    "        \n",
    "        return f\"Successfully logged workout: {workout}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error logging workout: {str(e)}\"\n",
    "\n",
    "food_logger_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[food_logger_tool],\n",
    "    name=\"food_logger\",\n",
    "    prompt=\"user will tell you what they ate and you will log it in the database\"\n",
    ")\n",
    "\n",
    "workout_tracker_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[workout_tracker_tool],\n",
    "    name=\"workout_tracker\",\n",
    "    prompt=\"user will tell you what they did and you will log it in the database\"\n",
    ")\n",
    "\n",
    "# Create supervisor workflow\n",
    "workflow = create_supervisor(\n",
    "    [food_logger_agent, workout_tracker_agent],\n",
    "    model=model,\n",
    "    prompt=(\n",
    "        \"You are a team supervisor managing a research expert and a math expert. \"\n",
    "        \"For tracking calories, use food_logger \"\n",
    "        \"For tracking workout, use workout_tracker\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compile and run\n",
    "app = workflow.compile()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Log Food Intake and Finish\",\n",
      "    \"description\": \"User logs their food intake and then finishes the process.\",\n",
      "    \"dry_run\": [\n",
      "      {\"node\": \"__START__\", \"action\": \"Start the process by routing to the supervisor node.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User chooses to log food intake, route to food_logger.\"},\n",
      "      {\"node\": \"food_logger\", \"action\": \"Log food intake and calculate calories.\"},\n",
      "      {\"node\": \"food_logger\", \"action\": \"Return control to supervisor.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User decides to finish the process, route to __END__.\"},\n",
      "      {\"node\": \"__END__\", \"action\": \"End the process.\"}\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Log Workout and Finish\",\n",
      "    \"description\": \"User logs their workout details and then finishes the process.\",\n",
      "    \"dry_run\": [\n",
      "      {\"node\": \"__START__\", \"action\": \"Start the process by routing to the supervisor node.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User chooses to log workout details, route to workout_tracker.\"},\n",
      "      {\"node\": \"workout_tracker\", \"action\": \"Log workout details and calculate calories burnt.\"},\n",
      "      {\"node\": \"workout_tracker\", \"action\": \"Return control to supervisor.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User decides to finish the process, route to __END__.\"},\n",
      "      {\"node\": \"__END__\", \"action\": \"End the process.\"}\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Log Food, Log Workout, Then Finish\",\n",
      "    \"description\": \"User logs food intake, then logs workout details, and finally finishes the process.\",\n",
      "    \"dry_run\": [\n",
      "      {\"node\": \"__START__\", \"action\": \"Start the process by routing to the supervisor node.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User chooses to log food intake, route to food_logger.\"},\n",
      "      {\"node\": \"food_logger\", \"action\": \"Log food intake and calculate calories.\"},\n",
      "      {\"node\": \"food_logger\", \"action\": \"Return control to supervisor.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User chooses to log workout details, route to workout_tracker.\"},\n",
      "      {\"node\": \"workout_tracker\", \"action\": \"Log workout details and calculate calories burnt.\"},\n",
      "      {\"node\": \"workout_tracker\", \"action\": \"Return control to supervisor.\"},\n",
      "      {\"node\": \"supervisor\", \"action\": \"User decides to finish the process, route to __END__.\"},\n",
      "      {\"node\": \"__END__\", \"action\": \"End the process.\"}\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# generate use cases\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "SYS_PROMPT= ChatPromptTemplate.from_template(\"\"\"\n",
    "You are given the json of a workflow graph below.\n",
    "{json_dict}\n",
    "You are supposed to write use cases for the graph.\n",
    "You will also do dry run of the graph with the use cases.\n",
    "The use cases should be in the format of a list of dictionaries.\n",
    "Each dictionary should have the following\n",
    "keys:\n",
    "- name: The name of the use case\n",
    "- description: The description of the use case\n",
    "- dry_run: The dry run of the use case\n",
    "\"\"\")\n",
    "\n",
    "from model_factory import get_model\n",
    "llm = get_model()\n",
    "use_cases = llm.invoke([SystemMessage(content=SYS_PROMPT.format(json_dict=json_dict))])\n",
    "use_cases.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " \n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph_supervisor import create_supervisor\n",
      "from langgraph.prebuilt import create_react_agent\n",
      "from langchain_core.prompts import ChatPromptTemplate\n",
      "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
      "\n",
      "# Create specialized agents\n",
      "\n",
      "@tool\n",
      "def food_logger_tool(food: str) -> str:\n",
      "    \"\"\"Mock implementation of food_logger_tool\"\"\"\n",
      "    return f\"Mock log: Food '{food}' has been logged successfully.\"\n",
      "\n",
      "@tool\n",
      "def workout_tracker_tool(workout: str) -> str:\n",
      "    \"\"\"Mock implementation of workout_tracker_tool\"\"\"\n",
      "    return f\"Mock log: Workout '{workout}' has been logged successfully.\"\n",
      "\n",
      "food_logger_agent = create_react_agent(\n",
      "    model=model,\n",
      "    tools=[food_logger_tool],\n",
      "    name=\"food_logger\",\n",
      "    prompt=\"user will tell you what they ate and you will log it in the database\"\n",
      ")\n",
      "\n",
      "workout_tracker_agent = create_react_agent(\n",
      "    model=model,\n",
      "    tools=[workout_tracker_tool],\n",
      "    name=\"workout_tracker\",\n",
      "    prompt=\"user will tell you what they did and you will log it in the database\"\n",
      ")\n",
      "\n",
      "# Create supervisor workflow\n",
      "workflow = create_supervisor(\n",
      "    [food_logger_agent, workout_tracker_agent],\n",
      "    model=model,\n",
      "    prompt=(\n",
      "        \"You are a team supervisor managing a research expert and a math expert. \"\n",
      "        \"For tracking calories, use food_logger \"\n",
      "        \"For tracking workout, use workout_tracker\"\n",
      "    )\n",
      ")\n",
      "\n",
      "# Compile and run\n",
      "app = workflow.compile()\n"
     ]
    }
   ],
   "source": [
    "# mock generation\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "SYS_PROMPT = \"\"\"\n",
    "You are given a code, look for any methods with 'tool' decorator and modify them to have mock implementation.\n",
    "\n",
    "Return the modified code in the same format as the input code.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mocked_code = llm.invoke([SystemMessage(content=SYS_PROMPT), HumanMessage(content=code)])\n",
    "mocked_code.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "\n",
    "def fetch_documents(url: str) -> str:\n",
    "    \"\"\"Fetch a document from a URL and return the markdownified text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The markdownified text of the document.\n",
    "    \"\"\"\n",
    "    httpx_client = httpx.Client(follow_redirects=True, timeout=10)\n",
    "\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "        img_tags = soup.find_all('img')\n",
    "        for img_tag in img_tags:\n",
    "            img_tag.decompose()\n",
    "\n",
    "        target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "        \n",
    "        if not target_div:\n",
    "            target_div = soup.find('article') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            target_div = soup.find('html') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            return html2text.html2text(str(soup))\n",
    "        \n",
    "        return html2text.html2text(str(target_div))\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph_supervisor import create_supervisor\n",
      "from langgraph.prebuilt import create_react_agent\n",
      "from langchain_core.prompts import ChatPromptTemplate\n",
      "from langchain_core.tools import tool\n",
      "import pytest\n",
      "from langsmith import testing as t\n",
      "from typing_extensions import Annotated, TypedDict\n",
      "from langchain.chat_models import init_chat_model\n",
      "from langgraph.checkpoint.memory import MemoryCheckpoint\n",
      "import asyncio\n",
      "\n",
      "# --- Original Code Block ---\n",
      "# Assume this code is in a file named app.py or similar\n",
      "# For testing purposes, we'll include it directly or ensure it's importable.\n",
      "\n",
      "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
      "\n",
      "@tool\n",
      "def food_logger_tool(food: str) -> str:\n",
      "    \"\"\"Mock implementation of food_logger_tool\"\"\"\n",
      "    return f\"Mock log: Food '{food}' has been logged successfully.\"\n",
      "\n",
      "@tool\n",
      "def workout_tracker_tool(workout: str) -> str:\n",
      "    \"\"\"Mock implementation of workout_tracker_tool\"\"\"\n",
      "    return f\"Mock log: Workout '{workout}' has been logged successfully.\"\n",
      "\n",
      "food_logger_agent = create_react_agent(\n",
      "    model=model,\n",
      "    tools=[food_logger_tool],\n",
      "    name=\"food_logger\",\n",
      "    prompt=\"user will tell you what they ate and you will log it in the database\"\n",
      ")\n",
      "\n",
      "workout_tracker_agent = create_react_agent(\n",
      "    model=model,\n",
      "    tools=[workout_tracker_tool],\n",
      "    name=\"workout_tracker\",\n",
      "    prompt=\"user will tell you what they did and you will log it in the database\"\n",
      ")\n",
      "\n",
      "workflow = create_supervisor(\n",
      "    [food_logger_agent, workout_tracker_agent],\n",
      "    model=model,\n",
      "    prompt=(\n",
      "        \"You are a team supervisor managing a research expert and a math expert. \"\n",
      "        \"For tracking calories, use food_logger \"\n",
      "        \"For tracking workout, use workout_tracker\"\n",
      "    )\n",
      ")\n",
      "\n",
      "app = workflow.compile()\n",
      "\n",
      "# --- End Original Code Block ---\n",
      "\n",
      "\n",
      "# --- Test Setup ---\n",
      "\n",
      "# LLM-as-a-judge setup for final response evaluation\n",
      "class GradeFinalResponse(TypedDict):\n",
      "    \"\"\"Evaluate if the final response confirms the action taken.\"\"\"\n",
      "    score: Annotated[\n",
      "        bool,\n",
      "        ...,\n",
      "        \"Return True if the final response confirms the action requested by the user (logging food/workout), otherwise False.\",\n",
      "    ]\n",
      "\n",
      "judge_llm_response = init_chat_model(\"gpt-4o-mini\").with_structured_output(GradeFinalResponse)\n",
      "\n",
      "# LLM-as-a-judge setup for supervisor routing evaluation (optional, direct check is easier)\n",
      "# We will use direct assertion for supervisor routing and agent tool calls as shown in docs.\n",
      "\n",
      "\n",
      "# --- Test Cases ---\n",
      "\n",
      "@pytest.mark.langsmith\n",
      "@pytest.mark.parametrize(\n",
      "    \"query, expected_trajectory\",\n",
      "    [\n",
      "        (\"I ate an apple\", [\"__START__\", \"supervisor\", \"food_logger\", \"food_logger\", \"supervisor\", \"__END__\"]),\n",
      "        (\"I did push-ups\", [\"__START__\", \"supervisor\", \"workout_tracker\", \"workout_tracker\", \"supervisor\", \"__END__\"]),\n",
      "        # Note: The multi-step case \"I ate a banana and then ran 5k\" is complex for simple trajectory assertion\n",
      "        # as it depends on the supervisor's multi-turn reasoning.\n",
      "        # Based on the dry run, it seems to handle it sequentially.\n",
      "        (\"I ate a banana and then ran 5k\", [\"__START__\", \"supervisor\", \"food_logger\", \"food_logger\", \"supervisor\", \"workout_tracker\", \"workout_tracker\", \"supervisor\", \"__END__\"]),\n",
      "        (\"I'm done\", [\"__START__\", \"supervisor\", \"__END__\"]), # Assuming supervisor can handle explicit end\n",
      "    ],\n",
      ")\n",
      "async def test_full_trajectory(query: str, expected_trajectory: list[str]) -> None:\n",
      "    \"\"\"Test the full node trajectory for different inputs.\"\"\"\n",
      "    t.log_inputs({\"query\": query})\n",
      "    t.log_reference_outputs({\"expected_trajectory\": expected_trajectory})\n",
      "\n",
      "    # Use a memory checkpoint to easily track the state history\n",
      "    config = {\"configurable\": {\"thread_id\": \"test_trajectory\"}}\n",
      "    app_with_checkpoint = workflow.compile(checkpointer=MemoryCheckpoint())\n",
      "\n",
      "    # Run the graph and collect node visits\n",
      "    visited_nodes = []\n",
      "    async for event in app_with_checkpoint.stream({\"messages\": [(\"user\", query)]}, config=config, stream_mode=\"messages\"):\n",
      "         for key in event.keys():\n",
      "             if key not in [\"messages\", \"__end__\"]: # Ignore state keys and final end\n",
      "                 visited_nodes.append(key)\n",
      "         if \"__end__\" in event:\n",
      "             visited_nodes.append(\"__END__\")\n",
      "\n",
      "\n",
      "    # Add the start node explicitly as stream doesn't show it\n",
      "    actual_trajectory = [\"__START__\"] + visited_nodes\n",
      "\n",
      "    t.log_outputs({\"actual_trajectory\": actual_trajectory})\n",
      "\n",
      "    # Assert the trajectory matches the expected one\n",
      "    assert actual_trajectory == expected_trajectory\n",
      "\n",
      "\n",
      "@pytest.mark.langsmith\n",
      "@pytest.mark.parametrize(\n",
      "    \"query, expected_action\",\n",
      "    [\n",
      "        (\"I ate an apple\", \"log food\"),\n",
      "        (\"I did push-ups\", \"log workout\"),\n",
      "        (\"I ate a banana and then ran 5k\", \"log food and log workout\"),\n",
      "        (\"Just saying hi\", \"respond politely without logging\"), # Test off-topic\n",
      "    ],\n",
      ")\n",
      "async def test_final_response_groundedness(query: str, expected_action: str) -> None:\n",
      "    \"\"\"Test if the final response confirms the action taken using LLM-as-a-judge.\"\"\"\n",
      "    t.log_inputs({\"query\": query})\n",
      "    t.log_reference_outputs({\"expected_action\": expected_action})\n",
      "\n",
      "    # Run the full graph\n",
      "    result = await app.invoke({\"messages\": [(\"user\", query)]})\n",
      "    final_message_content = result.get(\"messages\", [])[-1].content if result.get(\"messages\") else \"\"\n",
      "\n",
      "    t.log_outputs({\"final_response\": final_message_content})\n",
      "\n",
      "    # Use LLM-as-a-judge to grade the final response\n",
      "    with t.trace_feedback():\n",
      "        instructions = (\n",
      "            \"Grade the following ANSWER based on the USER QUERY and EXPECTED ACTION. \"\n",
      "            \"Return True if the ANSWER confirms that the EXPECTED ACTION was taken or acknowledges the query appropriately (e.g., for off-topic queries). \"\n",
      "            \"Return False otherwise.\"\n",
      "        )\n",
      "        answer_and_context = (\n",
      "            f\"USER QUERY: {query}\\n\"\n",
      "            f\"EXPECTED ACTION: {expected_action}\\n\"\n",
      "            f\"ANSWER: {final_message_content}\"\n",
      "        )\n",
      "\n",
      "        grade = await judge_llm_response.invoke(\n",
      "            [\n",
      "                {\"role\": \"system\", \"content\": instructions},\n",
      "                {\"role\": \"user\", \"content\": answer_and_context},\n",
      "            ]\n",
      "        )\n",
      "        t.log_feedback(key=\"final_response_confirms_action\", score=grade[\"score\"])\n",
      "\n",
      "    assert grade[\"score\"] is True\n",
      "\n",
      "\n",
      "@pytest.mark.langsmith\n",
      "@pytest.mark.parametrize(\n",
      "    \"query, expected_next_node\",\n",
      "    [\n",
      "        (\"I ate an apple\", \"food_logger\"),\n",
      "        (\"I did push-ups\", \"workout_tracker\"),\n",
      "        (\"I ate a banana and then ran 5k\", \"food_logger\"), # Supervisor routes to the first relevant agent\n",
      "        (\"What's the weather?\", \"supervisor\"), # Supervisor should handle non-logging queries or route back to itself\n",
      "        (\"I'm done\", \"__END__\"), # Explicit end request\n",
      "    ],\n",
      ")\n",
      "async def test_supervisor_routing(query: str, expected_next_node: str) -> None:\n",
      "    \"\"\"Test if the supervisor node routes correctly based on the input.\"\"\"\n",
      "    t.log_inputs({\"query\": query})\n",
      "    t.log_reference_outputs({\"expected_next_node\": expected_next_node})\n",
      "\n",
      "    # Invoke only the supervisor node\n",
      "    # The supervisor node expects the full state, including messages\n",
      "    # The output of the supervisor node is the name of the next node\n",
      "    result = await app.nodes[\"supervisor\"].invoke({\"messages\": [(\"user\", query)]})\n",
      "\n",
      "    # The supervisor node in create_supervisor returns the name of the next node directly\n",
      "    actual_next_node = result\n",
      "\n",
      "    t.log_outputs({\"actual_next_node\": actual_next_node})\n",
      "\n",
      "    # Check that the supervisor routed to the correct node\n",
      "    assert actual_next_node == expected_next_node\n",
      "\n",
      "\n",
      "@pytest.mark.langsmith\n",
      "@pytest.mark.parametrize(\n",
      "    \"agent_name, query, expected_tool\",\n",
      "    [\n",
      "        (\"food_logger\", \"log that I ate pizza\", food_logger_tool),\n",
      "        (\"food_logger\", \"I had a salad for lunch\", food_logger_tool),\n",
      "        (\"workout_tracker\", \"track my 30 minute run\", workout_tracker_tool),\n",
      "        (\"workout_tracker\", \"I lifted weights today\", workout_tracker_tool),\n",
      "    ],\n",
      ")\n",
      "async def test_agent_tool_calling(agent_name: str, query: str, expected_tool: tool) -> None:\n",
      "    \"\"\"Test if the individual agent nodes call their respective tools.\"\"\"\n",
      "    t.log_inputs({\"agent\": agent_name, \"query\": query})\n",
      "    t.log_reference_outputs({\"expected_tool_name\": expected_tool.name})\n",
      "\n",
      "    # Invoke only the specific agent node\n",
      "    # The agent node expects the full state, including messages\n",
      "    result = await app.nodes[agent_name].invoke({\"messages\": [(\"user\", query)]})\n",
      "\n",
      "    # Extract tool calls made by the agent's LLM\n",
      "    # The result from a ReAct agent node invocation contains the AIMessage with tool_calls\n",
      "    tool_calls = []\n",
      "    if result and result.get(\"messages\"):\n",
      "        last_message = result[\"messages\"][-1]\n",
      "        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
      "             tool_calls = last_message.tool_calls\n",
      "\n",
      "    actual_tool_names = [tc['name'] for tc in tool_calls]\n",
      "\n",
      "    t.log_outputs({\"actual_tool_calls\": actual_tool_names})\n",
      "\n",
      "    # Assert that the correct tool was called\n",
      "    assert expected_tool.name in actual_tool_names\n",
      "    # Optionally, check if only one tool was called if that's the expected behavior\n",
      "    assert len(actual_tool_names) == 1\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from model_factory import ModelName\n",
    "# generate test cases\n",
    "TEST_GEN_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are given langgraph code below:\n",
    "<CODE>\n",
    "{code}\n",
    "</CODE>\n",
    "You are given the use cases for a workflow graph along with dry runs.\n",
    "<USE_CASES>\n",
    "{use_cases}\n",
    "</USE_CASES>\n",
    "                                                   \n",
    "Below are documents which contain information about how to write test cases for the graph.\n",
    "<DOCUMENTS>\n",
    "<DOCUMENT1>\n",
    "{document1}\n",
    "</DOCUMENT1>\n",
    "</DOCUMENTS>\n",
    "                                                   \n",
    "You are supposed to write test cases for the graph in the <CODE> section, use the <USE_CASES> for generating test case inputs.\n",
    "                                              \n",
    "You are supposed to see the kind of tests that are being written in the <DOCUMENTS> section and write your own test cases in the same format.\n",
    "The tests should cover the following:\n",
    "1. Final response: Use LLM-as-judge to grade the final response of the graph.\n",
    "2. Trajectory: The trajectory of the nodes and tools called within the graph.\n",
    "3.Single step: Depending on the nature of each node, either using LLM-as-judge if the output of Node is a LLM text response, if the LLM is binded with tools, check if the llm is calling the correct tool when required and just responding back when not required.\n",
    "\n",
    "For the 3 type of tests the goal is to use pytest.parameterize to test against the different kind of inputs that could be derived from use cases.                  \n",
    "Note:\n",
    "- Also include the code in the output at the top\n",
    "                                                   \n",
    "DONT WRITE ANYTHING ELSE IN THE OUTPUT, ONLY OUTPUT THE CODE\n",
    "THIS CODE IS THE CODE THAT WILL BE RUN, SO IT SHOULD BE VALID PYTHON CODE\n",
    "DONT WRITE TOO MANY COMMENTS IN THE CODE, KEEP IT SIMPLE\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "gemini_llm = get_model(ModelName.GEMINI25FLASH)\n",
    "final_file =gemini_llm.invoke(TEST_GEN_PROMPT.format(\n",
    "    code=mocked_code,\n",
    "    use_cases=use_cases,\n",
    "    document1=fetch_documents(\"https://docs.smith.langchain.com/evaluation/tutorials/testing\")\n",
    "    ))\n",
    "\n",
    "final_file.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in e2b pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
