{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389e9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "import yaml\n",
    "import json\n",
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from typing import List\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "from typing import Annotated\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        # logging.FileHandler(\"scraper.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def fetch_documents(url: str) -> str:\n",
    "    \"\"\"Fetch a document from a URL and return the markdownified text.\n",
    "\n",
    "    Args:\n",
    "        url (satr): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The markdownified text of the document.\n",
    "    \"\"\"\n",
    "    httpx_client = httpx.Client(follow_redirects=True, timeout=10)\n",
    "\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        a_tags = soup.find_all('a')\n",
    "        for a_tag in a_tags:\n",
    "            a_tag.decompose()\n",
    "        \n",
    "        img_tags = soup.find_all('img')\n",
    "        for img_tag in img_tags:\n",
    "            img_tag.decompose()\n",
    "\n",
    "        target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "        \n",
    "        if not target_div:\n",
    "            target_div = soup.find('article') #langraph\n",
    "        \n",
    "        if not target_div:\n",
    "            return\n",
    "        \n",
    "        return html2text.html2text(str(target_div))\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\"\n",
    "    \n",
    "    \n",
    "agent_architecture_urls = [\"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/self-discover/self-discover\",\n",
    "]\n",
    "\n",
    "\n",
    "template = \"\"\"Your job is to get information from a user about what kind of agent they wish to build.\n",
    "\n",
    "You should get the following information from them:\n",
    "\n",
    "- What the objective of the agent is\n",
    "- Various usecases of the agent\n",
    "- Examples of the usage of the agent: input query and expected output from the agent\n",
    "\n",
    "If you are not able to discern this info, ask them to clarify! Do not attempt to wildly guess.\n",
    "\n",
    "After you are able to discern all the information, call the tool AgentInstruction \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6f87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentInstructions(BaseModel):\n",
    "    \"\"\"Instructions on how to build the Agent\"\"\"\n",
    "    objective: str = Field(description= \"What is the primary objective of the agent\")\n",
    "    usecases: List[str] = Field(description= \"What are the various responsibilities of the agent which it needs to fulfill\")\n",
    "    examples : str = Field(description= \"What are some examples of the usage of the agent (input query and expected output from the agent) ?\")\n",
    "\n",
    "class ArchEvaluationReport(BaseModel):\n",
    "    \"\"\"Class to represent the architecture evaluation report\"\"\"\n",
    "    name: str = Field(description=\"Name of the agent architecture being evaluated\")\n",
    "    highlights: str = Field(description=\"Concise summary of the architecture in 5 lines\")\n",
    "    evaluation_score: int = Field(description=\"evaluation of suitability of the agentic_architecture against user requirements from 1-10, 1 being least relevant to 10 being most relevant\")\n",
    "    justification: str = Field( description=\"Justification for the score\")\n",
    "    tailored_design: str = Field(description=\"Tailored design using the architecture\")\n",
    "    \n",
    "class ArchEvaluationWithUrl(NamedTuple):\n",
    "    url: str\n",
    "    report: ArchEvaluationReport\n",
    "\n",
    "class AgentBuilderState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    arch_evaluation_reports: Annotated[List[ArchEvaluationWithUrl], operator.add] = Field(\"list of agent architectures suggested in map-reduce step\")\n",
    "    best_agent_architecture: ArchEvaluationWithUrl = Field(\"The agent architecture best suited to above requirements\")\n",
    "    json_code: str = Field(\"The json code generated\")\n",
    "    python_code: str = Field(\"The Python code generated\")\n",
    "\n",
    "class ArchitectureEvaluationState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    url: str = Field(\"url of the agent architecture to evaluate against\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "def requirement_analysis_node(state: AgentBuilderState):\n",
    "    \n",
    "    llm_with_tool = llm.bind_tools([AgentInstructions])\n",
    "    response = llm_with_tool.invoke([SystemMessage(content=template)] + state[\"messages\"])\n",
    "    \n",
    "      # Construct the final answer from the arguments of the last tool call  \n",
    "    if len(response.tool_calls) == 0:\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    agent_instructions = response.tool_calls[0]\n",
    "    agent_instructions = AgentInstructions(**agent_instructions[\"args\"])\n",
    "    \n",
    "    return {\"messages\": [response], \"agent_instructions\": agent_instructions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6053a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH_EVALUATION_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are tasked with assessing the provided agentic architecture documentation to determine its relevance and applicability to the user requirements outlined below.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Agentic Architecture Documentation:\n",
    "{agent_architecture}\n",
    "\n",
    "- User Requirements:- Objectives: {objective}\n",
    "- Use Cases: {responsibilities}\n",
    "- Examples: {examples}\n",
    "\n",
    "\n",
    "Deliverables:\n",
    "Your evaluation should be presented in the following structured format:\n",
    "\n",
    "- Architecture Name:\n",
    "Provide the name of the agent architecture being assessed.\n",
    "- Concise Identifier:\n",
    "Suggest a brief, descriptive name for the architecture that encapsulates its purpose.\n",
    "- Key Highlights (2-3 Lines):\n",
    "Identify and summarize the most significant aspects or features of the architecture.\n",
    "- Feature Summary:\n",
    "Offer a detailed overview of the architecture's unique elements, functionalities, and capabilities.\n",
    "- Relevance Score (1-10):\n",
    "Assign a score based on the alignment between the architecture's features and the user's requirements (1 = minimally relevant, 10 = highly relevant).\n",
    "- Score Justification:\n",
    "Provide a clear and concise rationale (5-10 sentences) for the relevance score, highlighting how specific features match—or fail to match—the user's objectives, use cases, and examples.\n",
    "- Implementation Proposal:\n",
    "Outline a tailored approach for leveraging the architecture to meet the user’s requirements. Be specific and actionable, addressing how it can fulfill the stated objectives and responsibilities.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "AGENT_KERNEL_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        You are tasked with designing a langgraph StateGraph object that implements the {agent_architecture_name} architecture tailored to meet the user requirements outlined below.\n",
    "        <Requirements>\n",
    "        Objectives: {objective}\n",
    "        usecases: {responsibilities}\n",
    "        examples: {examples}\n",
    "        </Requirements>\n",
    "\n",
    "        <Documentation for {agent_architecture_name}>\n",
    "        {agent_architecture}\n",
    "        </Documentation for {agent_architecture_name}>\n",
    "        \n",
    "        Suggestion on how to implement the architecture in a way that meets the user requirements:\n",
    "        {agent_tailored}\n",
    "        \n",
    "        Output needs to be a compiled StateGraph object.\n",
    "        \n",
    "        Important to Note:\n",
    "        * Do not hallucinate when writing StateGraph related code, refer to the documentation provided.\n",
    "        * Understand the concept of the architecture, and refer to the examples of code. Now generate your own code tailored to requirements.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eef8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_kernel_builder(state: AgentBuilderState):\n",
    "    \"\"\"Build the agent kernel using the best architecture.\"\"\"\n",
    "    best_architecture: ArchEvaluationWithUrl = state[\"best_agent_architecture\"]\n",
    "    agent_instructions : AgentInstructions = state[\"agent_instructions\"]\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    agent_architecture_url : str = best_architecture.url\n",
    "    agent_architecture_report : ArchEvaluationReport = best_architecture.report\n",
    "    # agent_architecture_report.name\n",
    "    #agent_architecture_report.highlights\n",
    "    #agent_architecture_report.justification\n",
    "    #agent_architecture_report.tailored_design\n",
    "    \n",
    "    response =  llm.invoke([SystemMessage(content=AGENT_KERNEL_PROMPT.format(\n",
    "        objective=agent_instructions.objective,\n",
    "        responsibilities=agent_instructions.usecases,\n",
    "        examples = agent_instructions.examples,\n",
    "        # langgraph_glossary=fetch_documents(langgraph_glossary_url),\n",
    "        agent_tailored=agent_architecture_report.tailored_design,\n",
    "        agent_architecture_name = agent_architecture_report.name,\n",
    "        agent_architecture=fetch_documents(agent_architecture_url)))])\n",
    "    \n",
    "    # Return the generated agent kernel as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated agent kernel code!\")],\n",
    "        \"python_code\": response.content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5378e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def architecture_evaluation_map_node(state: AgentBuilderState):\n",
    "    return [Send(\"evaluate_against_architecture\", {\"agent_instructions\": state[\"agent_instructions\"], \"url\": url}) for url in agent_architecture_urls]\n",
    "\n",
    "def route_state(state: AgentBuilderState):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"add_tool_message\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"requirement_analysis\"\n",
    "\n",
    "def evaluate_against_architecture(state: ArchitectureEvaluationState):\n",
    "    agent_instructions: AgentInstructions = state[\"agent_instructions\"]\n",
    "    url: str = state[\"url\"]\n",
    "    llm_with_structured_output = llm.with_structured_output(ArchEvaluationReport)\n",
    "    archEvaluationReport: ArchEvaluationReport = llm_with_structured_output.invoke(\n",
    "        [SystemMessage(content=ARCH_EVALUATION_PROMPT.format(agent_architecture=fetch_documents(url),\n",
    "                                                             objective=agent_instructions.objective,\n",
    "                                                             responsibilities=agent_instructions.usecases,\n",
    "                                                             examples = agent_instructions.examples))])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Evaluated architecture {url}, arch_name: {archEvaluationReport.name}\")],\n",
    "        \"arch_evaluation_reports\": [ArchEvaluationWithUrl(url,archEvaluationReport)],\n",
    "    }\n",
    "\n",
    "def best_architecture(state: AgentBuilderState):\n",
    "    \"\"\"Select the best architecture based on the evaluation reports.\"\"\"\n",
    "    # Sort the architectures based on their evaluation scores\n",
    "    arch_reports : List[ArchEvaluationWithUrl] = state[\"arch_evaluation_reports\"]\n",
    "    sorted_architectures = sorted(arch_reports, key=lambda x: x.report.evaluation_score , reverse=True)\n",
    "    \n",
    "    # Select the best architecture (the first one in the sorted list)\n",
    "    best_architecture = sorted_architectures[0]\n",
    "    \n",
    "    print(\"found the best architecture\")\n",
    "    \n",
    "    # Return the best architecture as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Best architecture selected!\")],\n",
    "        \"best_agent_architecture\": best_architecture,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58789169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CODE_TO_JSON_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with converting the following stategraph comPilation code into a JSON. \n",
    "\n",
    "Contextual documents for understanding code:\n",
    "{documents}\n",
    "\n",
    "The code is as follows:\n",
    "{code_snippet}\n",
    "\n",
    "OUTPUT: Explaination and JSON. Do not include any code blocks. Seperate the JSON and explaination blocks and ensure that there is an explaination for each line of JSON produced but keep the blocks seperated.\n",
    "Each Output JSON will have a nodes sections containing all the nodes and an edges section\n",
    "\n",
    "Please follow:\n",
    "1. Produce the explaination first and then the JSON after it. DO not produce the JSON first. \n",
    "2. For any conditional edges, please include all the nodes that the source of a conditional edge can reach as part of the explaination.\n",
    "3. Any Edge entry in the JSON can only be conditional(mention conditional: true) if the source for that edge acts as a source for multiple edges. If you cannot point to atleast 2 targets for 1 source, then that source will not have any conditional edges\n",
    "4. A source can have any number of targets. Please write the explaination for each source node to target node edge\n",
    "5. Please ensure that the JSON starts with __START__ node and __END__ node with the correct edges from and to them\n",
    "6. Ensure all elements in the nodes sections of the output json contain the following fields: Schema_info, input_schema, output_schema, description, function_name. Please do not return any entries in the nodes without these fields and these fields can't be empty\n",
    "7. Ensure all elements in the edges sections of the output json contain the following fields: source, target, routing_conditions, conditional. Please do not return any entries in the edges without these fields and they can't be empty\n",
    "8. Every node should be a part of atleast one edge, Please ensure this is followed\n",
    "\n",
    "\n",
    "Example output JSON for a node:\n",
    "    \"code_node\":{{\n",
    "        \"schema_info\": /\"/\"/\"CodeWriterState:\n",
    "      type: TypedDict\n",
    "      fields:\n",
    "      - name: user_query\n",
    "        type: str\n",
    "      - name: execution_result\n",
    "        type: str/\"/\"/\",\n",
    "    \"input_schema\": \"CodeWriterState\",\n",
    "    \"output_schema\":\"RequiremenCodeWriterStatetAnalysisState\",\n",
    "    \"description\":\"This node analyzes the user_query, if the query is to write a code, it will make a tool call to run the proposed code. This node returns command object\",\n",
    "    \"function_name\": \"code_step\"\n",
    "    }}\n",
    "\n",
    "Example output JSON for an edge:\n",
    "edge:{{ source: \"abc\", target: \"cde\", routing_condition: \"if abc made a tool call then go to cde\", \"conditional\": true}}\n",
    "edge:{{ source: \"abc\", target: \"xyz\", routing_condition: \"if abc made an interupt to a human then go to xyz\", \"conditional\": true}}\n",
    "edge:{{ source: \"xyz\", target: \"_END_\", routing_condition: \"no nodes to go after xyz, we have our final output for this path\", \"conditional\": false}}s         \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f232093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_json_node(state: AgentBuilderState):\n",
    "    \"\"\"Convert the generated code to JSON.\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([SystemMessage(content=CODE_TO_JSON_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated JSON code!\")],\n",
    "        \"json_code\": json_code_ouptut.content,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20bbae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentBuilderState)\n",
    "workflow.add_node(\"requirement_analysis\", requirement_analysis_node)\n",
    "workflow.add_node(\"evaluate_against_architecture\", evaluate_against_architecture)\n",
    "workflow.add_node(\"best_architecture\", best_architecture)\n",
    "workflow.add_node(\"agent_kernel_builder\", agent_kernel_builder)\n",
    "workflow.add_node(\"code_to_json\", code_to_json_node)\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: AgentBuilderState):\n",
    "    \n",
    "   \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Requirements generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "workflow.add_edge(\"code_to_json\", END)\n",
    "workflow.add_edge(\"agent_kernel_builder\", \"code_to_json\")\n",
    "workflow.add_edge(\"best_architecture\", \"agent_kernel_builder\")\n",
    "workflow.add_edge(\"evaluate_against_architecture\", \"best_architecture\")\n",
    "workflow.add_conditional_edges(\"add_tool_message\", architecture_evaluation_map_node,[\"evaluate_against_architecture\"])\n",
    "workflow.add_conditional_edges(\"requirement_analysis\", route_state, [\"add_tool_message\", \"requirement_analysis\", END])\n",
    "workflow.add_edge(START, \"requirement_analysis\")\n",
    "infograph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa650d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (q/Q to quit): q\n",
      "AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "cached_human_responses = [\"hi!\", \"rag prompt\", \"1 rag, 2 none, 3 no, 4 no\", \"red\", \"q\"]\n",
    "cached_response_index = 0\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"User (q/Q to quit): \")\n",
    "    except:\n",
    "        user = cached_human_responses[cached_response_index]\n",
    "        cached_response_index += 1\n",
    "    print(f\"User (q/Q to quit): {user}\")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in infograph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"prompt\" in output:\n",
    "        print(\"Done!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202dc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
