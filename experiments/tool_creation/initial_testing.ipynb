{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a14c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "import yaml\n",
    "import json\n",
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from typing import List\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "from typing import Annotated\n",
    "from typing import NamedTuple\n",
    "import composio_langchain\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        # logging.FileHandler(\"scraper.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bfaf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Initial_prompt = \"\"\"You are an expert python developer. You will be given a description of a python function. \n",
    "\n",
    "You job is to estimate and extract the following information:\n",
    "\n",
    "- What exactly does this python do. What is the detailed objective of the function. Please write 1-5 lines\n",
    "- Suggest or extract the name of the the function\n",
    "- What would be the inputs/arguements required into this function to make it work. Please all mentioned the type of each input\n",
    "- WHat would be output produced by this input. Please mention the output type \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b542135",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7cfc715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionInstructions(BaseModel):\n",
    "    \"\"\"Instructions for defining a python function\"\"\"\n",
    "    objective: str = Field(description= \"what does this pythion function do\")\n",
    "    name: str = Field(description=\"name of the python function\")\n",
    "    input : List[str] = Field(description= \"what would be the input arguements to this function along with the types\")\n",
    "    output: List[str] = Field(description=\"what would be the output/return attributes for the function along with the types\")\n",
    "    code: str = Field(description=\"the final python code\")\n",
    "\n",
    "class CodebuilderState(BaseModel):\n",
    "    \"\"\"Instructions for defining a python function\"\"\"\n",
    "    code: str = Field(description= \"tailored code for the python function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae12f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"\"\"\n",
    "Create a python function that gets all my emails from gmail and filter them based on senders\"\n",
    "\"\"\"\n",
    "def functional_analysis_node(state: FunctionInstructions):\n",
    "  llm_with_structured_output = llm.with_structured_output(FunctionInstructions)\n",
    "  functionalReport: FunctionInstructions = llm_with_structured_output.invoke(\n",
    "      [SystemMessage(content=Initial_prompt)]+ [HumanMessage(content=human_prompt)])\n",
    "  return {  \"messages\": [AIMessage(content=\"Generated JSON code!\")],\n",
    "           \"objective\": functionalReport.objective,\n",
    "           \"name\": functionalReport.name,\n",
    "           \"input\": functionalReport.input,\n",
    "           \"output\": functionalReport.output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fe0565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_code_prompt = \"\"\"You are an expert Python developer tasked with creating Python functions (tools) based on user requests.\n",
    "\n",
    "            Your process is as follows:\n",
    "            1. Understand the user's request for a tool (e.g., \"tool to send a discord message\").\n",
    "            2. Find relevant Python SDKs for the core task.\n",
    "            3. See if Composio offers an integration for the relevant service (e.g., 'discord').\n",
    "            4. Analyze the results:\n",
    "                - If Composio has an integration, prioritize generating code that utilizes Composio (assume this involves calling a hypothetical 'composio.run_action()' function). Include a comment explaining this choice.\n",
    "                - If Composio does not have a clear integration, choose the most promising Python SDK found\n",
    "                - If no suitable SDK is found, state that you cannot create the function.\n",
    "            5. Generate *only* the complete, runnable Python function code based on your decision.\n",
    "                - The function should have clear arguments based on the user's likely intent (e.g., for discord, `channel_id` and `message_text`).\n",
    "                - Include a comprehensive docstring explaining the function, its arguments, and what it returns.\n",
    "                - Use type hints for all arguments and the return type.\n",
    "                - If using a standard SDK, add a comment indicating which SDK is intended (e.g., `# Uses discord.py`).\n",
    "                - If using Composio, structure the function to call `composio.run_action('service_name', 'action_name', params={{...}})` (you'll need to infer 'service_name' and 'action_name' and necessary params). Add comments explaining this structure.\n",
    "            6. Do not include any explanatory text before or after the code block. Output only the Python code for the function.\n",
    "\n",
    "    Here are some details about the python function you will be creating:\n",
    "    <objective>\n",
    "    {objective}\n",
    "    </objective>\n",
    "\n",
    "    <input schema>\n",
    "    {inputs}\n",
    "    </input schema>\n",
    "\n",
    "    <output schema>\n",
    "    {output}\n",
    "    </output schema>\n",
    "\n",
    "    <name of function>\n",
    "    {name}\n",
    "    </name of function>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb96806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_snips = \"\"\n",
    "\n",
    "def code_production_node(state: FunctionInstructions):\n",
    "    objective_agent: str = state.objective\n",
    "    name: str = state.name\n",
    "    input_args : List[str] = state.input\n",
    "    output_args: List[str] = state.output\n",
    "    response = llm.invoke([SystemMessage(content=write_code_prompt.format(\n",
    "          objective=objective_agent,\n",
    "          inputs=input_args,\n",
    "          output=output_args,\n",
    "          name=name,\n",
    "    ))])\n",
    "    code_snips = response\n",
    "    return {\n",
    "            \"code\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a698194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(functional_analysis_node)\n",
    "workflow.add_node(\"func_analysis\", functional_analysis_node)\n",
    "workflow.add_node(\"code_write\", code_production_node)\n",
    "\n",
    "workflow.add_edge(\"code_write\", END)\n",
    "workflow.add_edge(\"func_analysis\",\"code_write\")\n",
    "workflow.add_edge(START, \"func_analysis\")\n",
    "infograph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28578203",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(functional_analysis_node)\n",
    "workflow.add_node(\"func_analysis\", functional_analysis_node)\n",
    "# workflow.add_node(\"code_write\", code_production_node)\n",
    "\n",
    "workflow.add_edge(\"func_analysis\", END)\n",
    "# workflow.add_edge(\"func_analysis\",\"code_write\")\n",
    "workflow.add_edge(START, \"func_analysis\")\n",
    "infograph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "450809e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'func_analysis':\"\n",
      "'---'\n",
      "{ 'input': [ 'gmail_service: object (Gmail API service instance)',\n",
      "             'senders: list of strings (list of sender email addresses to '\n",
      "             'filter by)'],\n",
      "  'name': 'filter_emails_by_sender',\n",
      "  'objective': 'This Python function connects to a Gmail account using the '\n",
      "               'Gmail API, retrieves all emails, and filters them based on '\n",
      "               'specified sender email addresses. It allows users to manage '\n",
      "               'their inbox by focusing on emails from particular senders.',\n",
      "  'output': [ 'filtered_emails: list of dictionaries (list of email data '\n",
      "              'filtered by specified senders)']}\n",
      "'\\n---\\n'\n",
      "\"Output from node 'code_write':\"\n",
      "'---'\n",
      "{ 'code': AIMessage(content='```python\\ndef filter_emails_by_sender(gmail_service: object, senders: list[str]) -> list[dict]:\\n    \"\"\"\\n    Connects to a Gmail account using the Gmail API, retrieves all emails, \\n    and filters them based on specified sender email addresses.\\n\\n    Args:\\n        gmail_service (object): The Gmail API service instance used to interact with the Gmail API.\\n        senders (list[str]): A list of sender email addresses to filter the emails by.\\n\\n    Returns:\\n        list[dict]: A list of dictionaries containing email data filtered by the specified senders.\\n    \"\"\"\\n    filtered_emails = []\\n    results = gmail_service.users().messages().list(userId=\\'me\\').execute()\\n    messages = results.get(\\'messages\\', [])\\n\\n    for message in messages:\\n        msg = gmail_service.users().messages().get(userId=\\'me\\', id=message[\\'id\\']).execute()\\n        headers = msg[\\'payload\\'][\\'headers\\']\\n        for header in headers:\\n            if header[\\'name\\'] == \\'From\\':\\n                sender = header[\\'value\\']\\n                if sender in senders:\\n                    filtered_emails.append({\\n                        \\'id\\': message[\\'id\\'],\\n                        \\'snippet\\': msg[\\'snippet\\'],\\n                        \\'from\\': sender,\\n                        \\'subject\\': next((h[\\'value\\'] for h in headers if h[\\'name\\'] == \\'Subject\\'), None)\\n                    })\\n                break\\n\\n    return filtered_emails\\n```', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a'}, id='run-749c8f5e-7b4d-47f1-95d2-7530352c09b8-0')}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Maintain(BaseModel):\n",
    "    class Config:\n",
    "            arbitrary_types_allowed = True\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Create a python function that gets all my emails from gmail and filter them based on senders\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "code_snip = dict()\n",
    "for output in infograph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        code_snip = value\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dc8ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def filter_emails_by_sender(gmail_service: object, senders: list[str]) -> list[dict]:\n",
      "    \"\"\"\n",
      "    Connects to a Gmail account using the Gmail API, retrieves all emails, \n",
      "    and filters them based on specified sender email addresses.\n",
      "\n",
      "    Args:\n",
      "        gmail_service (object): The Gmail API service instance used to interact with the Gmail API.\n",
      "        senders (list[str]): A list of sender email addresses to filter the emails by.\n",
      "\n",
      "    Returns:\n",
      "        list[dict]: A list of dictionaries containing email data filtered by the specified senders.\n",
      "    \"\"\"\n",
      "    filtered_emails = []\n",
      "    results = gmail_service.users().messages().list(userId='me').execute()\n",
      "    messages = results.get('messages', [])\n",
      "\n",
      "    for message in messages:\n",
      "        msg = gmail_service.users().messages().get(userId='me', id=message['id']).execute()\n",
      "        headers = msg['payload']['headers']\n",
      "        for header in headers:\n",
      "            if header['name'] == 'From':\n",
      "                sender = header['value']\n",
      "                if sender in senders:\n",
      "                    filtered_emails.append({\n",
      "                        'id': message['id'],\n",
      "                        'snippet': msg['snippet'],\n",
      "                        'from': sender,\n",
      "                        'subject': next((h['value'] for h in headers if h['name'] == 'Subject'), None)\n",
      "                    })\n",
      "                break\n",
      "\n",
      "    return filtered_emails\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(code_snip['code'].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa0d73",
   "metadata": {},
   "source": [
    "from composio_langchain import ComposioToolSet, App\n",
    "\n",
    "composio_toolset = ComposioToolSet(api_key='zg6uxxn5rlc3aployj5ddo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "098b1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\tools\\toolset.py:2042: UserWarning: Running without a Composio API key\n",
      "  self.workspace.check_for_missing_dependencies(\n",
      "C:\\Users\\anupa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\client\\collections.py:1183: UserWarning: Using all actions of an app is not recommended for production.Learn more: https://docs.composio.dev/patterns/tools/use-tools/use-specific-actions\n",
      "\n",
      "Give Feedback / Get Help:\n",
      "    On GitHub: https://github.com/ComposioHQ/composio/issues/new\n",
      "    On Discord: https://dub.composio.dev/discord\n",
      "    On Email: tech@composio.dev\n",
      "    Talk to us on Intercom: https://composio.dev\n",
      "    Book a call with us: https://composio.dev/redirect?url=https://calendly.com/composiohq/support?utm_source=py-sdk-logs&utm_campaign=calendly\n",
      "If you need to debug this error, set `COMPOSIO_LOGGING_LEVEL=debug`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ApiKeyNotProvidedError",
     "evalue": "API Key not provided, either provide API key or export it as `COMPOSIO_API_KEY` or run `composio login`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mApiKeyNotProvidedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Initialize ToolSet (assuming API key is in env)\u001b[39;00m\n\u001b[32m      3\u001b[39m toolset = ComposioToolSet()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m github_tools = \u001b[43mtoolset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapps\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mApp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGITHUB\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(github_tools)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tools for GitHub.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio_openai\\toolset.py:142\u001b[39m, in \u001b[36mComposioToolSet.get_tools\u001b[39m\u001b[34m(self, actions, apps, tags, processors, check_connected_accounts)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m processors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mself\u001b[39m._processor_helpers.merge_processors(processors)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    132\u001b[39m     ChatCompletionToolParam(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    133\u001b[39m         **t.cast(\n\u001b[32m    134\u001b[39m             OpenAISchema,\n\u001b[32m    135\u001b[39m             \u001b[38;5;28mself\u001b[39m.schema.format(\n\u001b[32m    136\u001b[39m                 schema.model_dump(\n\u001b[32m    137\u001b[39m                     exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    138\u001b[39m                 )\n\u001b[32m    139\u001b[39m             ),\n\u001b[32m    140\u001b[39m         ).model_dump()\n\u001b[32m    141\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m schema \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_action_schemas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_connected_accounts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_connected_accounts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_populate_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\tools\\toolset.py:2067\u001b[39m, in \u001b[36mComposioToolSet.get_action_schemas\u001b[39m\u001b[34m(self, apps, actions, tags, check_connected_accounts, _populate_requested)\u001b[39m\n\u001b[32m   2059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._version_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2060\u001b[39m     actions = \u001b[38;5;28mself\u001b[39m._version_lock.apply(actions=actions)\n\u001b[32m   2062\u001b[39m items: t.List[ActionModel] = [\n\u001b[32m   2063\u001b[39m     *\u001b[38;5;28mself\u001b[39m._schema_helper.get_runtime_action_schemas(actions=actions),\n\u001b[32m   2064\u001b[39m     *\u001b[38;5;28mself\u001b[39m._schema_helper.get_local_action_schemas(\n\u001b[32m   2065\u001b[39m         apps=apps, actions=actions, tags=tags\n\u001b[32m   2066\u001b[39m     ),\n\u001b[32m-> \u001b[39m\u001b[32m2067\u001b[39m     *\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_schema_helper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_remote_actions_schemas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_connected_account\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_connected_account\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcheck_connected_accounts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2073\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2075\u001b[39m ]\n\u001b[32m   2077\u001b[39m items = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2078\u001b[39m     \u001b[38;5;28mmap\u001b[39m(\n\u001b[32m   2079\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m._schema_helper.process_schema(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2086\u001b[39m     )\n\u001b[32m   2087\u001b[39m )\n\u001b[32m   2089\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _populate_requested:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\tools\\toolset.py:535\u001b[39m, in \u001b[36mSchemaHelper.get_remote_actions_schemas\u001b[39m\u001b[34m(self, apps, actions, tags, check_connected_account)\u001b[39m\n\u001b[32m    533\u001b[39m items = [\u001b[38;5;28mself\u001b[39m.client.actions.get(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m versioned_actions]\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(none_versioned_actions) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(apps) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     items += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnone_versioned_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[38;5;28mself\u001b[39m._schema_cache.update({item.name: item.model_copy() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items})\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_connected_account \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\client\\collections.py:1301\u001b[39m, in \u001b[36mActions.get\u001b[39m\u001b[34m(self, action, actions, apps, tags, limit, use_case, allow_all)\u001b[39m\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_action(action=action)\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_case\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_case\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_all\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\client\\collections.py:1222\u001b[39m, in \u001b[36mActions._get_actions\u001b[39m\u001b[34m(self, actions, apps, tags, limit, use_case, allow_all)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1219\u001b[39m     queries[\u001b[33m\"\u001b[39m\u001b[33mlimit\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(limit)\n\u001b[32m   1221\u001b[39m response = \u001b[38;5;28mself\u001b[39m._raise_if_required(\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     response=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m.get(\n\u001b[32m   1223\u001b[39m         url=\u001b[38;5;28mstr\u001b[39m(\n\u001b[32m   1224\u001b[39m             \u001b[38;5;28mself\u001b[39m.endpoint(\n\u001b[32m   1225\u001b[39m                 queries=queries,\n\u001b[32m   1226\u001b[39m             )\n\u001b[32m   1227\u001b[39m         )\n\u001b[32m   1228\u001b[39m     )\n\u001b[32m   1229\u001b[39m )\n\u001b[32m   1231\u001b[39m response_json = response.json()\n\u001b[32m   1232\u001b[39m items = [\u001b[38;5;28mself\u001b[39m.model(**action) \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m response_json.get(\u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\client\\__init__.py:132\u001b[39m, in \u001b[36mComposio.http\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> HttpClient:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._http:\n\u001b[32m    130\u001b[39m         \u001b[38;5;28mself\u001b[39m._http = HttpClient(\n\u001b[32m    131\u001b[39m             base_url=\u001b[38;5;28mself\u001b[39m.base_url,\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m             api_key=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_key\u001b[49m,\n\u001b[32m    133\u001b[39m             runtime=\u001b[38;5;28mself\u001b[39m.runtime,\n\u001b[32m    134\u001b[39m         )\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._http\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\composio\\client\\__init__.py:114\u001b[39m, in \u001b[36mComposio.api_key\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m         \u001b[38;5;28mself\u001b[39m._api_key = env_api_key\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ApiKeyNotProvidedError\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._api_key = \u001b[38;5;28mself\u001b[39m.validate_api_key(\n\u001b[32m    117\u001b[39m     key=t.cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m._api_key),\n\u001b[32m    118\u001b[39m     base_url=\u001b[38;5;28mself\u001b[39m.base_url,\n\u001b[32m    119\u001b[39m )\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_key\n",
      "\u001b[31mApiKeyNotProvidedError\u001b[39m: API Key not provided, either provide API key or export it as `COMPOSIO_API_KEY` or run `composio login`"
     ]
    }
   ],
   "source": [
    "from composio_openai import ComposioToolSet, Action\n",
    "# Initialize ToolSet (assuming API key is in env)\n",
    "toolset = ComposioToolSet()\n",
    "github_tools = toolset.get_tools(apps=[App.GITHUB])\n",
    "print(f\"Fetched {len(github_tools)} tools for GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4334495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain, TransformChain\n",
    "from langchain_community.tools.zapier.tool import ZapierNLARunAction\n",
    "from langchain_community.utilities.zapier import ZapierNLAWrapper\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3de84ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "\n",
    "def fetch_documents(url: str) -> str:\n",
    "    \"\"\"Fetch a document from a URL and return the markdownified text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The markdownified text of the document.\n",
    "    \"\"\"\n",
    "    httpx_client = httpx.Client(follow_redirects=True, timeout=10)\n",
    "\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "        img_tags = soup.find_all('img')\n",
    "        for img_tag in img_tags:\n",
    "            img_tag.decompose()\n",
    "\n",
    "        target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "        \n",
    "        if not target_div:\n",
    "            target_div = soup.find('article') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            target_div = soup.find('html') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            return html2text.html2text(str(soup))\n",
    "        \n",
    "        return html2text.html2text(str(target_div))\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\"\n",
    "    \n",
    "def fetch_documents_with_links_html(url: str) -> tuple[str, list[tuple[str, str]]]:\n",
    "    \"\"\"Fetch a document from a URL, return the markdownified text with links as markdown, and extract links with their titles.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, list[tuple[str, str]]]: A tuple containing the markdownified text of the document with links, and a list of (link, title) tuples.\n",
    "    \"\"\"\n",
    "    httpx_client = httpx.Client(follow_redirects=True, timeout=10)\n",
    "    links = []\n",
    "\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "\n",
    "        if not target_div:\n",
    "            target_div = soup.find('article') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            return \"\", links # Return empty text but still the links\n",
    "\n",
    "        # Extract links *before* converting to markdown\n",
    "        a_tags = target_div.find_all('a')\n",
    "        for a_tag in a_tags:\n",
    "            link = a_tag.get('href')\n",
    "            title = a_tag.get_text(strip=True)\n",
    "            if link:\n",
    "                links.append((link, title))\n",
    "\n",
    "        markdown_converter = html2text.HTML2Text()\n",
    "        markdown_converter.body_width = 0  # Disable line wrapping for links to stay on one line\n",
    "        markdown_text = markdown_converter.handle(str(target_div))\n",
    "\n",
    "        return markdown_text, links\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\", [] # Return error message and empty links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cdd200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ArXiv\n",
      "\n",
      "This notebook goes over how to use the `arxiv` tool with an agent.\n",
      "\n",
      "First, you need to install the `arxiv` python package.\n",
      "\n",
      "    \n",
      "    \n",
      "    %pip install --upgrade --quiet  langchain-community arxiv  \n",
      "    \n",
      "    \n",
      "    \n",
      "    from langchain import hub  \n",
      "    from langchain.agents import AgentExecutor, create_react_agent, load_tools  \n",
      "    from langchain_openai import ChatOpenAI  \n",
      "      \n",
      "    llm = ChatOpenAI(temperature=0.0)  \n",
      "    tools = load_tools(  \n",
      "        [\"arxiv\"],  \n",
      "    )  \n",
      "    prompt = hub.pull(\"hwchase17/react\")  \n",
      "      \n",
      "    agent = create_react_agent(llm, tools, prompt)  \n",
      "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  \n",
      "    \n",
      "\n",
      "**API Reference:**[hub](https://python.langchain.com/api_reference/langchain/hub/langchain.hub.hub.html) | [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html) | [create_react_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.react.agent.create_react_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n",
      "    \n",
      "    \n",
      "    agent_executor.invoke(  \n",
      "        {  \n",
      "            \"input\": \"What's the paper 1605.08386 about?\",  \n",
      "        }  \n",
      "    )  \n",
      "    \n",
      "    \n",
      "    \n",
      "      \n",
      "      \n",
      "    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n",
      "    \u001b[32;1m\u001b[1;3mI should use the arxiv tool to search for the paper with the given identifier.  \n",
      "    Action: arxiv  \n",
      "    Action Input: 1605.08386\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2016-05-26  \n",
      "    Title: Heat-bath random walks with Markov bases  \n",
      "    Authors: Caprice Stanley, Tobias Windisch  \n",
      "    Summary: Graphs on lattice points are studied whose edges come from a finite set of  \n",
      "    allowed moves of arbitrary length. We show that the diameter of these graphs on  \n",
      "    fibers of a fixed integer matrix can be bounded from above by a constant. We  \n",
      "    then study the mixing behaviour of heat-bath random walks on these graphs. We  \n",
      "    also state explicit conditions on the set of moves so that the heat-bath random  \n",
      "    walk, a generalization of the Glauber dynamics, is an expander in fixed  \n",
      "    dimension.\u001b[0m\u001b[32;1m\u001b[1;3mThe paper \"1605.08386\" is titled \"Heat-bath random walks with Markov bases\" and is authored by Caprice Stanley and Tobias Windisch. It was published on May 26, 2016. The paper discusses the study of graphs on lattice points with edges coming from a finite set of allowed moves. It explores the diameter of these graphs and the mixing behavior of heat-bath random walks on them. The paper also discusses conditions for the heat-bath random walk to be an expander in fixed dimension.  \n",
      "    Final Answer: The paper \"1605.08386\" is about heat-bath random walks with Markov bases.\u001b[0m  \n",
      "      \n",
      "    \u001b[1m> Finished chain.\u001b[0m  \n",
      "    \n",
      "    \n",
      "    \n",
      "    {'input': \"What's the paper 1605.08386 about?\",  \n",
      "     'output': 'The paper \"1605.08386\" is about heat-bath random walks with Markov bases.'}  \n",
      "    \n",
      "\n",
      "## The ArXiv API Wrapper​\n",
      "\n",
      "The tool uses the `API Wrapper`. Below, we explore some of the features it\n",
      "provides.\n",
      "\n",
      "    \n",
      "    \n",
      "    from langchain_community.utilities import ArxivAPIWrapper  \n",
      "    \n",
      "\n",
      "**API\n",
      "Reference:**[ArxivAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.arxiv.ArxivAPIWrapper.html)\n",
      "\n",
      "You can use the ArxivAPIWrapper to get information about a scientific article\n",
      "or articles. The query text is limited to 300 characters.\n",
      "\n",
      "The ArxivAPIWrapper returns these article fields:\n",
      "\n",
      "  * Publishing date\n",
      "  * Title\n",
      "  * Authors\n",
      "  * Summary\n",
      "\n",
      "The following query returns information about one article with the arxiv ID\n",
      "\"1605.08386\".\n",
      "\n",
      "    \n",
      "    \n",
      "    arxiv = ArxivAPIWrapper()  \n",
      "    docs = arxiv.run(\"1605.08386\")  \n",
      "    docs  \n",
      "    \n",
      "    \n",
      "    \n",
      "    'Published: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.'  \n",
      "    \n",
      "\n",
      "Now, we want to get information about one author, `Caprice Stanley`.\n",
      "\n",
      "This query returns information about three articles. By default, the query\n",
      "returns information only about three top articles.\n",
      "\n",
      "    \n",
      "    \n",
      "    docs = arxiv.run(\"Caprice Stanley\")  \n",
      "    docs  \n",
      "    \n",
      "    \n",
      "    \n",
      "    'Published: 2017-10-10\\nTitle: On Mixing Behavior of a Family of Random Walks Determined by a Linear Recurrence\\nAuthors: Caprice Stanley, Seth Sullivant\\nSummary: We study random walks on the integers mod $G_n$ that are determined by an\\ninteger sequence $\\\\{ G_n \\\\}_{n \\\\geq 1}$ generated by a linear recurrence\\nrelation. Fourier analysis provides explicit formulas to compute the\\neigenvalues of the transition matrices and we use this to bound the mixing time\\nof the random walks.\\n\\nPublished: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.\\n\\nPublished: 2003-03-18\\nTitle: Calculation of fluxes of charged particles and neutrinos from atmospheric showers\\nAuthors: V. Plyaskin\\nSummary: The results on the fluxes of charged particles and neutrinos from a\\n3-dimensional (3D) simulation of atmospheric showers are presented. An\\nagreement of calculated fluxes with data on charged particles from the AMS and\\nCAPRICE detectors is demonstrated. Predictions on neutrino fluxes at different\\nexperimental sites are compared with results from other calculations.'  \n",
      "    \n",
      "\n",
      "Now, we are trying to find information about non-existing article. In this\n",
      "case, the response is \"No good Arxiv Result was found\"\n",
      "\n",
      "    \n",
      "    \n",
      "    docs = arxiv.run(\"1605.08386WWW\")  \n",
      "    docs  \n",
      "    \n",
      "    \n",
      "    \n",
      "    'No good Arxiv Result was found'  \n",
      "    \n",
      "\n",
      "## Related​\n",
      "\n",
      "  * Tool [conceptual guide](/docs/concepts/tools/)\n",
      "  * Tool [how-to guides](/docs/how_to/#tools)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = fetch_documents(\"https://python.langchain.com/docs/integrations/tools/arxiv/\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3473828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "tools = load_tools(\n",
    "    [\"arxiv\"],\n",
    ")\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d80e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_documents(url: str) -> str:\n",
    "    \"\"\"Fetch a document from a URL and return the markdownified text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The markdownified text of the document.\n",
    "    \"\"\"\n",
    "    httpx_client = httpx.Client(follow_redirects=True, timeout=10)\n",
    "\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "        img_tags = soup.find_all('img')\n",
    "        for img_tag in img_tags:\n",
    "            img_tag.decompose()\n",
    "\n",
    "        target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "        \n",
    "        if not target_div:\n",
    "            target_div = soup.find('article') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            target_div = soup.find('html') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            return html2text.html2text(str(soup))\n",
    "        \n",
    "        return html2text.html2text(str(target_div))\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a4c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Code:\n",
      "```python\n",
      "def calculate_area(length: float, width: float) -> float:\n",
      "    \"\"\"\n",
      "    Calculates the area of a rectangle.\n",
      "\n",
      "    Parameters:\n",
      "    length (float): The length of the rectangle.\n",
      "    width (float): The width of the rectangle.\n",
      "\n",
      "    Returns:\n",
      "    float: The area of the rectangle, calculated as length * width.\n",
      "\n",
      "    Example:\n",
      "    >>> calculate_area(5, 3)\n",
      "    15.0\n",
      "    \"\"\"\n",
      "    return length * width\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "# 1. Define Tool Specification (within a Python string, for simplicity)\n",
    "tool_spec = \"\"\"\n",
    "{\n",
    "  \"name\": \"calculate_area\",\n",
    "  \"description\": \"Calculates the area of a rectangle.\",\n",
    "  \"input_parameters\": [\n",
    "    {\n",
    "      \"name\": \"length\",\n",
    "      \"type\": \"number\",\n",
    "      \"description\": \"The length of the rectangle.\",\n",
    "      \"required\": true\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"width\",\n",
    "      \"type\": \"number\",\n",
    "      \"description\": \"The width of the rectangle.\",\n",
    "      \"required\": true\n",
    "    }\n",
    "  ],\n",
    "  \"output_specification\": {\n",
    "    \"type\": \"number\",\n",
    "    \"description\": \"The area of the rectangle.\"\n",
    "  },\n",
    "  \"functionality\": {\n",
    "    \"type\": \"python_function\"\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 2. Prepare the LLM Agent\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True)  # Use a powerful LLM\n",
    "# (In a full application, you might have other tools)\n",
    "tools = []\n",
    "\n",
    "\n",
    "# 3. Create Code Generation Prompt\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a Python programmer. You need to write a Python function\n",
    "that implements the following tool:\n",
    "\n",
    "Tool Specification:\n",
    "{tool_specification}\n",
    "\n",
    "-   Write a complete, runnable Python function.\n",
    "-   Include a docstring that explains what the function does and how to use it.\n",
    "-   Use type hints.\n",
    "-   Do not include any code outside of the function definition.\n",
    "\"\"\"\n",
    ")\n",
    "prompt = prompt_template.format(tool_specification=tool_spec)\n",
    "\n",
    "# 4. Agent Generates Code\n",
    "s = llm.invoke([SystemMessage(content=prompt)])\n",
    "print(\"Generated Code:\")\n",
    "print(s.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e425957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert Python developer tasked with creating Python functions (tools) based on user requests.\\n\\n            Your process is as follows:\\n            1. Understand the user\\'s request for a tool (e.g., \"tool to send a discord message\").\\n            2. Use the \\'sdk_search_tool\\' to find relevant Python SDKs for the core task.\\n            3. Use the \\'composio_check_tool\\' to see if Composio offers an integration for the relevant service (e.g., \\'discord\\').\\n            4. Analyze the results:\\n                - If Composio has an integration, prioritize generating code that utilizes Composio (assume this involves calling a hypothetical \\'composio.run_action()\\' function). Include a comment explaining this choice.\\n                - If Composio does not have a clear integration, choose the most promising Python SDK found in the search results.\\n                - If no suitable SDK is found, state that you cannot create the function.\\n            5. Generate *only* the complete, runnable Python function code based on your decision.\\n                - The function should have clear arguments based on the user\\'s likely intent (e.g., for discord, `channel_id` and `message_text`).\\n                - Include a comprehensive docstring explaining the function, its arguments, and what it returns.\\n                - Use type hints for all arguments and the return type.\\n                - If using a standard SDK, add a comment indicating which SDK is intended (e.g., `# Uses discord.py`).\\n                - If using Composio, structure the function to call `composio.run_action(\\'service_name\\', \\'action_name\\', params={{...}})` (you\\'ll need to infer \\'service_name\\' and \\'action_name\\' and necessary params). Add comments explaining this structure.\\n            6. Do not include any explanatory text before or after the code block. Output only the Python code for the function.\\n            '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"You are an expert Python developer tasked with creating Python functions (tools) based on user requests.\n",
    "\n",
    "            Your process is as follows:\n",
    "            1. Understand the user's request for a tool (e.g., \"tool to send a discord message\").\n",
    "            2. Find relevant Python SDKs for the core task.\n",
    "            3. See if Composio offers an integration for the relevant service (e.g., 'discord').\n",
    "            4. Analyze the results:\n",
    "                - If Composio has an integration, prioritize generating code that utilizes Composio (assume this involves calling a hypothetical 'composio.run_action()' function). Include a comment explaining this choice.\n",
    "                - If Composio does not have a clear integration, choose the most promising Python SDK found\n",
    "                - If no suitable SDK is found, state that you cannot create the function.\n",
    "            5. Generate *only* the complete, runnable Python function code based on your decision.\n",
    "                - The function should have clear arguments based on the user's likely intent (e.g., for discord, `channel_id` and `message_text`).\n",
    "                - Include a comprehensive docstring explaining the function, its arguments, and what it returns.\n",
    "                - Use type hints for all arguments and the return type.\n",
    "                - If using a standard SDK, add a comment indicating which SDK is intended (e.g., `# Uses discord.py`).\n",
    "                - If using Composio, structure the function to call `composio.run_action('service_name', 'action_name', params={{...}})` (you'll need to infer 'service_name' and 'action_name' and necessary params). Add comments explaining this structure.\n",
    "            6. Do not include any explanatory text before or after the code block. Output only the Python code for the function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bbe063",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9003dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc->check if any specific tool is good-> fetch doc link-> execute\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/update-state-from-tools/ \n",
    "tool command handling \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
