{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce52156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "import yaml\n",
    "import json\n",
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from typing import List\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "from typing import Annotated\n",
    "from typing import NamedTuple\n",
    "from utils.fetch_docs import fetch_documents\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        # logging.FileHandler(\"scraper.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "template = \"\"\"Your job is to get information from a user about what kind of agent they wish to build.\n",
    "\n",
    "You should get the following information from them:\n",
    "\n",
    "- What the objective of the agent is\n",
    "- Various usecases of the agent \n",
    "- Some examples of what the agent will be doing (Input and expected output pairs)\n",
    "\n",
    "If you are not able to discern this info, ask them to clarify! Do not attempt to wildly guess.\n",
    "\n",
    "After you are able to discern all the information, call the tool AgentInstruction\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919d49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentInstructions(BaseModel):\n",
    "    \"\"\"Instructions on how to build the Agent\"\"\"\n",
    "    objective: str = Field(description= \"What is the primary objective of the agent\")\n",
    "    usecases: List[str] = Field(description= \"What are the various responsibilities of the agent which it needs to fulfill\")\n",
    "    examples : str = Field(description= \"What are some examples of the usage of the agent (input query and expected output from the agent) ?\")\n",
    "\n",
    "class AgentBuilderState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    json_code: str = Field(\"The json code generated\")\n",
    "    python_code: str = Field(\"The Python code generated\")\n",
    "\n",
    "class ArchitectureEvaluationState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    url: str = Field(\"url of the agent architecture to evaluate against\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", temperature=0)\n",
    "\n",
    "def requirement_analysis_node(state: AgentBuilderState):\n",
    "    \n",
    "    llm_with_tool = llm.bind_tools([AgentInstructions])\n",
    "    response = llm_with_tool.invoke([SystemMessage(content=template)] + state[\"messages\"])\n",
    "    \n",
    "      # Construct the final answer from the arguments of the last tool call  \n",
    "    if len(response.tool_calls) == 0:\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    agent_instructions = response.tool_calls[0]\n",
    "    agent_instructions = AgentInstructions(**agent_instructions[\"args\"])\n",
    "    \n",
    "    return {\"messages\": [response], \"agent_instructions\": agent_instructions}\n",
    "\n",
    "\n",
    "def route_state(state: AgentBuilderState):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"agent_kernel_builder\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"requirement_analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f87e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AGENT_KERNEL_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Task Overview:\n",
    "        Design a langgraph StateGraph object implementing the the best architecture for the given set of requirements, tailored to fulfill the user requirements defined below\n",
    "\n",
    "        <Requirements>\n",
    "        Objectives: {objective}\n",
    "        usecases: {responsibilities}\n",
    "        examples: {examples}\n",
    "        </Requirements>\n",
    "\n",
    "        \n",
    "        Expected Output:\n",
    "        Your task is to produce a compiled StateGraph object.\n",
    "\n",
    "        Guidelines for Code Generation:\n",
    "        - Accuracy: Avoid hallucinations or speculative assumptions when writing code. Refer exclusively to the provided documentation.\n",
    "        - Understanding: Thoroughly comprehend the architecture and examples of code.\n",
    "        - Customization: Generate code tailored specifically to meet the user requirements.\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "def agent_kernel_builder(state: AgentBuilderState):\n",
    "    \"\"\"Build the agent kernel using the best architecture.\"\"\"\n",
    "    agent_instructions : AgentInstructions = state[\"agent_instructions\"]\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    # agent_architecture_report.name\n",
    "    #agent_architecture_report.highlights\n",
    "    #agent_architecture_report.justification\n",
    "    #agent_architecture_report.tailored_design\n",
    "    print(\"reached here\")\n",
    "    response =  llm.invoke([HumanMessage(content=AGENT_KERNEL_PROMPT.format(\n",
    "        objective=agent_instructions.objective,\n",
    "        responsibilities=agent_instructions.usecases,\n",
    "        examples = agent_instructions.examples,\n",
    "        # langgraph_glossary=fetch_documents(langgraph_glossary_url),\n",
    "        ))])\n",
    "    \n",
    "    # Return the generated agent kernel as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated agent kernel code!\")],\n",
    "        \"python_code\": response.content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec67a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CODE_TO_JSON_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with converting the following stategraph comPilation code into a JSON. \n",
    "\n",
    "Contextual documents for understanding code:\n",
    "{documents}\n",
    "\n",
    "The Input code is as follows:\n",
    "{code_snippet}\n",
    "\n",
    "OUTPUT: Explaination and JSON. Do not include any code blocks. Seperate the JSON and explaination blocks and ensure that there is an explaination for each line of JSON produced but keep the blocks seperated.\n",
    "Each Output JSON will have a nodes sections containing all the nodes and an edges section\n",
    "\n",
    "Please follow:\n",
    "1. Produce the explaination first and then the JSON after it. DO not produce the JSON first. \n",
    "2. For any conditional edges, please include all the nodes that the source of a conditional edge can reach as part of the explaination.\n",
    "3. Any Edge entry in the JSON can only be conditional(mention conditional: true) if the source for that edge acts as a source for multiple edges. If you cannot point to atleast 2 targets for 1 source, then that source will not have any conditional edges\n",
    "4. A source can have any number of targets. Please write the explaination for each source node to target node edge\n",
    "5. Please ensure that the JSON starts with __START__ node and __END__ node with the correct edges from and to them\n",
    "6. Ensure all elements in the nodes sections of the output json contain the following fields: Schema_info, input_schema, output_schema, description, function_name. Please do not return any entries in the nodes without these fields and these fields can't be empty\n",
    "7. Ensure all elements in the edges sections of the output json contain the following fields: source, target, routing_conditions, conditional. Please do not return any entries in the edges without these fields and they can't be empty\n",
    "8. Every node should be a part of atleast one edge, Please ensure this is followed\n",
    "9. Attach the code snippet for each node aswell that. Please extract it from the Input code\n",
    "\n",
    "\n",
    "Example output JSON for a node:\n",
    "    \"code_node\":{{\n",
    "        \"schema_info\": /\"/\"/\"CodeWriterState:\n",
    "      type: TypedDict\n",
    "      fields:\n",
    "      - name: user_query\n",
    "        type: str\n",
    "      - name: execution_result\n",
    "        type: str/\"/\"/\",\n",
    "    \"input_schema\": \"CodeWriterState\",\n",
    "    \"output_schema\":\"RequiremenCodeWriterStatetAnalysisState\",\n",
    "    \"description\":\"This node analyzes the user_query, if the query is to write a code, it will make a tool call to run the proposed code. This node returns command object\",\n",
    "    \"function_name\": \"code_step\"\n",
    "    }}\n",
    "\n",
    "Example output JSON for an edge:\n",
    "edge:{{ source: \"abc\", target: \"cde\", routing_condition: \"if abc made a tool call then go to cde\", \"conditional\": true}}\n",
    "edge:{{ source: \"abc\", target: \"xyz\", routing_condition: \"if abc made an interupt to a human then go to xyz\", \"conditional\": true}}\n",
    "edge:{{ source: \"xyz\", target: \"_END_\", routing_condition: \"no nodes to go after xyz, we have our final output for this path\", \"conditional\": false}}s         \n",
    "\"\"\")\n",
    "def code_to_json_node(state: AgentBuilderState):\n",
    "    \"\"\"Convert the generated code to JSON.\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([HumanMessage(content=CODE_TO_JSON_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated JSON code!\")],\n",
    "        \"json_code\": json_code_ouptut.content,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f75bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JSON_CODE_COMBINE_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with verifying and updating the provided JSON that represents the nodes and edges of the langgraph to ensure it is correct with respect to the input code.\n",
    "\n",
    "Contextual Documents for Understanding Code:\n",
    "{documents}\n",
    "\n",
    "Input Code:\n",
    "<Input code>{code_snippet}</Input code>\n",
    "JSON:\n",
    "<JSON>{node_json}</JSON>\n",
    "\n",
    "OUTPUT: JSON\n",
    "Your task is divided into two parts:\n",
    "- Validation: Verify that the JSON adheres to the rules outlined below.\n",
    "- Correction and Augmentation: If the JSON is incorrect or incomplete, update it with a clear justification for every change, and include the code snippet for each node extracted from the input code.\n",
    "\n",
    "Rules for Validation and Update:\n",
    "- Conditional Edges:- An edge can be marked as conditional: true only if its source acts as a source for multiple edges (i.e., at least two targets).\n",
    "- If the source does not meet this condition, then it cannot have conditional edges.\n",
    "\n",
    "- Edge Targets:- Each source can have any number of targets. This flexibility must be maintained.\n",
    "\n",
    "- Start and End Nodes:- The JSON must begin with the __START__ node and conclude with the __END__ node, with correct edges to and from them. Edges into the END node can also be conditional if they meet the above mentioned conditions      \n",
    "\n",
    "- Node Structure:- Each node entry in the nodes section of the JSON must include the following non-empty fields:- schema_info\n",
    "- id\n",
    "- schema_info\n",
    "- input_schema\n",
    "- output_schema\n",
    "- description\n",
    "- function_name\n",
    "\n",
    "\n",
    "- Edge Structure:- Each edge entry in the edges section of the JSON must include the following non-empty fields:- source\n",
    "- target\n",
    "- routing_conditions\n",
    "- conditional\n",
    "\n",
    "\n",
    "- Node-Edge Relationship:- Every node must be part of at least one edge. Ensure this relationship is consistently followed.\n",
    "\n",
    "- Node Code Snippets:- Attach a code field to every node in the JSON, extracted directly from the input code.\n",
    "\n",
    "- Schema Requirements:- The final JSON must conform to the schema provided below:\n",
    "\n",
    "\n",
    "Schema for JSON. Ensure the following schema is followed. No field should be missing for any node or edge:\n",
    "- Node Example:\n",
    "\n",
    "{{\n",
    "  \"code_node\": {{\n",
    "    \"id\" : \"<id of the node, similar to name>\"\n",
    "    \"schema_info\": \"<define the class structure of the state of this node. Also provide a name>\",\n",
    "    \"input_schema\": \"<input state object name>\",\n",
    "    \"output_schema\": \"<output state object name>\",\n",
    "    \"description\": \"<description>\",\n",
    "    \"function_name\": \"<function_name>\",\n",
    "    \"code\": \"<python_code>\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\n",
    "- Edge Example:\n",
    "\n",
    "{{\n",
    "  \"edge\": {{\n",
    "    \"source\": \"<source_node>\",\n",
    "    \"target\": \"<target_node>\",\n",
    "    \"routing_condition\": \"<routing_condition>\",\n",
    "    \"conditional\": true/false\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\n",
    "                                            \n",
    "Key Instructions:\n",
    "- Do not update any pre-existing field of the JSON unless you have an extremely strong justification for doing so.\n",
    "- Clearly document the reasoning behind any additions, updates, or modifications to the JSON. Justifications should draw inspiration from the contextual documents mentioned earlier.\n",
    "- Ensure conditional edges strictly adhere to the rules outlined above.\n",
    "- Input_Schema and output_schemas can only have value None in JSON for START and END nodes. Please follow this without fail\n",
    "- Include a code field for each code_node entry, with the exact code that corresponds to the node in the input code.\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "def json_better_node(state: AgentBuilderState):\n",
    "    \"\"\"Add code to the json flow\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([HumanMessage(content=JSON_CODE_COMBINE_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        node_json = state[\"json_code\"]\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated updated JSON code!\")],\n",
    "        \"json_code\": json_code_ouptut.content,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6ed40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_GEN_PROMPT = PromptTemplate.from_template( \"\"\"\n",
    "You are an expert Python programmer specializing in LangGraph and AI agent development. Your primary task is to generate compilable Python code for a LangGraph state graph based on a JSON description that will be provided. You must carefully analyze the JSON to determine node functionalities, state management, and graph connectivity.\n",
    "\n",
    "**Input:**\n",
    "You will receive a JSON object with two main keys:\n",
    "1.  `nodes`: A dictionary where each key is a unique node ID. The value for each node ID is an object containing:\n",
    "    * `id`: The node's identifier.\n",
    "    * `schema_info`: A string describing the structure of the `GraphState` (e.g., \"GraphState:\\n type: TypedDict\\n fields:\\n - name: input\\n type: str...\"). You will need to parse this to define the `GraphState` TypedDict.\n",
    "    * `input_schema`: The expected input schema for the node (typically \"GraphState\").\n",
    "    * `output_schema`: The schema of the output produced by the node (typically \"GraphState\", indicating a partial update).\n",
    "    * `description`: A natural language description of what the node does. This is crucial for determining implementation strategy.\n",
    "    * `function_name`: The suggested Python function name for this node.\n",
    "    * `code` (optional): A string containing Python code for the node's function. This might be a complete implementation or a simplified example.\n",
    "\n",
    "2.  `edges`: A list of objects, each describing a directed edge in the graph. Each edge object contains:\n",
    "    * `source`: The ID of the source node (or \"__START__\" for the graph's entry point).\n",
    "    * `target`: The ID of the target node (or \"__END__\" for a graph termination point).\n",
    "    * `routing_conditions`: A natural language description of the condition under which this edge is taken, especially for conditional edges.\n",
    "    * `conditional`: A boolean flag, `true` if the edge is part of a conditional branch, `false` otherwise.\n",
    "\n",
    "**Output Requirements:**\n",
    "Generate a single, self-contained, and compilable Python script that performs the following:\n",
    "\n",
    "1.  **Imports:** Include all necessary Python libraries (e.g., `typing` for `TypedDict`, `Optional`, `Dict`, `Any`; `langgraph.graph.StatefulGraph`, `langgraph.graph.START`, `langgraph.graph.END`; `langgraph.checkpoint.memory.InMemoryCheckpointer`; potentially `langchain_openai`, `langchain_core.pydantic_v1` for Pydantic models if LLM with structured output is needed; `re` if used in provided code snippets).\n",
    "\n",
    "2.  **State Definition (`GraphState`):**\n",
    "    * Parse the `schema_info` string from one of the node descriptions (assume they are consistent; if not, use the first one encountered).\n",
    "    * Define a `GraphState` class using `typing.TypedDict` that accurately reflects the fields and their types as specified in `schema_info`. Pay close attention to `Optional` types and nested structures if any.\n",
    "\n",
    "3.  **Node Implementation (Python Functions):**\n",
    "    For each node defined in the `nodes` section of the JSON:\n",
    "    * Create a Python function with the `function_name` provided. This function must accept the `GraphState` (the TypedDict you defined) as its sole argument and return a dictionary representing the partial update to the state.\n",
    "    * **Decision Logic for Implementation Strategy (CRITICAL):**\n",
    "        * **Simple Algorithmic Logic:** If the `description` indicates a straightforward task and the provided `code` snippet is a complete, purely algorithmic Python function (e.g., string manipulation, regex-based parsing, simple dictionary operations) that fully implements this description without requiring advanced natural language understanding or complex inference, then directly use or adapt this provided `code` for the node's function.\n",
    "        * **LLM Requirement:** If the `description` implies complex tasks such as:\n",
    "            * Natural Language Understanding (NLU) (e.g., \"robust intent classification\", \"understanding user queries\")\n",
    "            * Complex decision-making based on unstructured input\n",
    "            * Text generation or summarization\n",
    "            * Or if the `description` explicitly states \"this function would typically use an LLM\" or similar.\n",
    "            Then, you MUST implement the node to utilize a Large Language Model (LLM).\n",
    "            * If `code` is provided but is clearly a simplistic placeholder for what should be an LLM-driven task (e.g., basic keyword matching for intent classification when robust understanding is needed, as seen in the example's `classify_intent` node), you should replace or augment this simplistic code with an actual LLM integration.\n",
    "            * When an LLM is required:\n",
    "                * Include the necessary import for a common LLM client (e.g., `from langchain_openai import ChatOpenAI`).\n",
    "                * In the node function, you can either instantiate a generic model (e.g., `llm = ChatOpenAI(model=\"gpt-3.5-turbo\") # TODO: Replace with specific model and API key if needed`) or provide clear comment placeholders (e.g., `# Initialize LLM here (e.g., llm = ChatOpenAI(...))` followed by `# response = llm.invoke(...) # Adapt prompt and parsing based on node's task`).\n",
    "                * The LLM should be prompted (even if schematically) to perform the task outlined in the node's `description`.\n",
    "        * **Structured Output from LLM:** If the node's `description` or its purpose (e.g., extracting specific entities, parsing data into a predefined schema beyond simple `GraphState` fields) suggests that an LLM needs to produce a structured output (e.g., JSON, specific Pydantic model):\n",
    "            * Define a Pydantic model (e.g., `from langchain_core.pydantic_v1 import BaseModel, Field`) representing the desired structured output.\n",
    "            * If implementing an LLM call, configure it to use the Pydantic model for its output (e.g., with OpenAI's function calling/tool usage features, or by instructing the LLM to generate JSON conforming to the model).\n",
    "        * **Tools for LLM:** If the `description` implies the node needs to interact with external systems, call specific APIs, or choose from a set of defined capabilities (e.g., \"search customer database,\" \"fetch external data,\" \"invoke a specific service\"):\n",
    "            * Define appropriate LangChain tools (e.g., using `@tool` from `langchain_core.tools`).\n",
    "            * If implementing an LLM call, bind these tools to the LLM. The LLM's role would be to decide which tool(s) to call based on the current state and input. For this generation task, you might define placeholder tools if the specifics are not in the JSON.\n",
    "\n",
    "4.  **Graph Construction (`StatefulGraph`):**\n",
    "    * Instantiate `StatefulGraph(GraphState)`.\n",
    "    * Add each implemented node function to the graph using `graph.add_node(\"node_id\", node_function)`.\n",
    "    * Set the graph's entry point using `graph.add_edge(START, \"entry_node_id\")` where `\"entry_node_id\"` is the target of the edge originating from `\"__START__\"`.\n",
    "\n",
    "5.  **Edge Implementation:**\n",
    "    * Iterate through the `edges` list in the JSON.\n",
    "    * **Regular Edges:** If `conditional` is `false`:\n",
    "        * If `target` is `__END__`, use `graph.add_edge(source_node_id, END)`.\n",
    "        * Otherwise, use `graph.add_edge(source_node_id, target_node_id)`.\n",
    "    * **Conditional Edges:** If `conditional` is `true`:\n",
    "        * The `source` node of these conditional edges is expected to produce some output in the `GraphState` (e.g., an `intent` field) that determines the next path.\n",
    "        * Create a separate routing function (e.g., `def route_after_source_node(state: GraphState) -> str:`).\n",
    "        * This routing function must inspect the relevant fields in the `state` and return the string ID of the next node to execute, based on the logic described in the `routing_conditions` for each conditional edge originating from that source.\n",
    "        * Use `graph.add_conditional_edges(source_node_id, routing_function, {{ \"target_id_1\": \"target_id_1\", \"target_id_2\": \"target_id_2\", ... \"__END__\": END }})`. The keys in the dictionary are the possible return values from your routing function, and the values are the actual node IDs or `END`.\n",
    "\n",
    "6.  **Compilation:**\n",
    "    * Instantiate an `InMemoryCheckpointer`: `checkpointer = InMemoryCheckpointer()`.\n",
    "    * Compile the graph: `final_app = graph.compile(checkpointer=checkpointer)`. The compiled graph must be assigned to a variable named `final_app`.\n",
    "\n",
    "**Important Considerations:**\n",
    "* The generated Python code must be complete, runnable, and accurately reflect the graph structure and logic described in the JSON.\n",
    "* Ensure all node functions correctly update and return the relevant parts of the `GraphState`.\n",
    "* If the provided `code` in the JSON uses specific libraries (e.g., `re`), make sure the corresponding import is included at the top of the script.\n",
    "* Handle `__START__` and `__END__` correctly in edge definitions. `langgraph.graph.START` and `langgraph.graph.END` should be used.\n",
    "\n",
    "Here is the JSON input:\n",
    "<json>\n",
    "{code_json}\n",
    "</json>\n",
    "\n",
    "Please generate the Python code now:\n",
    "\"\"\")\n",
    "\n",
    "def code_node(state: AgentBuilderState):\n",
    "    \"\"\"Produce the final python code\"\"\"\n",
    "    code_ouptut = llm.invoke([HumanMessage(content=CODE_GEN_PROMPT.format(\n",
    "        code_json = state[\"json_code\"]\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated final python code!\")],\n",
    "        \"python_code\": code_ouptut.content,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a752111",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_GEN_PROMPT = PromptTemplate.from_template( \"\"\"\n",
    "You are an expert Python programmer specializing in LangGraph and AI agent development. Your primary task is to generate compilable, logical, and complete Python code for a LangGraph state graph based on a JSON description. You must prioritize LLM-based implementations for relevant tasks and consider advanced graph architectures.\n",
    "\n",
    "**Input:**\n",
    "You will receive a JSON object with two main keys:\n",
    "1.  `nodes`: A dictionary where each key is a unique node ID. The value for each node ID is an object containing:\n",
    "    * `id`: The node's identifier.\n",
    "    * `schema_info`: A string describing the structure of the `GraphState` (e.g., \"GraphState:\\n type: TypedDict\\n fields:\\n - name: input\\n type: str...\"). You will need to parse this to define the `GraphState` TypedDict.\n",
    "    * `input_schema`: The expected input schema for the node (typically \"GraphState\").\n",
    "    * `output_schema`: The schema of the output produced by the node (typically \"GraphState\", indicating a partial update).\n",
    "    * `description`: A natural language description of what the node does. This is crucial for determining implementation strategy and overall architecture.\n",
    "    * `function_name`: The suggested Python function name for this node.\n",
    "    * `code` (optional): A string containing Python code for the node's function. **Treat this `code` primarily as an illustration or a very basic version. Prioritize LLM-based solutions if the `description` suggests a more robust approach is needed.**\n",
    "\n",
    "2.  `edges`: A list of objects, each describing a directed edge in the graph. Each edge object contains:\n",
    "    * `source`: The ID of the source node (or \"__START__\" for the graph's entry point).\n",
    "    * `target`: The ID of the target node (or \"__END__\" for a graph termination point).\n",
    "    * `routing_conditions`: A natural language description of the condition under which this edge is taken, especially for conditional edges.\n",
    "    * `conditional`: A boolean flag, `true` if the edge is part of a conditional branch, `false` otherwise.\n",
    "\n",
    "---\n",
    "**Phase 1: Graph Architecture Analysis & Strategy**\n",
    "\n",
    "Before generating any code, analyze the overall workflow implied by the `nodes` and `edges` in the JSON.\n",
    "1.  **Identify Potential Architectures:** Consider if the described system aligns with or would benefit from known advanced LangGraph architectures such as:\n",
    "    * **Plan and Execute**: Does the graph imply a planning step (e.g., breaking down a complex task) followed by the execution of those plans by one or more action nodes?\n",
    "    * **Agent Supervisor / Hierarchical Agent Teams**: Do the nodes and their conditional routing suggest a supervisory agent dispatching tasks to specialized worker agents, or a hierarchy of agents making decisions and delegating?\n",
    "    * **Multi-Agent Collaboration (e.g., Swarm Architecture)**: Does the problem benefit from multiple agents working in parallel or collaboratively, perhaps sharing insights or contributing to a common goal?\n",
    "    * **Reflection / Self-Correction (e.g., Self-Discover frameworks)**: Are there indications of iterative refinement, where results are evaluated and the process is adjusted?\n",
    "\n",
    "2.  **Architectural Decision:**\n",
    "    * If you determine that one or more of these architectures are strongly applicable and would create a more robust or intelligent system based on the JSON's intent, choose to implement it.\n",
    "    * This may require you to define additional coordinating nodes or logic (e.g., a dedicated 'planner' LLM-agent, a 'supervisor' LLM-agent that routes tasks) that are not explicitly listed as individual nodes in the input JSON but are integral to the chosen architecture.\n",
    "    * If no specific advanced architecture seems directly applicable or sufficiently justified by the input JSON, proceed with a standard stateful graph construction based on the explicit nodes and edges.\n",
    "\n",
    "3.  **Initial Comment:** At the very beginning of your generated Python script, include a comment block stating:\n",
    "    * Which LangGraph architecture(s) (if any) you've identified and chosen to implement, with a brief justification based on your interpretation of the input JSON.\n",
    "    * If you are proceeding with a standard graph, mention that.\n",
    "\n",
    "---\n",
    "**Phase 2: Python Code Generation**\n",
    "\n",
    "Generate a single, self-contained, and compilable Python script that implements your chosen strategy.\n",
    "\n",
    "1.  **Imports:** Include all necessary Python libraries (e.g., `typing`, `langgraph.graph`, `langgraph.checkpoint.memory`, LLM client libraries like `langchain_openai`, `langchain_google_genai`, `langchain_core.pydantic_v1`, `langchain_core.tools`, `re`).\n",
    "\n",
    "2.  **State Definition (`GraphState`):**\n",
    "    * Parse the `schema_info` string to define a `GraphState` class using `typing.TypedDict`.\n",
    "\n",
    "3.  **Node Implementation (Python Functions):**\n",
    "    For each conceptual node in your chosen architecture (these may map directly to JSON nodes or be new architectural nodes you define):\n",
    "    * Create a Python function. This function must accept the `GraphState` and return a dictionary representing the partial update to the state.\n",
    "    * **Decision Logic for Implementation (Prioritize LLM, No Mock Data):**\n",
    "        * **Default to LLM-Based Solutions:** Your default stance should be to implement an **LLM-based solution** if the node's `description` (from JSON or your architectural design) suggests tasks like:\n",
    "            * Natural Language Understanding (NLU)\n",
    "            * Complex classification or routing\n",
    "            * Content generation or summarization\n",
    "            * Tool selection and usage\n",
    "            * Planning or complex decision-making.\n",
    "            * Any task where an LLM would provide more robust, flexible, or intelligent behavior than simple hardcoded logic.\n",
    "        * **Handling Provided `code`:** If `code` is present in the JSON for a node, treat it as a **low-priority hint or a simplistic example**. Do **not** simply copy it if an LLM approach is more appropriate for the described task.\n",
    "        * **Algorithmic Logic (Use Sparingly):** Only use purely algorithmic Python code (like from the `code` attribute or written new) if the node's task is genuinely simple, deterministic (e.g., basic data formatting, fixed calculation), *and* an LLM would offer no significant benefit for that specific, narrow function.\n",
    "        * **Functional LLM Calls:** When an LLM is used, instantiate a generic model (e.g., `llm = ChatOpenAI(model=\"gpt-3.5-turbo\")` or `llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")`) and include a **functional, descriptive prompt** relevant to the node's task. Ensure the code for the LLM call is complete and not just a comment. Add a `TODO` comment for the user to specify API keys and potentially refine the model/prompt.\n",
    "        * **No Mock Data:** Generated functions must be logical and aim for completeness. **Avoid using mock data or overly simplistic placeholder logic** where an LLM or a proper algorithmic implementation is expected.\n",
    "        * **Structured Output & Tools:** If the task implies structured output from an LLM or the use of tools, define necessary Pydantic models and/or LangChain tools, and integrate them with the LLM call.\n",
    "        * **Human in the Loop Nodes:** If you've designed a HITL step as a dedicated node, its function might primarily format data for human review and then process the subsequent human input (which would be added to the state, potentially by an external mechanism or a subsequent node). The graph might pause using an interruption mechanism tied to this node.\n",
    "        * **Structured Output from LLM:** If the node's `description` or its purpose (e.g., extracting specific entities, parsing data into a predefined schema beyond simple `GraphState` fields) suggests that an LLM needs to produce a structured output (e.g., JSON, specific Pydantic model):\n",
    "            * Define a Pydantic model (e.g., `from langchain_core.pydantic_v1 import BaseModel, Field`) representing the desired structured output.\n",
    "            * If implementing an LLM call, configure it to use the Pydantic model for its output (e.g., with OpenAI's function calling/tool usage features, or by instructing the LLM to generate JSON conforming to the model).\n",
    "        * **Tools for LLM:** If the `description` implies the node needs to interact with external systems, call specific APIs, or choose from a set of defined capabilities (e.g., \"search customer database,\" \"fetch external data,\" \"invoke a specific service\"):\n",
    "            * Define appropriate LangChain tools (e.g., using `@tool` from `langchain_core.tools`).\n",
    "            * If implementing an LLM call, bind these tools to the LLM. The LLM's role would be to decide which tool(s) to call based on the current state and input. For this generation task, you might define placeholder tools if the specifics are not in the JSON.\n",
    "        * Ensure Variable assignment needs to be coherent with the graph state \n",
    "\n",
    "4.  **Graph Construction (`StatefulGraph`):**\n",
    "    * Instantiate `StatefulGraph(GraphState)`.\n",
    "    * Add each implemented node function to the graph using `graph.add_node(\"node_id\", node_function)`.\n",
    "    * Set the graph's entry point using `graph.add_edge(START, \"entry_node_id\")` where `\"entry_node_id\"` is the target of the edge originating from `\"__START__\"`.\n",
    "\n",
    "5.  **Edge Implementation:**\n",
    "    * Iterate through the `edges` list in the JSON.\n",
    "    * **Regular Edges:** If `conditional` is `false`:\n",
    "        * If `target` is `__END__`, use `graph.add_edge(source_node_id, END)`.\n",
    "        * Otherwise, use `graph.add_edge(source_node_id, target_node_id)`.\n",
    "    * **Conditional Edges:** If `conditional` is `true`:\n",
    "        * The `source` node of these conditional edges is expected to produce some output in the `GraphState` (e.g., an `intent` field) that determines the next path.\n",
    "        * Create a separate routing function (e.g., `def route_after_source_node(state: GraphState) -> str:`).\n",
    "        * This routing function must inspect the relevant fields in the `state` and return the string ID of the next node to execute, based on the logic described in the `routing_conditions` for each conditional edge originating from that source.\n",
    "        * Use `graph.add_conditional_edges(source_node_id, routing_function, {{ \"target_id_1\": \"target_id_1\", \"target_id_2\": \"target_id_2\", ... \"__END__\": END }})`. The keys in the dictionary are the possible return values from your routing function, and the values are the actual node IDs or `END`.\n",
    "\n",
    "6.  **Compilation:**\n",
    "    * Instantiate an `InMemoryCheckpointer`: `checkpointer = InMemoryCheckpointer()`.\n",
    "    * Compile the graph: `final_app = graph.compile(checkpointer=checkpointer)`. The compiled graph must be assigned to a variable named `final_app`.\n",
    "\n",
    "---\n",
    "**Phase 3: Required Keys/Credentials Identification**\n",
    "\n",
    "After generating the complete Python script, add a separate section at the end of your response, clearly titled:\n",
    "`## Required Keys and Credentials`\n",
    "\n",
    "In this section, list all environment variables or API keys a user would need to set for the generated code to execute successfully (e.g., `OPENAI_API_KEY`, `GOOGLE_API_KEY`, tool-specific keys). If no external keys are needed, state that.\n",
    "\n",
    "---\n",
    "**Important Considerations (General):**\n",
    "* The primary goal is **compilable, logical, and functionally plausible Python code** that intelligently interprets the JSON input.\n",
    "* Focus on creating a system that leverages LLMs effectively for tasks suited to them.\n",
    "* Ensure node functions correctly update and return relevant parts of the `GraphState`.\n",
    "* If the provided `code` in the JSON uses specific libraries (e.g., `re`), make sure the corresponding import is included at the top of the script.\n",
    "* Handle `__START__` and `__END__` correctly in edge definitions. `langgraph.graph.START` and `langgraph.graph.END` should be used.\n",
    "\n",
    "Here is the JSON input:\n",
    "<json>\n",
    "{code_json}\n",
    "</json>\n",
    "\n",
    "Please generate the Python code and the list of required keys now:\n",
    "\"\"\")\n",
    "\n",
    "def code_node(state: AgentBuilderState):\n",
    "    \"\"\"Produce the final python code\"\"\"\n",
    "    code_ouptut = llm.invoke([HumanMessage(content=CODE_GEN_PROMPT.format(\n",
    "        code_json = state[\"json_code\"]\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated final python code!\")],\n",
    "        \"python_code\": code_ouptut.content,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f46a1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentBuilderState)\n",
    "workflow.add_node(\"requirement_analysis\", requirement_analysis_node)\n",
    "workflow.add_node(\"agent_kernel_builder\", agent_kernel_builder)\n",
    "workflow.add_node(\"code_to_json\", code_to_json_node)\n",
    "workflow.add_node(\"json_update\", json_better_node)\n",
    "workflow.add_node(\"code_node\",code_node)\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: AgentBuilderState):\n",
    "    \n",
    "   \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Requirements generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "workflow.add_edge(\"code_node\", END)\n",
    "workflow.add_edge(\"json_update\", \"code_node\")\n",
    "workflow.add_edge(\"code_to_json\", \"json_update\")\n",
    "workflow.add_edge(\"agent_kernel_builder\", \"code_to_json\")\n",
    "workflow.add_conditional_edges(\"requirement_analysis\", route_state, [\"agent_kernel_builder\", \"requirement_analysis\", END])\n",
    "workflow.add_edge(START, \"requirement_analysis\")\n",
    "infograph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35028943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (q/Q to quit): 1. Primary objective is handle customers, resolve their issues, fetch information for them and conflict to resolution 2. Use cases would be updating customer information, providing customers with the data they ask for, asking customers for their requirements and suggesting them products 3. example 1: input: what is the price of product x? output:  price of x is 300$ example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi Example 3: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accoutning along with, I would also suggest product z which helps with customer out reach and is generally used by customers opening new business and fits your use case\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  AgentInstructions (22067fec-66fe-41da-9b39-e64504a8975e)\n",
      " Call ID: 22067fec-66fe-41da-9b39-e64504a8975e\n",
      "  Args:\n",
      "    examples: example 1: input: what is the price of product x? output: price of x is 300$ example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi Example 3: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accoutning along with, I would also suggest product z which helps with customer out reach and is generally used by customers opening new business and fits your use case\n",
      "    objective: handle customers, resolve their issues, fetch information for them and conflict to resolution\n",
      "    usecases: ['updating customer information', 'providing customers with the data they ask for', 'asking customers for their requirements and suggesting them products']\n",
      "reached here\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "cached_human_responses = [\"hi!\", \"rag prompt\", \"1 rag, 2 none, 3 no, 4 no\", \"red\", \"q\"]\n",
    "cached_response_index = 0\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"User (q/Q to quit): \")\n",
    "    except:\n",
    "        user = cached_human_responses[cached_response_index]\n",
    "        cached_response_index += 1\n",
    "    print(f\"User (q/Q to quit): {user}\")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in infograph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"prompt\" in output:\n",
    "        print(\"Done!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "```json\n",
    "{\n",
    "  \"nodes\": {\n",
    "    \"classify_intent\": {\n",
    "      \"id\": \"classify_intent\",\n",
    "      \"schema_info\": \"GraphState:\\n  type: TypedDict\\n  fields:\\n  - name: input\\n    type: str\\n  - name: output\\n    type: str\\n  - name: intent\\n    type: Optional[str]\\n  - name: customer_data\\n    type: dict\\n  - name: product_catalog\\n    type: dict\",\n",
    "      \"input_schema\": \"GraphState\",\n",
    "      \"output_schema\": \"GraphState\",\n",
    "      \"description\": \"Classifies the intent of the user's input. In a real-world scenario, this function would typically use an LLM (e.g., OpenAI, Anthropic) to perform robust intent classification. For this example, we use simple keyword matching for demonstration.\",\n",
    "      \"function_name\": \"classify_intent\",\n",
    "      \"code\": \"def classify_intent(state: GraphState) -> GraphState:\\n    \\\"\\\"\\\"\\n    Classifies the intent of the user's input.\\n    In a real-world scenario, this function would typically use an LLM\\n    (e.g., OpenAI, Anthropic) to perform robust intent classification.\\n    For this example, we use simple keyword matching for demonstration.\\n    \\\"\\\"\\\"\\n    user_input = state[\\\"input\\\"].lower()\\n    intent = None\\n\\n    if \\\"update\\\" in user_input or \\\"change my address\\\" in user_input:\\n        intent = \\\"update_info\\\"\\n    elif \\\"price of\\\" in user_input or \\\"what is\\\" in user_input or \\\"data\\\" in user_input or \\\"my address\\\" in user_input or \\\"my name\\\" in user_input:\\n        intent = \\\"fetch_data\\\"\\n    elif \\\"bakery\\\" in user_input or \\\"supply chain\\\" in user_input or \\\"billing\\\" in user_input or \\\"need to setup\\\" in user_input:\\n        intent = \\\"product_suggestion\\\"\\n    else:\\n        intent = \\\"unclear\\\" # Fallback for unhandled or ambiguous cases\\n\\n    print(f\\\"---CLASSIFY INTENT---\\\": Input: '{state['input']}' -> Intent: '{intent}'\\\")\\n    return {\\\"intent\\\": intent}\"\n",
    "    },\n",
    "    \"update_customer_info_agent\": {\n",
    "      \"id\": \"update_customer_info_agent\",\n",
    "      \"schema_info\": \"GraphState:\\n  type: TypedDict\\n  fields:\\n  - name: input\\n    type: str\\n  - name: output\\n    type: str\\n  - name: intent\\n    type: Optional[str]\\n  - name: customer_data\\n    type: dict\\n  - name: product_catalog\\n    type: dict\",\n",
    "      \"input_schema\": \"GraphState\",\n",
    "      \"output_schema\": \"GraphState\",\n",
    "      \"description\": \"Handles updating customer information based on the parsed input. This function simulates interaction with a customer database.\",\n",
    "      \"function_name\": \"update_customer_info_agent\",\n",
    "      \"code\": \"def update_customer_info_agent(state: GraphState) -> GraphState:\\n    \\\"\\\"\\\"\\n    Handles updating customer information based on the parsed input.\\n    This function simulates interaction with a customer database.\\n    \\\"\\\"\\\"\\n    user_input = state[\\\"input\\\"]\\n    customer_data = state[\\\"customer_data\\\"].copy() # Create a mutable copy\\n    output = \\\"Could not update information. Please specify what to update.\\\"\\n\\n    # Example: \\\"Please update my address to \\\"delhi\\\"\\\"\\n    # Using regex to extract field and value\\n    match = re.search(r\\\"update my (address|email|name|age) to \\\\\\\"?([a-zA-Z0-9\\\\s]+)\\\\\\\"\\\", user_input, re.IGNORECASE)\\n    if match:\\n        field = match.group(1).lower()\\n        value = match.group(2).strip()\\n        if field in customer_data:\\n            customer_data[field] = value\\n            # Construct output matching example format\\n            output = (f\\\"Address updated, here are your new user details-> \\\"\\n                      f\\\"Name: {customer_data.get('name')}, age {customer_data.get('age')}, \\\"\\n                      f\\\"Address: {customer_data.get('address')}\\\")\\n        else:\\n            output = f\\\"Sorry, I cannot update the field '{field}'. Available fields are name, age, address, email.\\\"\\n    else:\\n        output = \\\"I understand you want to update information, but I couldn't parse the specific details. Could you please rephrase?\\\"\\n\\n    print(f\\\"---UPDATE CUSTOMER INFO AGENT---\\\": Output: '{output}'\\\")\\n    return {\\\"customer_data\\\": customer_data, \\\"output\\\": output}\"\n",
    "    },\n",
    "    \"fetch_info_agent\": {\n",
    "      \"id\": \"fetch_info_agent\",\n",
    "      \"schema_info\": \"GraphState:\\n  type: TypedDict\\n  fields:\\n  - name: input\\n    type: str\\n  - name: output\\n    type: str\\n  - name: intent\\n    type: Optional[str]\\n  - name: customer_data\\n    type: dict\\n  - name: product_catalog\\n    type: dict\",\n",
    "      \"input_schema\": \"GraphState\",\n",
    "      \"output_schema\": \"GraphState\",\n",
    "      \"description\": \"Handles fetching specific information for the customer from mock data.\",\n",
    "      \"function_name\": \"fetch_info_agent\",\n",
    "      \"code\": \"def fetch_info_agent(state: GraphState) -> GraphState:\\n    \\\"\\\"\\\"\\n    Handles fetching specific information for the customer from mock data.\\n    \\\"\\\"\\\"\\n    user_input = state[\\\"input\\\"].lower()\\n    customer_data = state[\\\"customer_data\\\"]\\n    output = \\\"I couldn't find the information you asked for.\\\"\\n\\n    if \\\"price of product x\\\" in user_input:\\n        price = customer_data.get(\\\"product_x_price\\\")\\n        if price:\\n            output = f\\\"price of x is {price}$\\\"\\n    elif \\\"price of product y\\\" in user_input:\\n        price = customer_data.get(\\\"product_y_price\\\")\\n        if price:\\n            output = f\\\"price of y is {price}$\\\"\\n    elif \\\"price of product z\\\" in user_input:\\n        price = customer_data.get(\\\"product_z_price\\\")\\n        if price:\\n            output = f\\\"price of z is {price}$\\\"\\n    elif \\\"my address\\\" in user_input:\\n        address = customer_data.get(\\\"address\\\")\\n        if address:\\n            output = f\\\"Your current address is: {address}\\\"\\n    elif \\\"my name\\\" in user_input:\\n        name = customer_data.get(\\\"name\\\")\\n        if name:\\n            output = f\\\"Your name is: {name}\\\"\\n    else:\\n        output = \\\"I can fetch information about product prices or your personal details like address and name. What specific information are you looking for?\\\"\\n\\n    print(f\\\"---FETCH INFO AGENT---\\\": Output: '{output}'\\\")\\n    return {\\\"output\\\": output}\"\n",
    "    },\n",
    "    \"product_suggestion_agent\": {\n",
    "      \"id\": \"product_suggestion_agent\",\n",
    "      \"schema_info\": \"GraphState:\\n  type: TypedDict\\n  fields:\\n  - name: input\\n    type: str\\n  - name: output\\n    type: str\\n  - name: intent\\n    type: Optional[str]\\n  - name: customer_data\\n    type: dict\\n  - name: product_catalog\\n    type: dict\",\n",
    "      \"input_schema\": \"GraphState\",\n",
    "      \"output_schema\": \"GraphState\",\n",
    "      \"description\": \"Asks customers for their requirements and suggests products from the catalog. This function simulates a recommendation engine or a sales agent.\",\n",
    "      \"function_name\": \"product_suggestion_agent\",\n",
    "      \"code\": \"def product_suggestion_agent(state: GraphState) -> GraphState:\\n    \\\"\\\"\\\"\\n    Asks customers for their requirements and suggests products from the catalog.\\n    This function simulates a recommendation engine or a sales agent.\\n    \\\"\\\"\\\"\\n    user_input = state[\\\"input\\\"].lower()\\n    product_catalog = state[\\\"product_catalog\\\"]\\n    output = \\\"I can help you find products. Please tell me more about your needs.\\\"\\n\\n    # Example: \\\"I am opening up a bakery and need to setup my supply chain and billing\\\"\\n    suggested_products_info = []\\n    if \\\"supply chain\\\" in user_input:\\n        if \\\"product x\\\" in product_catalog:\\n            suggested_products_info.append(product_catalog[\\\"product x\\\"])\\n    if \\\"billing\\\" in user_input:\\n        if \\\"product y\\\" in product_catalog:\\n            suggested_products_info.append(product_catalog[\\\"product y\\\"])\\n\\n    # Always suggest product z as it fits \\\"new business\\\" and \\\"customer outreach\\\"\\n    if \\\"product z\\\" in product_catalog and product_catalog[\\\"product z\\\"] not in suggested_products_info:\\n        suggested_products_info.append(product_catalog[\\\"product z\\\"])\\n\\n    if suggested_products_info:\\n        product_phrases = []\\n        for p_info in suggested_products_info:\\n            # Format: \\\"product x that will output your supply chain monitoring\\\"\\n            product_phrases.append(f\\\"product {p_info['name'].lower().replace('product ', '')} that {p_info['description'].lower()}\\\")\\n\\n        # Construct the output string to match the example closely\\n        if len(product_phrases) > 1:\\n            # Separate the last product for \\\"along with, I would also suggest\\\"\\n            last_product_phrase = product_phrases.pop()\\n            output = \\\"We have \\\" + \\\", \\\".join(product_phrases)\\n            output += f\\\" along with, I would also suggest {last_product_phrase} and fits your use case\\\"\\n        else:\\n            output = f\\\"We have {product_phrases[0]} and fits your use case\\\"\\n\\n        # Add the general \\\"used by customers opening new business\\\" part if product z was suggested\\n        if any(p['name'] == 'Product Z' for p in suggested_products_info):\\n            output = output.replace(\\\"and fits your use case\\\", \\\"and is generally used by customers opening new business and fits your use case\\\")\\n\\n    else:\\n        output = \\\"Based on your requirements, I couldn't find specific products. Could you elaborate?\\\"\\n\\n    print(f\\\"---PRODUCT SUGGESTION AGENT---\\\": Output: '{output}'\\\")\\n    return {\\\"output\\\": output}\"\n",
    "    }\n",
    "  },\n",
    "  \"edges\": [\n",
    "    {\n",
    "      \"source\": \"__START__\",\n",
    "      \"target\": \"classify_intent\",\n",
    "      \"routing_conditions\": \"This is the entry point of the graph, routing initial user input to the intent classification node.\",\n",
    "      \"conditional\": false\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"classify_intent\",\n",
    "      \"target\": \"update_customer_info_agent\",\n",
    "      \"routing_conditions\": \"If the classified intent is 'update_info'.\",\n",
    "      \"conditional\": true\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"classify_intent\",\n",
    "      \"target\": \"fetch_info_agent\",\n",
    "      \"routing_conditions\": \"If the classified intent is 'fetch_data' or if the intent is 'unclear' (fallback).\",\n",
    "      \"conditional\": true\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"classify_intent\",\n",
    "      \"target\": \"product_suggestion_agent\",\n",
    "      \"routing_conditions\": \"If the classified intent is 'product_suggestion'.\",\n",
    "      \"conditional\": true\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"update_customer_info_agent\",\n",
    "      \"target\": \"__END__\",\n",
    "      \"routing_conditions\": \"The task of updating customer information is complete.\",\n",
    "      \"conditional\": false\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"fetch_info_agent\",\n",
    "      \"target\": \"__END__\",\n",
    "      \"routing_conditions\": \"The task of fetching information is complete.\",\n",
    "      \"conditional\": false\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"product_suggestion_agent\",\n",
    "      \"target\": \"__END__\",\n",
    "      \"routing_conditions\": \"The task of providing product suggestions is complete.\",\n",
    "      \"conditional\": false\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1838dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "To design the `langgraph` `StateGraph` object, we will implement an architecture that routes user queries to specialized \"agents\" based on the detected intent.\n",
    "\n",
    "**Architecture Overview:**\n",
    "\n",
    "1.  **State Definition (`GraphState`)**: A `TypedDict` to hold the current state of the conversation, including the user's input, the generated output, the classified intent, and mock customer/product data.\n",
    "2.  **Nodes**:\n",
    "    *   `classify_intent`: An initial node that analyzes the user's input to determine the primary intent (e.g., update info, fetch data, product suggestion). In a real application, this would typically involve an LLM call. For this example, it uses simple keyword matching.\n",
    "    *   `update_customer_info_agent`: Handles requests to modify customer details.\n",
    "    *   `fetch_info_agent`: Retrieves specific information for the customer.\n",
    "    *   `product_suggestion_agent`: Recommends products based on user requirements.\n",
    "3.  **Conditional Routing**: After `classify_intent`, a conditional edge will direct the flow to the appropriate agent node.\n",
    "4.  **End Node**: All agent nodes will lead to the `END` of the graph, signifying the completion of the task.\n",
    "\n",
    "**Detailed Implementation:**\n",
    "\n",
    "```python\n",
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "import re # For parsing updates in the update_customer_info_agent\n",
    "\n",
    "# 1. Define the Graph State\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        input: The user's initial query.\n",
    "        output: The response generated by an agent.\n",
    "        intent: The classified intent of the user's query (e.g., \"update_info\", \"fetch_data\", \"product_suggestion\").\n",
    "        customer_data: A dictionary simulating customer information, mutable across nodes.\n",
    "        product_catalog: A dictionary simulating available products, immutable for agents.\n",
    "    \"\"\"\n",
    "    input: str\n",
    "    output: str\n",
    "    intent: Optional[str]\n",
    "    customer_data: dict\n",
    "    product_catalog: dict\n",
    "\n",
    "# Mock data for demonstration purposes\n",
    "MOCK_CUSTOMER_DATA = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 30,\n",
    "    \"address\": \"123 Main St, Anytown\",\n",
    "    \"email\": \"john.doe@example.com\",\n",
    "    \"product_x_price\": 300,\n",
    "    \"product_y_price\": 500,\n",
    "    \"product_z_price\": 100\n",
    "}\n",
    "\n",
    "MOCK_PRODUCT_CATALOG = {\n",
    "    \"product x\": {\n",
    "        \"name\": \"Product X\",\n",
    "        \"description\": \"will output your supply chain monitoring\",\n",
    "        \"price\": 300\n",
    "    },\n",
    "    \"product y\": {\n",
    "        \"name\": \"Product Y\",\n",
    "        \"description\": \"would automate your billing and accounting\",\n",
    "        \"price\": 500\n",
    "    },\n",
    "    \"product z\": {\n",
    "        \"name\": \"Product Z\",\n",
    "        \"description\": \"helps with customer outreach and is generally used by customers opening new business\",\n",
    "        \"price\": 100\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Define the Nodes (Functions)\n",
    "\n",
    "def classify_intent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Classifies the intent of the user's input.\n",
    "    In a real-world scenario, this function would typically use an LLM\n",
    "    (e.g., OpenAI, Anthropic) to perform robust intent classification.\n",
    "    For this example, we use simple keyword matching for demonstration.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"].lower()\n",
    "    intent = None\n",
    "\n",
    "    if \"update\" in user_input or \"change my address\" in user_input:\n",
    "        intent = \"update_info\"\n",
    "    elif \"price of\" in user_input or \"what is\" in user_input or \"data\" in user_input or \"my address\" in user_input or \"my name\" in user_input:\n",
    "        intent = \"fetch_data\"\n",
    "    elif \"bakery\" in user_input or \"supply chain\" in user_input or \"billing\" in user_input or \"need to setup\" in user_input:\n",
    "        intent = \"product_suggestion\"\n",
    "    else:\n",
    "        intent = \"unclear\" # Fallback for unhandled or ambiguous cases\n",
    "\n",
    "    print(f\"---CLASSIFY INTENT---: Input: '{state['input']}' -> Intent: '{intent}'\")\n",
    "    return {\"intent\": intent}\n",
    "\n",
    "def update_customer_info_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Handles updating customer information based on the parsed input.\n",
    "    This function simulates interaction with a customer database.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"]\n",
    "    customer_data = state[\"customer_data\"].copy() # Create a mutable copy\n",
    "    output = \"Could not update information. Please specify what to update.\"\n",
    "\n",
    "    # Example: \"Please update my address to \"delhi\"\"\n",
    "    # Using regex to extract field and value\n",
    "    match = re.search(r\"update my (address|email|name|age) to \\\"?([a-zA-Z0-9\\s]+)\\\"?\", user_input, re.IGNORECASE)\n",
    "    if match:\n",
    "        field = match.group(1).lower()\n",
    "        value = match.group(2).strip()\n",
    "        if field in customer_data:\n",
    "            customer_data[field] = value\n",
    "            # Construct output matching example format\n",
    "            output = (f\"Address updated, here are your new user details-> \"\n",
    "                      f\"Name: {customer_data.get('name')}, age {customer_data.get('age')}, \"\n",
    "                      f\"Address: {customer_data.get('address')}\")\n",
    "        else:\n",
    "            output = f\"Sorry, I cannot update the field '{field}'. Available fields are name, age, address, email.\"\n",
    "    else:\n",
    "        output = \"I understand you want to update information, but I couldn't parse the specific details. Could you please rephrase?\"\n",
    "\n",
    "    print(f\"---UPDATE CUSTOMER INFO AGENT---: Output: '{output}'\")\n",
    "    return {\"customer_data\": customer_data, \"output\": output}\n",
    "\n",
    "def fetch_info_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Handles fetching specific information for the customer from mock data.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"].lower()\n",
    "    customer_data = state[\"customer_data\"]\n",
    "    output = \"I couldn't find the information you asked for.\"\n",
    "\n",
    "    if \"price of product x\" in user_input:\n",
    "        price = customer_data.get(\"product_x_price\")\n",
    "        if price:\n",
    "            output = f\"price of x is {price}$\"\n",
    "    elif \"price of product y\" in user_input:\n",
    "        price = customer_data.get(\"product_y_price\")\n",
    "        if price:\n",
    "            output = f\"price of y is {price}$\"\n",
    "    elif \"price of product z\" in user_input:\n",
    "        price = customer_data.get(\"product_z_price\")\n",
    "        if price:\n",
    "            output = f\"price of z is {price}$\"\n",
    "    elif \"my address\" in user_input:\n",
    "        address = customer_data.get(\"address\")\n",
    "        if address:\n",
    "            output = f\"Your current address is: {address}\"\n",
    "    elif \"my name\" in user_input:\n",
    "        name = customer_data.get(\"name\")\n",
    "        if name:\n",
    "            output = f\"Your name is: {name}\"\n",
    "    else:\n",
    "        output = \"I can fetch information about product prices or your personal details like address and name. What specific information are you looking for?\"\n",
    "\n",
    "    print(f\"---FETCH INFO AGENT---: Output: '{output}'\")\n",
    "    return {\"output\": output}\n",
    "\n",
    "def product_suggestion_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Asks customers for their requirements and suggests products from the catalog.\n",
    "    This function simulates a recommendation engine or a sales agent.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"].lower()\n",
    "    product_catalog = state[\"product_catalog\"]\n",
    "    output = \"I can help you find products. Please tell me more about your needs.\"\n",
    "\n",
    "    # Example: \"I am opening up a bakery and need to setup my supply chain and billing\"\n",
    "    suggested_products_info = []\n",
    "    if \"supply chain\" in user_input:\n",
    "        if \"product x\" in product_catalog:\n",
    "            suggested_products_info.append(product_catalog[\"product x\"])\n",
    "    if \"billing\" in user_input:\n",
    "        if \"product y\" in product_catalog:\n",
    "            suggested_products_info.append(product_catalog[\"product y\"])\n",
    "\n",
    "    # Always suggest product z as it fits \"new business\" and \"customer outreach\"\n",
    "    if \"product z\" in product_catalog and product_catalog[\"product z\"] not in suggested_products_info:\n",
    "        suggested_products_info.append(product_catalog[\"product z\"])\n",
    "\n",
    "    if suggested_products_info:\n",
    "        product_phrases = []\n",
    "        for p_info in suggested_products_info:\n",
    "            # Format: \"product x that will output your supply chain monitoring\"\n",
    "            product_phrases.append(f\"product {p_info['name'].lower().replace('product ', '')} that {p_info['description'].lower()}\")\n",
    "\n",
    "        # Construct the output string to match the example closely\n",
    "        if len(product_phrases) > 1:\n",
    "            # Separate the last product for \"along with, I would also suggest\"\n",
    "            last_product_phrase = product_phrases.pop()\n",
    "            output = \"We have \" + \", \".join(product_phrases)\n",
    "            output += f\" along with, I would also suggest {last_product_phrase} and fits your use case\"\n",
    "        else:\n",
    "            output = f\"We have {product_phrases[0]} and fits your use case\"\n",
    "\n",
    "        # Add the general \"used by customers opening new business\" part if product z was suggested\n",
    "        if any(p['name'] == 'Product Z' for p in suggested_products_info):\n",
    "            output = output.replace(\"and fits your use case\", \"and is generally used by customers opening new business and fits your use case\")\n",
    "\n",
    "    else:\n",
    "        output = \"Based on your requirements, I couldn't find specific products. Could you elaborate?\"\n",
    "\n",
    "    print(f\"---PRODUCT SUGGESTION AGENT---: Output: '{output}'\")\n",
    "    return {\"output\": output}\n",
    "\n",
    "# 3. Define the Conditional Edge Logic\n",
    "def route_to_agent(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Routes the execution based on the classified intent.\n",
    "    \"\"\"\n",
    "    intent = state[\"intent\"]\n",
    "    if intent == \"update_info\":\n",
    "        return \"update_customer_info_agent\"\n",
    "    elif intent == \"fetch_data\":\n",
    "        return \"fetch_info_agent\"\n",
    "    elif intent == \"product_suggestion\":\n",
    "        return \"product_suggestion_agent\"\n",
    "    else:\n",
    "        # Fallback for unclear intent: could route to a \"clarify_agent\"\n",
    "        # For this example, we'll route to fetch_info_agent as a general fallback.\n",
    "        print(\"---ROUTER---: Intent unclear, routing to fetch_info_agent as a default fallback.\")\n",
    "        return \"fetch_info_agent\"\n",
    "\n",
    "# 4. Build the StateGraph\n",
    "def create_customer_service_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Creates and compiles the StateGraph for customer service operations.\n",
    "    \"\"\"\n",
    "    workflow = StateGraph(GraphState)\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    workflow.add_node(\"classify_intent\", classify_intent)\n",
    "    workflow.add_node(\"update_customer_info_agent\", update_customer_info_agent)\n",
    "    workflow.add_node(\"fetch_info_agent\", fetch_info_agent)\n",
    "    workflow.add_node(\"product_suggestion_agent\", product_suggestion_agent)\n",
    "\n",
    "    # Set the entry point for the graph\n",
    "    workflow.set_entry_point(\"classify_intent\")\n",
    "\n",
    "    # Add conditional edges from the classify_intent node\n",
    "    workflow.add_conditional_edges(\n",
    "        \"classify_intent\",\n",
    "        route_to_agent,\n",
    "        {\n",
    "            \"update_customer_info_agent\": \"update_customer_info_agent\",\n",
    "            \"fetch_info_agent\": \"fetch_info_agent\",\n",
    "            \"product_suggestion_agent\": \"product_suggestion_agent\",\n",
    "            # If you had an \"unclear_intent_agent\", you'd add it here:\n",
    "            # \"unclear_intent_agent\": \"unclear_intent_agent\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add direct edges from each agent node to the END node\n",
    "    workflow.add_edge(\"update_customer_info_agent\", END)\n",
    "    workflow.add_edge(\"fetch_info_agent\", END)\n",
    "    workflow.add_edge(\"product_suggestion_agent\", END)\n",
    "\n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "    return app\n",
    "\n",
    "# Compile the StateGraph object\n",
    "compiled_customer_service_graph = create_customer_service_graph()\n",
    "\n",
    "# Example Usage (for testing the compiled graph)\n",
    "if __name__ == \"__main__\":\n",
    "    # Initial state for the graph execution\n",
    "    initial_state = {\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"\",\n",
    "        \"intent\": None,\n",
    "        \"customer_data\": MOCK_CUSTOMER_DATA.copy(), # Use a copy to avoid modifying global mock data\n",
    "        \"product_catalog\": MOCK_PRODUCT_CATALOG\n",
    "    }\n",
    "\n",
    "    print(\"--- Running Example 1: Fetch Information ---\")\n",
    "    ex1_state = initial_state.copy()\n",
    "    ex1_state[\"input\"] = \"what is the price of product x?\"\n",
    "    result1 = compiled_customer_service_graph.invoke(ex1_state)\n",
    "    print(f\"Final Output 1: {result1['output']}\\n\")\n",
    "    # Expected: price of x is 300$\n",
    "\n",
    "    print(\"--- Running Example 2: Update Customer Information ---\")\n",
    "    ex2_state = initial_state.copy()\n",
    "    ex2_state[\"input\"] = 'Please update my address to \"delhi\"'\n",
    "    result2 = compiled_customer_service_graph.invoke(ex2_state)\n",
    "    print(f\"Final Output 2: {result2['output']}\")\n",
    "    print(f\"Updated Customer Data 2: {result2['customer_data']}\\n\")\n",
    "    # Expected: Address updated, here are your new user details-> Name: John Doe, age 30, Address: delhi\n",
    "\n",
    "    print(\"--- Running Example 3: Product Suggestion ---\")\n",
    "    ex3_state = initial_state.copy()\n",
    "    ex3_state[\"input\"] = \"I am opening up a bakery and need to setup my supply chain and billing\"\n",
    "    result3 = compiled_customer_service_graph.invoke(ex3_state)\n",
    "    print(f\"Final Output 3: {result3['output']}\\n\")\n",
    "    # Expected: We have product x that will output your supply chain monitoring, product y that would automate your billing and accounting along with, I would also suggest product z which helps with customer outreach and is generally used by customers opening new business and fits your use case\n",
    "\n",
    "    print(\"--- Running Example 4: Fetch Customer Address ---\")\n",
    "    ex4_state = initial_state.copy()\n",
    "    ex4_state[\"input\"] = \"What is my current address?\"\n",
    "    result4 = compiled_customer_service_graph.invoke(ex4_state)\n",
    "    print(f\"Final Output 4: {result4['output']}\\n\")\n",
    "\n",
    "    print(\"--- Running Example 5: Unclear Intent (Fallback) ---\")\n",
    "    ex5_state = initial_state.copy()\n",
    "    ex5_state[\"input\"] = \"Tell me a joke.\"\n",
    "    result5 = compiled_customer_service_graph.invoke(ex5_state)\n",
    "    print(f\"Final Output 5: {result5['output']}\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import re\n",
    "from typing import TypedDict, Optional, Dict, Any\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemoryCheckpointer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the GraphState\n",
    "# Parsed from schema_info:\n",
    "# GraphState:\n",
    "#   type: TypedDict\n",
    "#   fields:\n",
    "#   - name: input\n",
    "#     type: str\n",
    "#   - name: output\n",
    "#     type: str\n",
    "#   - name: intent\n",
    "#     type: Optional[str]\n",
    "#   - name: customer_data\n",
    "#     type: dict\n",
    "#   - name: product_catalog\n",
    "#     type: dict\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        input: The user's initial input string.\n",
    "        output: The response generated by the agent.\n",
    "        intent: The classified intent of the user's input (e.g., \"update_info\", \"fetch_data\").\n",
    "        customer_data: A dictionary holding mock customer information.\n",
    "        product_catalog: A dictionary holding mock product information.\n",
    "    \"\"\"\n",
    "    input: str\n",
    "    output: str\n",
    "    intent: Optional[str]\n",
    "    customer_data: Dict[str, Any]\n",
    "    product_catalog: Dict[str, Any]\n",
    "\n",
    "# --- Node Implementations ---\n",
    "\n",
    "def classify_intent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Classifies the intent of the user's input using an LLM.\n",
    "    This replaces the simple keyword matching with a more robust LLM-based classification.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"]\n",
    "    \n",
    "    # Initialize LLM\n",
    "    # TODO: Replace with specific model and API key if needed\n",
    "    # Ensure OPENAI_API_KEY environment variable is set or pass it directly.\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0) \n",
    "\n",
    "    # Define the prompt for intent classification\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert intent classifier. Classify the user's input into one of the following categories:\\n\"\n",
    "                \"- 'update_info': If the user wants to change or update their personal information (e.g., address, name, email).\\n\"\n",
    "                \"- 'fetch_data': If the user wants to retrieve specific information (e.g., product prices, their address, their name).\\n\"\n",
    "                \"- 'product_suggestion': If the user is asking for product recommendations or solutions for a business need.\\n\"\n",
    "                \"- 'unclear': If the intent is ambiguous or does not fit the above categories.\\n\"\n",
    "                \"Respond with only the intent category string (e.g., 'update_info', 'fetch_data', 'product_suggestion', 'unclear').\"\n",
    "            ),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create a chain to classify intent\n",
    "    intent_classifier_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        # Invoke the LLM to get the intent\n",
    "        raw_intent = intent_classifier_chain.invoke({\"input\": user_input}).strip().lower()\n",
    "        \n",
    "        # Validate and map the LLM's output to expected intents\n",
    "        valid_intents = [\"update_info\", \"fetch_data\", \"product_suggestion\", \"unclear\"]\n",
    "        if raw_intent in valid_intents:\n",
    "            intent = raw_intent\n",
    "        else:\n",
    "            intent = \"unclear\" # Fallback if LLM returns an unexpected string\n",
    "            print(f\"Warning: LLM returned unexpected intent '{raw_intent}'. Falling back to 'unclear'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM intent classification: {e}. Falling back to 'unclear'.\")\n",
    "        intent = \"unclear\" # Fallback in case of API errors\n",
    "\n",
    "    print(f\"---CLASSIFY INTENT---: Input: '{state['input']}' -> Intent: '{intent}'\")\n",
    "    return {\"intent\": intent}\n",
    "\n",
    "def update_customer_info_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Handles updating customer information based on the parsed input.\n",
    "    This function simulates interaction with a customer database.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"]\n",
    "    customer_data = state[\"customer_data\"].copy() # Create a mutable copy\n",
    "    output = \"Could not update information. Please specify what to update.\"\n",
    "\n",
    "    # Example: \"Please update my address to \"delhi\"\"\n",
    "    # Using regex to extract field and value\n",
    "    match = re.search(r\"update my (address|email|name|age) to \\\"?([a-zA-Z0-9\\s]+)\\\"?\", user_input, re.IGNORECASE)\n",
    "    if match:\n",
    "        field = match.group(1).lower()\n",
    "        value = match.group(2).strip()\n",
    "        if field in customer_data:\n",
    "            customer_data[field] = value\n",
    "            # Construct output matching example format\n",
    "            output = (f\"Address updated, here are your new user details-> \"\n",
    "                      f\"Name: {customer_data.get('name')}, age {customer_data.get('age')}, \"\n",
    "                      f\"Address: {customer_data.get('address')}\")\n",
    "        else:\n",
    "            output = f\"Sorry, I cannot update the field '{field}'. Available fields are name, age, address, email.\"\n",
    "    else:\n",
    "        output = \"I understand you want to update information, but I couldn't parse the specific details. Could you please rephrase?\"\n",
    "\n",
    "    print(f\"---UPDATE CUSTOMER INFO AGENT---: Output: '{output}'\")\n",
    "    return {\"customer_data\": customer_data, \"output\": output}\n",
    "\n",
    "def fetch_info_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Handles fetching specific information for the customer from mock data.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"].lower()\n",
    "    customer_data = state[\"customer_data\"]\n",
    "    output = \"I couldn't find the information you asked for.\"\n",
    "\n",
    "    if \"price of product x\" in user_input:\n",
    "        price = customer_data.get(\"product_x_price\")\n",
    "        if price:\n",
    "            output = f\"price of x is {price}$\"\n",
    "    elif \"price of product y\" in user_input:\n",
    "        price = customer_data.get(\"product_y_price\")\n",
    "        if price:\n",
    "            output = f\"price of y is {price}$\"\n",
    "    elif \"price of product z\" in user_input:\n",
    "        price = customer_data.get(\"product_z_price\")\n",
    "        if price:\n",
    "            output = f\"price of z is {price}$\"\n",
    "    elif \"my address\" in user_input:\n",
    "        address = customer_data.get(\"address\")\n",
    "        if address:\n",
    "            output = f\"Your current address is: {address}\"\n",
    "    elif \"my name\" in user_input:\n",
    "        name = customer_data.get(\"name\")\n",
    "        if name:\n",
    "            output = f\"Your name is: {name}\"\n",
    "    else:\n",
    "        output = \"I can fetch information about product prices or your personal details like address and name. What specific information are you looking for?\"\n",
    "\n",
    "    print(f\"---FETCH INFO AGENT---: Output: '{output}'\")\n",
    "    return {\"output\": output}\n",
    "\n",
    "def product_suggestion_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Asks customers for their requirements and suggests products from the catalog.\n",
    "    This function simulates a recommendation engine or a sales agent.\n",
    "    \"\"\"\n",
    "    user_input = state[\"input\"].lower()\n",
    "    product_catalog = state[\"product_catalog\"]\n",
    "    output = \"I can help you find products. Please tell me more about your needs.\"\n",
    "\n",
    "    # Example: \"I am opening up a bakery and need to setup my supply chain and billing\"\n",
    "    suggested_products_info = []\n",
    "    if \"supply chain\" in user_input:\n",
    "        if \"product x\" in product_catalog:\n",
    "            suggested_products_info.append(product_catalog[\"product x\"])\n",
    "    if \"billing\" in user_input:\n",
    "        if \"product y\" in product_catalog:\n",
    "            suggested_products_info.append(product_catalog[\"product y\"])\n",
    "\n",
    "    # Always suggest product z as it fits \"new business\" and \"customer outreach\"\n",
    "    if \"product z\" in product_catalog and product_catalog[\"product z\"] not in suggested_products_info:\n",
    "        suggested_products_info.append(product_catalog[\"product z\"])\n",
    "\n",
    "    if suggested_products_info:\n",
    "        product_phrases = []\n",
    "        for p_info in suggested_products_info:\n",
    "            # Format: \"product x that will output your supply chain monitoring\"\n",
    "            product_phrases.append(f\"product {p_info['name'].lower().replace('product ', '')} that {p_info['description'].lower()}\")\n",
    "\n",
    "        # Construct the output string to match the example closely\n",
    "        if len(product_phrases) > 1:\n",
    "            # Separate the last product for \"along with, I would also suggest\"\n",
    "            last_product_phrase = product_phrases.pop()\n",
    "            output = \"We have \" + \", \".join(product_phrases)\n",
    "            output += f\" along with, I would also suggest {last_product_phrase} and fits your use case\"\n",
    "        else:\n",
    "            output = f\"We have {product_phrases[0]} and fits your use case\"\n",
    "\n",
    "        # Add the general \"used by customers opening new business\" part if product z was suggested\n",
    "        if any(p['name'] == 'Product Z' for p in suggested_products_info):\n",
    "            output = output.replace(\"and fits your use case\", \"and is generally used by customers opening new business and fits your use case\")\n",
    "\n",
    "    else:\n",
    "        output = \"Based on your requirements, I couldn't find specific products. Could you elaborate?\"\n",
    "\n",
    "    print(f\"---PRODUCT SUGGESTION AGENT---: Output: '{output}'\")\n",
    "    return {\"output\": output}\n",
    "\n",
    "# --- Routing Function ---\n",
    "\n",
    "def route_intent(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Routes the graph based on the classified intent.\n",
    "    \"\"\"\n",
    "    intent = state.get(\"intent\")\n",
    "    if intent == \"update_info\":\n",
    "        print(\"---ROUTING---: Intent 'update_info' -> update_customer_info_agent\")\n",
    "        return \"update_customer_info_agent\"\n",
    "    elif intent == \"fetch_data\":\n",
    "        print(\"---ROUTING---: Intent 'fetch_data' -> fetch_info_agent\")\n",
    "        return \"fetch_info_agent\"\n",
    "    elif intent == \"product_suggestion\":\n",
    "        print(\"---ROUTING---: Intent 'product_suggestion' -> product_suggestion_agent\")\n",
    "        return \"product_suggestion_agent\"\n",
    "    else: # Handles \"unclear\" and any other unexpected intent\n",
    "        print(\"---ROUTING---: Intent 'unclear' or unhandled -> fetch_info_agent (fallback)\")\n",
    "        return \"fetch_info_agent\" # Fallback to fetch_info_agent for unclear cases\n",
    "\n",
    "# --- Graph Construction ---\n",
    "\n",
    "# Define the graph\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"classify_intent\", classify_intent)\n",
    "graph.add_node(\"update_customer_info_agent\", update_customer_info_agent)\n",
    "graph.add_node(\"fetch_info_agent\", fetch_info_agent)\n",
    "graph.add_node(\"product_suggestion_agent\", product_suggestion_agent)\n",
    "\n",
    "# Set entry point\n",
    "graph.add_edge(START, \"classify_intent\")\n",
    "\n",
    "# Add conditional edges from classify_intent\n",
    "graph.add_conditional_edges(\n",
    "    \"classify_intent\",\n",
    "    route_intent,\n",
    "    {\n",
    "        \"update_customer_info_agent\": \"update_customer_info_agent\",\n",
    "        \"fetch_info_agent\": \"fetch_info_agent\",\n",
    "        \"product_suggestion_agent\": \"product_suggestion_agent\",\n",
    "        # The routing function handles \"unclear\" by returning \"fetch_info_agent\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add direct edges to END\n",
    "graph.add_edge(\"update_customer_info_agent\", END)\n",
    "graph.add_edge(\"fetch_info_agent\", END)\n",
    "graph.add_edge(\"product_suggestion_agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = InMemoryCheckpointer()\n",
    "final_app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# --- Example Usage (Optional, for testing) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Mock initial data for customer and product catalog\n",
    "    initial_customer_data = {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"age\": 30,\n",
    "        \"address\": \"123 Main St, Anytown\",\n",
    "        \"email\": \"john.doe@example.com\",\n",
    "        \"product_x_price\": 100,\n",
    "        \"product_y_price\": 250,\n",
    "        \"product_z_price\": 500\n",
    "    }\n",
    "\n",
    "    initial_product_catalog = {\n",
    "        \"product x\": {\n",
    "            \"name\": \"Product X\",\n",
    "            \"description\": \"will output your supply chain monitoring\"\n",
    "        },\n",
    "        \"product y\": {\n",
    "            \"name\": \"Product Y\",\n",
    "            \"description\": \"will help you with your billing and invoicing\"\n",
    "        },\n",
    "        \"product z\": {\n",
    "            \"name\": \"Product Z\",\n",
    "            \"description\": \"is designed for customer outreach and new business setup\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Running example 1: Update Info ---\")\n",
    "    inputs_1 = {\n",
    "        \"input\": \"Please update my address to \\\"456 Oak Ave, New City\\\"\",\n",
    "        \"customer_data\": initial_customer_data,\n",
    "        \"product_catalog\": initial_product_catalog\n",
    "    }\n",
    "    for s in final_app.stream(inputs_1):\n",
    "        print(s)\n",
    "    print(f\"Final State 1: {final_app.get_state(None).values['output']}\")\n",
    "    print(f\"Updated Customer Data 1: {final_app.get_state(None).values['customer_data']}\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Running example 2: Fetch Info ---\")\n",
    "    inputs_2 = {\n",
    "        \"input\": \"What is the price of product y?\",\n",
    "        \"customer_data\": initial_customer_data,\n",
    "        \"product_catalog\": initial_product_catalog\n",
    "    }\n",
    "    for s in final_app.stream(inputs_2):\n",
    "        print(s)\n",
    "    print(f\"Final State 2: {final_app.get_state(None).values['output']}\")\n",
    "\n",
    "    print(\"\\n--- Running example 3: Product Suggestion ---\")\n",
    "    inputs_3 = {\n",
    "        \"input\": \"I am opening up a bakery and need to setup my supply chain and billing\",\n",
    "        \"customer_data\": initial_customer_data,\n",
    "        \"product_catalog\": initial_product_catalog\n",
    "    }\n",
    "    for s in final_app.stream(inputs_3):\n",
    "        print(s)\n",
    "    print(f\"Final State 3: {final_app.get_state(None).values['output']}\")\n",
    "\n",
    "    print(\"\\n--- Running example 4: Unclear Intent (should fallback to fetch_info_agent) ---\")\n",
    "    inputs_4 = {\n",
    "        \"input\": \"Tell me about the weather.\",\n",
    "        \"customer_data\": initial_customer_data,\n",
    "        \"product_catalog\": initial_product_catalog\n",
    "    }\n",
    "    for s in final_app.stream(inputs_4):\n",
    "        print(s)\n",
    "    print(f\"Final State 4: {final_app.get_state(None).values['output']}\")\n",
    "\n",
    "    print(\"\\n--- Running example 5: Fetch My Address ---\")\n",
    "    inputs_5 = {\n",
    "        \"input\": \"Can you tell me my address?\",\n",
    "        \"customer_data\": initial_customer_data,\n",
    "        \"product_catalog\": initial_product_catalog\n",
    "    }\n",
    "    for s in final_app.stream(inputs_5):\n",
    "        print(s)\n",
    "    print(f\"Final State 5: {final_app.get_state(None).values['output']}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Literal, Optional, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemoryCheckpointer\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "# TODO: Set your OpenAI API key as an environment variable: OPENAI_API_KEY\n",
    "# For example: os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\n",
    "# Or pass it directly to ChatOpenAI(api_key=\"...\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) # Using a smaller, faster model for routing and extraction\n",
    "\n",
    "# --- Phase 1: Graph Architecture Analysis & Strategy ---\n",
    "# This graph implements a \"Router-Agent\" or \"Agent Supervisor\" architecture.\n",
    "# Justification:\n",
    "# 1.  **Intent Routing**: The `intent_router` node acts as a central supervisor,\n",
    "#     classifying the user's initial input and dynamically routing it to\n",
    "#     specialized \"worker\" nodes (`log_diet`, `log_workout`, `analyze_workout`).\n",
    "#     This is a classic pattern for dispatching tasks based on user intent.\n",
    "# 2.  **Specialized Agents**: Each action node (`log_diet`, `log_workout`, `analyze_workout`)\n",
    "#     is designed to handle a specific type of task, leveraging LLMs for\n",
    "#     structured data extraction and intelligent analysis. This modularity\n",
    "#     is characteristic of agentic workflows.\n",
    "# 3.  **Unified Response Generation**: A final `generate_response` node consolidates\n",
    "#     outputs from various action paths, ensuring a consistent user experience.\n",
    "# This architecture allows for clear separation of concerns and easy extension\n",
    "# with new capabilities.\n",
    "\n",
    "# --- Phase 2: Python Code Generation ---\n",
    "\n",
    "# 1. State Definition\n",
    "class FoodItem(TypedDict):\n",
    "    name: str\n",
    "    calories: int\n",
    "    meal_type: str  # e.g., breakfast, lunch, dinner, snack, drink\n",
    "\n",
    "class WorkoutExercise(TypedDict):\n",
    "    name: str\n",
    "    sets: int\n",
    "    reps: int\n",
    "    calories_burnt: int\n",
    "->Variable assignment needs to be coherent with the graph state \n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    parsed_intent: Optional[str]  # 'log_diet', 'log_workout', 'analyze_workout', 'unclear'\n",
    "    diet_log: List[FoodItem]\n",
    "    workout_log: List[WorkoutExercise]\n",
    "    daily_calories_consumed: int\n",
    "    daily_calories_burnt: int\n",
    "    weekly_workout_summary: Dict[str, Any]  # e.g., {'bicep_curls_total_sets': 10, 'bicep_goal_achieved': False}\n",
    "    analysis_result: Optional[str]\n",
    "    response: Optional[str]\n",
    "\n",
    "# Pydantic models for structured output from LLMs\n",
    "class FoodItemPydantic(BaseModel):\n",
    "    name: str = Field(description=\"Name of the food item.\")\n",
    "    calories: int = Field(description=\"Estimated calorie content of the food item.\")\n",
    "    meal_type: str = Field(description=\"Type of meal (e.g., breakfast, lunch, dinner, snack, drink, unknown).\")\n",
    "\n",
    "class WorkoutExercisePydantic(BaseModel):\n",
    "    name: str = Field(description=\"Name of the exercise.\")\n",
    "    sets: int = Field(description=\"Number of sets performed.\")\n",
    "    reps: int = Field(description=\"Number of repetitions per set.\")\n",
    "    calories_burnt: int = Field(description=\"Estimated calories burnt during this exercise.\")\n",
    "\n",
    "\n",
    "# 2. Node Implementations (Python Functions)\n",
    "\n",
    "def intent_router(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Classifies the user's initial input to determine the primary intent:\n",
    "    'log_diet', 'log_workout', 'analyze_workout', or 'unclear'.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant that classifies user intent for a diet and workout tracker. \"\n",
    "                   \"Classify the following user input into one of these categories: \"\n",
    "                   \"'log_diet', 'log_workout', 'analyze_workout', 'unclear'. \"\n",
    "                   \"Respond with only the category name, e.g., 'log_diet'.\"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    if not user_input:\n",
    "        return {\"parsed_intent\": \"unclear\"}\n",
    "\n",
    "    intent = chain.invoke({\"user_input\": user_input}).strip().lower()\n",
    "    \n",
    "    # Ensure the intent is one of the expected values\n",
    "    valid_intents = ['log_diet', 'log_workout', 'analyze_workout', 'unclear']\n",
    "    if intent not in valid_intents:\n",
    "        intent = 'unclear' # Default to unclear if LLM hallucinates\n",
    "\n",
    "    print(f\"Intent Router: User input '{user_input}' classified as '{intent}'\")\n",
    "    return {\"parsed_intent\": intent}\n",
    "\n",
    "def log_diet(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Processes user input related to diet. Extracts food items, estimates their\n",
    "    calorie content, and updates the `diet_log` and `daily_calories_consumed` fields.\n",
    "    Constructs a user-friendly response message.\n",
    "    \"\"\"\n",
    "    parser = JsonOutputParser(pydantic_object=List[FoodItemPydantic])\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant that extracts food items and their details from user input. \"\n",
    "                   \"Extract 'name', 'calories' (integer, estimate if not provided), and 'meal_type' \"\n",
    "                   \"(e.g., 'breakfast', 'lunch', 'dinner', 'snack', 'drink', 'unknown'). \"\n",
    "                   \"If no specific meal type is mentioned, use 'unknown'. \"\n",
    "                   \"If no calories are mentioned, provide a reasonable estimate (e.g., apple: 95, chicken breast: 200, soda: 150). \"\n",
    "                   \"Provide a JSON array of objects. If no food is mentioned, return an empty array. \"\n",
    "                   \"Example: [{{\\\"name\\\": \\\"apple\\\", \\\"calories\\\": 95, \\\"meal_type\\\": \\\"snack\\\"}}].\\n\"\n",
    "                   \"Format instructions: {format_instructions}\"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "    \n",
    "    chain = prompt | llm.with_structured_output(List[FoodItemPydantic])\n",
    "\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    extracted_food_items_pydantic: List[FoodItemPydantic] = []\n",
    "    try:\n",
    "        extracted_food_items_pydantic = chain.invoke({\"user_input\": user_input})\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting food items: {e}\")\n",
    "        # Fallback to empty list if extraction fails\n",
    "\n",
    "    current_diet_log: List[FoodItem] = state.get(\"diet_log\", [])\n",
    "    current_calories_consumed: int = state.get(\"daily_calories_consumed\", 0)\n",
    "\n",
    "    logged_items_names = []\n",
    "    for item_pydantic in extracted_food_items_pydantic:\n",
    "        item_typeddict: FoodItem = {\n",
    "            \"name\": item_pydantic.name,\n",
    "            \"calories\": item_pydantic.calories,\n",
    "            \"meal_type\": item_pydantic.meal_type\n",
    "        }\n",
    "        current_diet_log.append(item_typeddict)\n",
    "        current_calories_consumed += item_typeddict.get(\"calories\", 0)\n",
    "        logged_items_names.append(item_typeddict.get(\"name\", \"unknown item\"))\n",
    "\n",
    "    if logged_items_names:\n",
    "        response_msg = f\"Logged {', '.join(logged_items_names)} as part of your diet.\"\n",
    "    else:\n",
    "        response_msg = \"Could not identify any food items to log.\"\n",
    "    \n",
    "    response_msg += f\" Total calories consumed today: {current_calories_consumed}.\"\n",
    "\n",
    "    print(f\"Log Diet: {response_msg}\")\n",
    "    return {\n",
    "        \"diet_log\": current_diet_log,\n",
    "        \"daily_calories_consumed\": current_calories_consumed,\n",
    "        \"response\": response_msg\n",
    "    }\n",
    "\n",
    "def log_workout(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Processes user input related to workouts. Extracts exercise details (sets, reps,\n",
    "    estimated calories burnt), updates the `workout_log`, `daily_calories_burnt`,\n",
    "    and `weekly_workout_summary` fields. Checks for and reports on workout goals\n",
    "    and generates a response message.\n",
    "    \"\"\"\n",
    "    parser = JsonOutputParser(pydantic_object=List[WorkoutExercisePydantic])\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant that extracts workout exercises and their details from user input. \"\n",
    "                   \"Extract 'name', 'sets' (integer), 'reps' (integer), and 'calories_burnt' (integer, estimate if not provided). \"\n",
    "                   \"If no specific reps are mentioned, use 10. If no calories are mentioned, estimate based on typical exercise intensity \"\n",
    "                   \"(e.g., 20-50 calories per set, or 100-300 for a full workout). \"\n",
    "                   \"Provide a JSON array of objects. If no workout is mentioned, return an empty array. \"\n",
    "                   \"Example: [{{\\\"name\\\": \\\"bicep curls\\\", \\\"sets\\\": 4, \\\"reps\\\": 10, \\\"calories_burnt\\\": 80}}].\\n\"\n",
    "                   \"Format instructions: {format_instructions}\"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "    \n",
    "    chain = prompt | llm.with_structured_output(List[WorkoutExercisePydantic])\n",
    "\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    extracted_exercises_pydantic: List[WorkoutExercisePydantic] = []\n",
    "    try:\n",
    "        extracted_exercises_pydantic = chain.invoke({\"user_input\": user_input})\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting workout exercises: {e}\")\n",
    "        # Fallback to empty list if extraction fails\n",
    "\n",
    "    current_workout_log: List[WorkoutExercise] = state.get(\"workout_log\", [])\n",
    "    current_calories_burnt: int = state.get(\"daily_calories_burnt\", 0)\n",
    "    current_weekly_summary: Dict[str, Any] = state.get(\"weekly_workout_summary\", {})\n",
    "\n",
    "    logged_exercises_names = []\n",
    "    for exercise_pydantic in extracted_exercises_pydantic:\n",
    "        exercise_typeddict: WorkoutExercise = {\n",
    "            \"name\": exercise_pydantic.name,\n",
    "            \"sets\": exercise_pydantic.sets,\n",
    "            \"reps\": exercise_pydantic.reps,\n",
    "            \"calories_burnt\": exercise_pydantic.calories_burnt\n",
    "        }\n",
    "        current_workout_log.append(exercise_typeddict)\n",
    "        current_calories_burnt += exercise_typeddict.get(\"calories_burnt\", 0)\n",
    "        logged_exercises_names.append(exercise_typeddict.get(\"name\", \"unknown exercise\"))\n",
    "        \n",
    "        # Update weekly summary for analysis (example: bicep curls goal)\n",
    "        exercise_name_key = exercise_typeddict['name'].lower().replace(' ', '_') + '_total_sets'\n",
    "        current_weekly_summary[exercise_name_key] = current_weekly_summary.get(exercise_name_key, 0) + exercise_typeddict['sets']\n",
    "        \n",
    "    # Simple goal check for bicep training (example: 7 sets per week)\n",
    "    if current_weekly_summary.get('bicep_curls_total_sets', 0) >= 7:\n",
    "        current_weekly_summary['bicep_goal_achieved'] = True\n",
    "    else:\n",
    "        current_weekly_summary['bicep_goal_achieved'] = False\n",
    "\n",
    "    if logged_exercises_names:\n",
    "        response_msg = f\"Workout logged, {current_calories_burnt} calories burnt during the workout today.\"\n",
    "    else:\n",
    "        response_msg = \"Could not identify any workouts to log.\"\n",
    "\n",
    "    if current_weekly_summary.get('bicep_goal_achieved'):\n",
    "        response_msg += \" You have achieved the weekly goal for bicep training.\"\n",
    "\n",
    "    print(f\"Log Workout: {response_msg}\")\n",
    "    return {\n",
    "        \"workout_log\": current_workout_log,\n",
    "        \"daily_calories_burnt\": current_calories_burnt,\n",
    "        \"weekly_workout_summary\": current_weekly_summary,\n",
    "        \"response\": response_msg\n",
    "    }\n",
    "\n",
    "def analyze_workout(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Provides insights and recommendations based on the aggregated `weekly_workout_summary`.\n",
    "    Generates an analysis output, which also serves as the response message.\n",
    "    \"\"\"\n",
    "    weekly_summary = state.get(\"weekly_workout_summary\", {})\n",
    "    workout_log = state.get(\"workout_log\", [])\n",
    "\n",
    "    if not weekly_summary and not workout_log:\n",
    "        analysis_output = \"No workout data available for analysis yet. Log some workouts first!\"\n",
    "    else:\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are an AI fitness coach. Analyze the provided workout summary and log. \"\n",
    "                       \"Provide insights, identify trends, suggest improvements, and motivate the user. \"\n",
    "                       \"Consider total sets, reps, calories burnt, and any specific goals mentioned (like bicep goal). \"\n",
    "                       \"If the bicep goal is achieved, congratulate the user and suggest next steps. \"\n",
    "                       \"If not, encourage them to reach it. Keep the analysis concise and actionable.\"),\n",
    "            (\"user\", \"Here is the weekly workout summary: {weekly_summary}\\n\"\n",
    "                     \"Here is the full workout log: {workout_log}\\n\"\n",
    "                     \"Please provide an analysis and recommendations.\")\n",
    "        ])\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        \n",
    "        analysis_output = chain.invoke({\n",
    "            \"weekly_summary\": json.dumps(weekly_summary, indent=2),\n",
    "            \"workout_log\": json.dumps(workout_log, indent=2)\n",
    "        })\n",
    "\n",
    "    print(f\"Analyze Workout: {analysis_output}\")\n",
    "    return {\n",
    "        \"analysis_result\": analysis_output,\n",
    "        \"response\": analysis_output\n",
    "    }\n",
    "\n",
    "def generate_response(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Formulates the final user-facing message. It prioritizes any response\n",
    "    already set by a preceding action node. If no specific response is available\n",
    "    (e.g., for an unclear intent), it provides a default helpful message.\n",
    "    \"\"\"\n",
    "    if state.get(\"response\"):\n",
    "        final_response = state[\"response\"]\n",
    "    else:\n",
    "        final_response = \"I'm not sure how to help with that. Please tell me if you want to log diet, log a workout, or get a workout analysis.\"\n",
    "    \n",
    "    print(f\"Generate Response: {final_response}\")\n",
    "    return {\"response\": final_response}\n",
    "\n",
    "# 3. Graph Construction\n",
    "graph_builder = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"intent_router\", intent_router)\n",
    "graph_builder.add_node(\"log_diet\", log_diet)\n",
    "graph_builder.add_node(\"log_workout\", log_workout)\n",
    "graph_builder.add_node(\"analyze_workout\", analyze_workout)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.add_edge(START, \"intent_router\")\n",
    "\n",
    "# Conditional routing from intent_router\n",
    "def route_intent(state: GraphState) -> str:\n",
    "    \"\"\"Routes based on the parsed intent.\"\"\"\n",
    "    intent = state.get(\"parsed_intent\")\n",
    "    if intent == \"log_diet\":\n",
    "        return \"log_diet\"\n",
    "    elif intent == \"log_workout\":\n",
    "        return \"log_workout\"\n",
    "    elif intent == \"analyze_workout\":\n",
    "        return \"analyze_workout\"\n",
    "    else: # 'unclear' or any unexpected intent\n",
    "        return \"generate_response\"\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"intent_router\",\n",
    "    route_intent,\n",
    "    {\n",
    "        \"log_diet\": \"log_diet\",\n",
    "        \"log_workout\": \"log_workout\",\n",
    "        \"analyze_workout\": \"analyze_workout\",\n",
    "        \"generate_response\": \"generate_response\", # For 'unclear' intent\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add regular edges\n",
    "graph_builder.add_edge(\"log_diet\", \"generate_response\")\n",
    "graph_builder.add_edge(\"log_workout\", \"generate_response\")\n",
    "graph_builder.add_edge(\"analyze_workout\", \"generate_response\")\n",
    "\n",
    "# Set graph termination\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "# 4. Compilation\n",
    "checkpointer = InMemoryCheckpointer()\n",
    "final_app = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example Usage\n",
    "    print(\"--- Running Example 1: Log Diet ---\")\n",
    "    inputs = {\"user_input\": \"I ate an apple for snack (95 calories) and a chicken salad for lunch (350 calories).\"}\n",
    "    for s in final_app.stream(inputs):\n",
    "        print(s)\n",
    "    \n",
    "    print(\"\\n--- Running Example 2: Log Workout ---\")\n",
    "    inputs = {\"user_input\": \"Just finished my workout: 3 sets of 12 reps bicep curls, 4 sets of 8 reps bench press.\"}\n",
    "    for s in final_app.stream(inputs):\n",
    "        print(s)\n",
    "\n",
    "    print(\"\\n--- Running Example 3: Analyze Workout (after logging) ---\")\n",
    "    # To see the analysis, we need to run the workout log again to accumulate data\n",
    "    # Or manually set the state for analysis\n",
    "    # Let's run the workout log again to simulate more data\n",
    "    inputs_workout_2 = {\"user_input\": \"Did 5 sets of bicep curls today, 10 reps each.\"}\n",
    "    for s in final_app.stream(inputs_workout_2):\n",
    "        print(s)\n",
    "\n",
    "    # Now analyze\n",
    "    inputs_analyze = {\"user_input\": \"Can you analyze my workout progress?\"}\n",
    "    for s in final_app.stream(inputs_analyze):\n",
    "        print(s)\n",
    "\n",
    "    print(\"\\n--- Running Example 4: Unclear Intent ---\")\n",
    "    inputs = {\"user_input\": \"What's the weather like?\"}\n",
    "    for s in final_app.stream(inputs):\n",
    "        print(s)\n",
    "\n",
    "    print(\"\\n--- Running Example 5: Empty Input ---\")\n",
    "    inputs = {\"user_input\": \"\"}\n",
    "    for s in final_app.stream(inputs):\n",
    "        print(s)\n",
    "```\n",
    "\n",
    "## Required Keys and Credentials\n",
    "*   `OPENAI_API_KEY`: This environment variable must be set to your OpenAI API key for the `ChatOpenAI` model to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d122df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Make code DFS an analyser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "# Phase 1: Graph Architecture Analysis & Strategy\n",
    "# This graph implements a Router-Agent architecture.\n",
    "# The 'intent_router' node acts as a supervisory agent, classifying the user's intent\n",
    "# and dispatching the task to specialized \"worker\" nodes: 'log_diet', 'log_workout',\n",
    "# or 'analyze_workout'. If the intent is unclear, it routes to a generic response.\n",
    "# This architecture is chosen because the problem naturally breaks down into distinct,\n",
    "# intent-driven tasks, each handled by a dedicated LLM-powered function,\n",
    "# which is a common and effective pattern for building intelligent agents.\n",
    "\n",
    "import json\n",
    "from typing import TypedDict, List, Dict, Any, Union\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI # Uncomment if using Google GenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemoryCheckpointer\n",
    "\n",
    "# TODO: Configure your LLM. For OpenAI, ensure OPENAI_API_KEY is set in your environment.\n",
    "# For Google GenAI, ensure GOOGLE_API_KEY is set.\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)\n",
    "\n",
    "# Define Pydantic models for structured output from LLMs\n",
    "class FoodItem(BaseModel):\n",
    "    name: str = Field(description=\"Name of the food item.\")\n",
    "    calories: int = Field(description=\"Estimated calorie content of the food item.\")\n",
    "    meal_type: str = Field(description=\"Type of meal (e.g., breakfast, lunch, dinner, snack, drink, unknown).\")\n",
    "\n",
    "class WorkoutExercise(BaseModel):\n",
    "    name: str = Field(description=\"Name of the exercise.\")\n",
    "    sets: int = Field(description=\"Number of sets performed.\")\n",
    "    reps: int = Field(description=\"Number of repetitions per set.\")\n",
    "    calories_burnt: int = Field(description=\"Estimated calories burnt during this exercise.\")\n",
    "\n",
    "# Phase 2: Python Code Generation\n",
    "\n",
    "# State Definition (GraphState)\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        user_input: The initial input from the user.\n",
    "        parsed_intent: The classified intent of the user's input ('log_diet', 'log_workout', 'analyze_workout', 'unclear').\n",
    "        diet_log: A list of FoodItem objects (stored as dicts) representing logged food.\n",
    "        workout_log: A list of WorkoutExercise objects (stored as dicts) representing logged workouts.\n",
    "        daily_calories_consumed: Total calories consumed today.\n",
    "        daily_calories_burnt: Total calories burnt today.\n",
    "        weekly_workout_summary: A dictionary summarizing weekly workout stats (e.g., {'bicep_curls_total_sets': 10, 'bicep_goal_achieved': False}).\n",
    "        analysis_result: The detailed analysis output from the 'analyze_workout' node.\n",
    "        response: The final user-facing message.\n",
    "    \"\"\"\n",
    "    user_input: str\n",
    "    parsed_intent: str\n",
    "    diet_log: List[Dict[str, Any]] # Stored as dicts for TypedDict compatibility\n",
    "    workout_log: List[Dict[str, Any]] # Stored as dicts for TypedDict compatibility\n",
    "    daily_calories_consumed: int\n",
    "    daily_calories_burnt: int\n",
    "    weekly_workout_summary: Dict[str, Any]\n",
    "    analysis_result: str\n",
    "    response: str\n",
    "\n",
    "# Node Implementations (Python Functions)\n",
    "\n",
    "def intent_router(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Classifies the user's initial input to determine their intent.\n",
    "    Uses an LLM for robust intent classification.\n",
    "    \"\"\"\n",
    "    print(\"---INTENT ROUTER---\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant that classifies user intent for a diet and workout tracker. Classify the following user input into one of these categories: 'log_diet', 'log_workout', 'analyze_workout', 'unclear'. Respond with only the category name.\"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    if not user_input:\n",
    "        print(\"No user input provided, defaulting to 'unclear' intent.\")\n",
    "        return {\"parsed_intent\": \"unclear\"}\n",
    "\n",
    "    intent = chain.invoke({\"user_input\": user_input})\n",
    "    \n",
    "    # Basic validation to ensure intent is one of the expected values\n",
    "    valid_intents = ['log_diet', 'log_workout', 'analyze_workout', 'unclear']\n",
    "    if intent not in valid_intents:\n",
    "        print(f\"LLM returned an invalid intent: '{intent}'. Defaulting to 'unclear'.\")\n",
    "        intent = \"unclear\"\n",
    "\n",
    "    print(f\"Parsed intent: {intent}\")\n",
    "    return {\"parsed_intent\": intent}\n",
    "\n",
    "def log_diet(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Processes user input related to diet. Extracts food items, estimates calories,\n",
    "    and updates the diet log. Uses an LLM for structured data extraction.\n",
    "    \"\"\"\n",
    "    print(\"---LOG DIET---\")\n",
    "    # Use with_structured_output for robust Pydantic model extraction\n",
    "    structured_llm = llm.with_structured_output(List[FoodItem])\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant that extracts food items from user input. \"\n",
    "                   \"Extract food items, their estimated calorie content, and meal type. \"\n",
    "                   \"If no specific meal type is mentioned, use 'unknown'. \"\n",
    "                   \"If no calories are mentioned, provide a reasonable estimate (e.g., apple 95, sandwich 300, soda 150). \"\n",
    "                   \"If multiple items, list them all. If no food is mentioned, return an empty array. \"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ])\n",
    "    chain = prompt | structured_llm\n",
    "    \n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    extracted_food_items: List[FoodItem] = []\n",
    "    try:\n",
    "        extracted_food_items = chain.invoke({\"user_input\": user_input})\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting food items: {e}. Returning empty list.\")\n",
    "        # Fallback to empty list if parsing fails or LLM returns invalid structure\n",
    "\n",
    "    current_diet_log = state.get(\"diet_log\", [])\n",
    "    current_calories = state.get(\"daily_calories_consumed\", 0)\n",
    "\n",
    "    logged_items_names = []\n",
    "    for item in extracted_food_items:\n",
    "        current_diet_log.append(item.dict()) # Store as dict for TypedDict compatibility\n",
    "        current_calories += item.calories\n",
    "        logged_items_names.append(item.name)\n",
    "\n",
    "    response_msg = \"\"\n",
    "    if logged_items_names:\n",
    "        response_msg = f\"Logged {', '.join(logged_items_names)} as part of your diet.\"\n",
    "    else:\n",
    "        response_msg = \"Could not identify any food items to log.\"\n",
    "    \n",
    "    response_msg += f\" Calories consumed today: {current_calories}.\"\n",
    "\n",
    "    print(f\"Diet log updated. Response: {response_msg}\")\n",
    "    return {\n",
    "        \"diet_log\": current_diet_log,\n",
    "        \"daily_calories_consumed\": current_calories,\n",
    "        \"response\": response_msg\n",
    "    }\n",
    "\n",
    "def log_workout(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Processes user input related to workouts. Extracts exercise details,\n",
    "    updates workout log and calorie burn. Uses an LLM for structured data extraction.\n",
    "    \"\"\"\n",
    "    print(\"---LOG WORKOUT---\")\n",
    "    # Use with_structured_output for robust Pydantic model extraction\n",
    "    structured_llm = llm.with_structured_output(List[WorkoutExercise])\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant that extracts workout exercises from user input. \"\n",
    "                   \"Extract exercise name, sets, reps, and estimated calories burnt. \"\n",
    "                   \"If no specific reps are mentioned, use 10. \"\n",
    "                   \"If no calories are mentioned, estimate based on typical exercise intensity (e.g., 20-50 calories per set per exercise). \"\n",
    "                   \"If multiple exercises, list them all. If no exercise is mentioned, return an empty array. \"),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ])\n",
    "    chain = prompt | structured_llm\n",
    "\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    extracted_exercises: List[WorkoutExercise] = []\n",
    "    try:\n",
    "        extracted_exercises = chain.invoke({\"user_input\": user_input})\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting workout exercises: {e}. Returning empty list.\")\n",
    "        # Fallback to empty list if parsing fails or LLM returns invalid structure\n",
    "\n",
    "    current_workout_log = state.get(\"workout_log\", [])\n",
    "    current_calories_burnt = state.get(\"daily_calories_burnt\", 0)\n",
    "    current_weekly_summary = state.get(\"weekly_workout_summary\", {})\n",
    "\n",
    "    logged_exercises_names = []\n",
    "    for exercise in extracted_exercises:\n",
    "        current_workout_log.append(exercise.dict()) # Store as dict for TypedDict compatibility\n",
    "        current_calories_burnt += exercise.calories_burnt\n",
    "        logged_exercises_names.append(exercise.name)\n",
    "        \n",
    "        # Update weekly summary for analysis (example: bicep curls goal)\n",
    "        exercise_name_key = exercise.name.lower().replace(' ', '_') + '_total_sets'\n",
    "        current_weekly_summary[exercise_name_key] = current_weekly_summary.get(exercise_name_key, 0) + exercise.sets\n",
    "        \n",
    "    # Simple goal check for bicep training (example: 7 sets per week)\n",
    "    if current_weekly_summary.get('bicep_curls_total_sets', 0) >= 7:\n",
    "        current_weekly_summary['bicep_goal_achieved'] = True\n",
    "    else:\n",
    "        current_weekly_summary['bicep_goal_achieved'] = False\n",
    "\n",
    "    response_msg = \"\"\n",
    "    if logged_exercises_names:\n",
    "        response_msg = f\"Workout logged, {current_calories_burnt} calories burnt during the workout today.\"\n",
    "    else:\n",
    "        response_msg = \"Could not identify any workouts to log.\"\n",
    "\n",
    "    if current_weekly_summary.get('bicep_goal_achieved'):\n",
    "        response_msg += \" You have achieved the weekly goal for bicep training.\"\n",
    "\n",
    "    print(f\"Workout log updated. Response: {response_msg}\")\n",
    "    return {\n",
    "        \"workout_log\": current_workout_log,\n",
    "        \"daily_calories_burnt\": current_calories_burnt,\n",
    "        \"weekly_workout_summary\": current_weekly_summary,\n",
    "        \"response\": response_msg\n",
    "    }\n",
    "\n",
    "def analyze_workout(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Provides insights and recommendations based on the aggregated weekly_workout_summary.\n",
    "    Uses an LLM to generate a comprehensive analysis.\n",
    "    \"\"\"\n",
    "    print(\"---ANALYZE WORKOUT---\")\n",
    "    weekly_summary = state.get(\"weekly_workout_summary\", {})\n",
    "    workout_log = state.get(\"workout_log\", [])\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI fitness coach. Analyze the provided workout data and provide insights, \"\n",
    "                   \"recommendations, and encouragement. Focus on progress, areas for improvement, \"\n",
    "                   \"and general fitness advice. If no data is available, state that clearly. \"\n",
    "                   \"Consider the following data:\\n\"\n",
    "                   \"Weekly Summary: {weekly_summary}\\n\"\n",
    "                   \"Full Workout Log: {workout_log}\\n\"\n",
    "                   \"Daily Calories Burnt: {daily_calories_burnt}\\n\"\n",
    "                   \"User Input: {user_input}\\n\"\n",
    "                   \"Provide a concise, helpful analysis.\"),\n",
    "        (\"user\", \"Analyze my workout data.\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    analysis_output = chain.invoke({\n",
    "        \"weekly_summary\": json.dumps(weekly_summary, indent=2),\n",
    "        \"workout_log\": json.dumps(workout_log, indent=2),\n",
    "        \"daily_calories_burnt\": state.get(\"daily_calories_burnt\", 0),\n",
    "        \"user_input\": state.get(\"user_input\", \"\")\n",
    "    })\n",
    "\n",
    "    print(f\"Workout analysis generated. Response: {analysis_output}\")\n",
    "    return {\n",
    "        \"analysis_result\": analysis_output,\n",
    "        \"response\": analysis_output # For simplicity, analysis result is the response\n",
    "    }\n",
    "\n",
    "def generate_response(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generates the final user-facing response. Prioritizes responses set by\n",
    "    action nodes, otherwise provides a default message.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE RESPONSE---\")\n",
    "    # If an action node has already set a specific response, use it.\n",
    "    # Otherwise, provide a default message for unclear intents.\n",
    "    if state.get(\"response\"):\n",
    "        final_response = state[\"response\"]\n",
    "    else:\n",
    "        final_response = \"I'm not sure how to help with that. Please tell me if you want to log diet, log a workout, or get a workout analysis.\"\n",
    "    \n",
    "    print(f\"Final response: {final_response}\")\n",
    "    return {\"response\": final_response}\n",
    "\n",
    "# Graph Construction (StatefulGraph)\n",
    "graph_builder = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"intent_router\", intent_router)\n",
    "graph_builder.add_node(\"log_diet\", log_diet)\n",
    "graph_builder.add_node(\"log_workout\", log_workout)\n",
    "graph_builder.add_node(\"analyze_workout\", analyze_workout)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.add_edge(START, \"intent_router\")\n",
    "\n",
    "# Define conditional routing for intent_router\n",
    "def route_intent(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Routes the graph based on the parsed intent.\n",
    "    \"\"\"\n",
    "    intent = state.get(\"parsed_intent\")\n",
    "    print(f\"Routing based on intent: {intent}\")\n",
    "    if intent == \"log_diet\":\n",
    "        return \"log_diet\"\n",
    "    elif intent == \"log_workout\":\n",
    "        return \"log_workout\"\n",
    "    elif intent == \"analyze_workout\":\n",
    "        return \"analyze_workout\"\n",
    "    else: # 'unclear' or any unexpected intent\n",
    "        return \"generate_response\"\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"intent_router\",\n",
    "    route_intent,\n",
    "    {\n",
    "        \"log_diet\": \"log_diet\",\n",
    "        \"log_workout\": \"log_workout\",\n",
    "        \"analyze_workout\": \"analyze_workout\",\n",
    "        \"generate_response\": \"generate_response\", # For 'unclear' intent\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add regular edges from action nodes to generate_response\n",
    "graph_builder.add_edge(\"log_diet\", \"generate_response\")\n",
    "graph_builder.add_edge(\"log_workout\", \"generate_response\")\n",
    "graph_builder.add_edge(\"analyze_workout\", \"generate_response\")\n",
    "\n",
    "# Set graph termination\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = InMemoryCheckpointer()\n",
    "final_app = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Example Usage (Optional, for testing)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Running LangGraph Application ---\")\n",
    "\n",
    "    # Test Case 1: Log Diet\n",
    "    print(\"\\n--- Test Case 1: Log Diet ---\")\n",
    "    inputs_diet = {\"user_input\": \"I ate an apple for 95 calories and a sandwich for 300 calories for lunch.\"}\n",
    "    # Using a fixed thread_id for demonstration purposes to accumulate state\n",
    "    thread_id = \"user123\" \n",
    "    for s in final_app.stream(inputs_diet, config={\"configurable\": {\"thread_id\": thread_id}}):\n",
    "        print(s)\n",
    "    print(f\"Final State after diet log: {final_app.get_state(thread_id=thread_id).values}\")\n",
    "\n",
    "    # Test Case 2: Log Workout\n",
    "    print(\"\\n--- Test Case 2: Log Workout ---\")\n",
    "    inputs_workout = {\"user_input\": \"I did 3 sets of 10 reps of bicep curls and 4 sets of 8 reps of squats, burnt 200 calories.\"}\n",
    "    for s in final_app.stream(inputs_workout, config={\"configurable\": {\"thread_id\": thread_id}}):\n",
    "        print(s)\n",
    "    print(f\"Final State after workout log: {final_app.get_state(thread_id=thread_id).values}\")\n",
    "\n",
    "    # Test Case 3: Analyze Workout (after logging some workouts)\n",
    "    print(\"\\n--- Test Case 3: Analyze Workout ---\")\n",
    "    inputs_analyze = {\"user_input\": \"How was my workout performance this week?\"}\n",
    "    for s in final_app.stream(inputs_analyze, config={\"configurable\": {\"thread_id\": thread_id}}):\n",
    "        print(s)\n",
    "    print(f\"Final State after workout analysis: {final_app.get_state(thread_id=thread_id).values}\")\n",
    "\n",
    "    # Test Case 4: Unclear Intent\n",
    "    print(\"\\n--- Test Case 4: Unclear Intent ---\")\n",
    "    inputs_unclear = {\"user_input\": \"Tell me a joke.\"}\n",
    "    # Using a new thread_id for a fresh start\n",
    "    thread_id_unclear = \"user_unclear\"\n",
    "    for s in final_app.stream(inputs_unclear, config={\"configurable\": {\"thread_id\": thread_id_unclear}}):\n",
    "        print(s)\n",
    "    print(f\"Final State after unclear intent: {final_app.get_state(thread_id=thread_id_unclear).values}\")\n",
    "\n",
    "    # Test Case 5: Log more bicep curls to hit goal (continuing from original thread)\n",
    "    print(\"\\n--- Test Case 5: Log more bicep curls to hit goal ---\")\n",
    "    inputs_bicep_goal = {\"user_input\": \"Did 2 sets of bicep curls today.\"}\n",
    "    for s in final_app.stream(inputs_bicep_goal, config={\"configurable\": {\"thread_id\": thread_id}}):\n",
    "        print(s)\n",
    "    print(f\"Final State after hitting bicep goal: {final_app.get_state(thread_id=thread_id).values}\")\n",
    "    \n",
    "    # Test Case 6: Analyze Workout again to see goal achievement (continuing from original thread)\n",
    "    print(\"\\n--- Test Case 6: Analyze Workout again to see goal achievement ---\")\n",
    "    inputs_analyze_again = {\"user_input\": \"What about my bicep goal?\"}\n",
    "    for s in final_app.stream(inputs_analyze_again, config={\"configurable\": {\"thread_id\": thread_id}}):\n",
    "        print(s)\n",
    "    print(f\"Final State after re-analysis: {final_app.get_state(thread_id=thread_id).values}\")\n",
    "\n",
    "```\n",
    "\n",
    "## Required Keys and Credentials\n",
    "\n",
    "For the generated Python code to execute successfully, you will need to set up the following environment variables:\n",
    "\n",
    "*   **`OPENAI_API_KEY`**: Required if you are using `ChatOpenAI` as your LLM.\n",
    "    *   You can obtain this key from the OpenAI platform.\n",
    "\n",
    "If you choose to use `ChatGoogleGenerativeAI` (by uncommenting the relevant lines), you would need:\n",
    "\n",
    "*   **`GOOGLE_API_KEY`**: Required for Google's Generative AI models (e.g., Gemini).\n",
    "    *   You can obtain this key from the Google Cloud Console or Google AI Studio.\n",
    "\n",
    "**How to set environment variables:**\n",
    "\n",
    "Before running the script, set the environment variable in your terminal:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"your_openai_api_key_here\"\n",
    "# Or for Google:\n",
    "# export GOOGLE_API_KEY=\"your_google_api_key_here\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
