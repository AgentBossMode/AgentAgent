{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce52156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "import yaml\n",
    "import json\n",
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from typing import List\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "from typing import Annotated\n",
    "from typing import NamedTuple\n",
    "from utils.fetch_docs import fetch_documents\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        # logging.FileHandler(\"scraper.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "template = \"\"\"Your job is to get information from a user about what kind of agent they wish to build.\n",
    "\n",
    "You should get the following information from them:\n",
    "\n",
    "- What the objective of the agent is\n",
    "- Various usecases of the agent \n",
    "- Some examples of what the agent will be doing (Input and expected output pairs)\n",
    "\n",
    "If you are not able to discern this info, ask them to clarify! Do not attempt to wildly guess.\n",
    "\n",
    "After you are able to discern all the information, call the tool AgentInstruction\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919d49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentInstructions(BaseModel):\n",
    "    \"\"\"Instructions on how to build the Agent\"\"\"\n",
    "    objective: str = Field(description= \"What is the primary objective of the agent\")\n",
    "    usecases: List[str] = Field(description= \"What are the various responsibilities of the agent which it needs to fulfill\")\n",
    "    examples : str = Field(description= \"What are some examples of the usage of the agent (input query and expected output from the agent) ?\")\n",
    "\n",
    "class AgentBuilderState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    json_code: str = Field(\"The json code generated\")\n",
    "    python_code: str = Field(\"The Python code generated\")\n",
    "\n",
    "class ArchitectureEvaluationState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    url: str = Field(\"url of the agent architecture to evaluate against\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", temperature=0)\n",
    "\n",
    "def requirement_analysis_node(state: AgentBuilderState):\n",
    "    \n",
    "    llm_with_tool = llm.bind_tools([AgentInstructions])\n",
    "    response = llm_with_tool.invoke([SystemMessage(content=template)] + state[\"messages\"])\n",
    "    \n",
    "      # Construct the final answer from the arguments of the last tool call  \n",
    "    if len(response.tool_calls) == 0:\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    agent_instructions = response.tool_calls[0]\n",
    "    agent_instructions = AgentInstructions(**agent_instructions[\"args\"])\n",
    "    \n",
    "    return {\"messages\": [response], \"agent_instructions\": agent_instructions}\n",
    "\n",
    "\n",
    "def route_state(state: AgentBuilderState):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"agent_kernel_builder\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"requirement_analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f87e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AGENT_KERNEL_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Task Overview:\n",
    "        Design a langgraph StateGraph object implementing the the best architecture for the given set of requirements, tailored to fulfill the user requirements defined below\n",
    "\n",
    "        <Requirements>\n",
    "        Objectives: {objective}\n",
    "        usecases: {responsibilities}\n",
    "        examples: {examples}\n",
    "        </Requirements>\n",
    "\n",
    "        \n",
    "        Expected Output:\n",
    "        Your task is to produce a compiled StateGraph object.\n",
    "\n",
    "        Guidelines for Code Generation:\n",
    "        - Accuracy: Avoid hallucinations or speculative assumptions when writing code. Refer exclusively to the provided documentation.\n",
    "        - Understanding: Thoroughly comprehend the architecture and examples of code.\n",
    "        - Customization: Generate code tailored specifically to meet the user requirements.\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "def agent_kernel_builder(state: AgentBuilderState):\n",
    "    \"\"\"Build the agent kernel using the best architecture.\"\"\"\n",
    "    agent_instructions : AgentInstructions = state[\"agent_instructions\"]\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    # agent_architecture_report.name\n",
    "    #agent_architecture_report.highlights\n",
    "    #agent_architecture_report.justification\n",
    "    #agent_architecture_report.tailored_design\n",
    "    print(\"reached here\")\n",
    "    response =  llm.invoke([HumanMessage(content=AGENT_KERNEL_PROMPT.format(\n",
    "        objective=agent_instructions.objective,\n",
    "        responsibilities=agent_instructions.usecases,\n",
    "        examples = agent_instructions.examples,\n",
    "        # langgraph_glossary=fetch_documents(langgraph_glossary_url),\n",
    "        ))])\n",
    "    \n",
    "    # Return the generated agent kernel as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated agent kernel code!\")],\n",
    "        \"python_code\": response.content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec67a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CODE_TO_JSON_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with converting the following stategraph comPilation code into a JSON. \n",
    "\n",
    "Contextual documents for understanding code:\n",
    "{documents}\n",
    "\n",
    "The Input code is as follows:\n",
    "{code_snippet}\n",
    "\n",
    "OUTPUT: Explaination and JSON. Do not include any code blocks. Seperate the JSON and explaination blocks and ensure that there is an explaination for each line of JSON produced but keep the blocks seperated.\n",
    "Each Output JSON will have a nodes sections containing all the nodes and an edges section\n",
    "\n",
    "Please follow:\n",
    "1. Produce the explaination first and then the JSON after it. DO not produce the JSON first. \n",
    "2. For any conditional edges, please include all the nodes that the source of a conditional edge can reach as part of the explaination.\n",
    "3. Any Edge entry in the JSON can only be conditional(mention conditional: true) if the source for that edge acts as a source for multiple edges. If you cannot point to atleast 2 targets for 1 source, then that source will not have any conditional edges\n",
    "4. A source can have any number of targets. Please write the explaination for each source node to target node edge\n",
    "5. Please ensure that the JSON starts with __START__ node and __END__ node with the correct edges from and to them\n",
    "6. Ensure all elements in the nodes sections of the output json contain the following fields: Schema_info, input_schema, output_schema, description, function_name. Please do not return any entries in the nodes without these fields and these fields can't be empty\n",
    "7. Ensure all elements in the edges sections of the output json contain the following fields: source, target, routing_conditions, conditional. Please do not return any entries in the edges without these fields and they can't be empty\n",
    "8. Every node should be a part of atleast one edge, Please ensure this is followed\n",
    "9. Attach the code snippet for each node aswell that. Please extract it from the Input code\n",
    "\n",
    "\n",
    "Example output JSON for a node:\n",
    "    \"code_node\":{{\n",
    "        \"schema_info\": /\"/\"/\"CodeWriterState:\n",
    "      type: TypedDict\n",
    "      fields:\n",
    "      - name: user_query\n",
    "        type: str\n",
    "      - name: execution_result\n",
    "        type: str/\"/\"/\",\n",
    "    \"input_schema\": \"CodeWriterState\",\n",
    "    \"output_schema\":\"RequiremenCodeWriterStatetAnalysisState\",\n",
    "    \"description\":\"This node analyzes the user_query, if the query is to write a code, it will make a tool call to run the proposed code. This node returns command object\",\n",
    "    \"function_name\": \"code_step\"\n",
    "    }}\n",
    "\n",
    "Example output JSON for an edge:\n",
    "edge:{{ source: \"abc\", target: \"cde\", routing_condition: \"if abc made a tool call then go to cde\", \"conditional\": true}}\n",
    "edge:{{ source: \"abc\", target: \"xyz\", routing_condition: \"if abc made an interupt to a human then go to xyz\", \"conditional\": true}}\n",
    "edge:{{ source: \"xyz\", target: \"_END_\", routing_condition: \"no nodes to go after xyz, we have our final output for this path\", \"conditional\": false}}s         \n",
    "\"\"\")\n",
    "def code_to_json_node(state: AgentBuilderState):\n",
    "    \"\"\"Convert the generated code to JSON.\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([HumanMessage(content=CODE_TO_JSON_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated JSON code!\")],\n",
    "        \"json_code\": json_code_ouptut.content,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f75bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JSON_CODE_COMBINE_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with verifying and updating the provided JSON that represents the nodes and edges of the langgraph to ensure it is correct with respect to the input code.\n",
    "\n",
    "Contextual Documents for Understanding Code:\n",
    "{documents}\n",
    "\n",
    "Input Code:\n",
    "<Input code>{code_snippet}</Input code>\n",
    "JSON:\n",
    "<JSON>{node_json}</JSON>\n",
    "\n",
    "OUTPUT: JSON\n",
    "Your task is divided into two parts:\n",
    "- Validation: Verify that the JSON adheres to the rules outlined below.\n",
    "- Correction and Augmentation: If the JSON is incorrect or incomplete, update it with a clear justification for every change, and include the code snippet for each node extracted from the input code.\n",
    "\n",
    "Rules for Validation and Update:\n",
    "- Conditional Edges:- An edge can be marked as conditional: true only if its source acts as a source for multiple edges (i.e., at least two targets).\n",
    "- If the source does not meet this condition, then it cannot have conditional edges.\n",
    "\n",
    "- Edge Targets:- Each source can have any number of targets. This flexibility must be maintained.\n",
    "\n",
    "- Start and End Nodes:- The JSON must begin with the __START__ node and conclude with the __END__ node, with correct edges to and from them. Edges into the END node can also be conditional if they meet the above mentioned conditions      \n",
    "\n",
    "- Node Structure:- Each node entry in the nodes section of the JSON must include the following non-empty fields:- schema_info\n",
    "- id\n",
    "- schema_info\n",
    "- input_schema\n",
    "- output_schema\n",
    "- description\n",
    "- function_name\n",
    "\n",
    "\n",
    "- Edge Structure:- Each edge entry in the edges section of the JSON must include the following non-empty fields:- source\n",
    "- target\n",
    "- routing_conditions\n",
    "- conditional\n",
    "\n",
    "\n",
    "- Node-Edge Relationship:- Every node must be part of at least one edge. Ensure this relationship is consistently followed.\n",
    "\n",
    "- Node Code Snippets:- Attach a code field to every node in the JSON, extracted directly from the input code.\n",
    "\n",
    "- Schema Requirements:- The final JSON must conform to the schema provided below:\n",
    "\n",
    "\n",
    "Schema for JSON. Ensure the following schema is followed. No field should be missing for any node or edge:\n",
    "- Node Example:\n",
    "\n",
    "{{\n",
    "  \"code_node\": {{\n",
    "    \"id\" : \"<id of the node, similar to name>\"\n",
    "    \"schema_info\": \"<define the class structure of the state of this node. Also provide a name>\",\n",
    "    \"input_schema\": \"<input state object name>\",\n",
    "    \"output_schema\": \"<output state object name>\",\n",
    "    \"description\": \"<description>\",\n",
    "    \"function_name\": \"<function_name>\",\n",
    "    \"code\": \"<python_code>\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\n",
    "- Edge Example:\n",
    "\n",
    "{{\n",
    "  \"edge\": {{\n",
    "    \"source\": \"<source_node>\",\n",
    "    \"target\": \"<target_node>\",\n",
    "    \"routing_condition\": \"<routing_condition>\",\n",
    "    \"conditional\": true/false\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\n",
    "                                            \n",
    "Key Instructions:\n",
    "- Do not update any pre-existing field of the JSON unless you have an extremely strong justification for doing so.\n",
    "- Clearly document the reasoning behind any additions, updates, or modifications to the JSON. Justifications should draw inspiration from the contextual documents mentioned earlier.\n",
    "- Ensure conditional edges strictly adhere to the rules outlined above.\n",
    "- Input_Schema and output_schemas can only have value None in JSON for START and END nodes. Please follow this without fail\n",
    "- Include a code field for each code_node entry, with the exact code that corresponds to the node in the input code.\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "def json_better_node(state: AgentBuilderState):\n",
    "    \"\"\"Add code to the json flow\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([HumanMessage(content=JSON_CODE_COMBINE_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        node_json = state[\"json_code\"]\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated updated JSON code!\")],\n",
    "        \"json_code\": json_code_ouptut.content,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46a1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentBuilderState)\n",
    "workflow.add_node(\"requirement_analysis\", requirement_analysis_node)\n",
    "workflow.add_node(\"agent_kernel_builder\", agent_kernel_builder)\n",
    "workflow.add_node(\"code_to_json\", code_to_json_node)\n",
    "workflow.add_node(\"json_update\", json_better_node)\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: AgentBuilderState):\n",
    "    \n",
    "   \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Requirements generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "workflow.add_edge(\"json_update\", END)\n",
    "workflow.add_edge(\"code_to_json\", \"json_update\")\n",
    "workflow.add_edge(\"agent_kernel_builder\", \"code_to_json\")\n",
    "workflow.add_conditional_edges(\"requirement_analysis\", route_state, [\"agent_kernel_builder\", \"requirement_analysis\", END])\n",
    "workflow.add_edge(START, \"requirement_analysis\")\n",
    "infograph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35028943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (q/Q to quit): 1. Primary objective is handle customers, resolve their issues, fetch information for them and conflict to resolution 2. Use cases would be updating customer information, providing customers with the data they ask for, asking customers for their requirements and suggesting them products 3. example 1: input: what is the price of product x? output:  price of x is 300$ example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi Example 3: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accoutning along with, I would also suggest product z which helps with customer out reach and is generally used by customers opening new business and fits your use case\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  AgentInstructions (e7a458b0-7e0d-4cd7-9a76-97149222b7fd)\n",
      " Call ID: e7a458b0-7e0d-4cd7-9a76-97149222b7fd\n",
      "  Args:\n",
      "    examples: example 1: input: what is the price of product x? output: price of x is 300$ example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi Example 3: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accoutning along with, I would also suggest product z which helps with customer out reach and is generally used by customers opening new business and fits your use case\n",
      "    objective: handle customers, resolve their issues, fetch information for them and conflict to resolution\n",
      "    usecases: ['updating customer information', 'providing customers with the data they ask for', 'asking customers for their requirements and suggesting them products']\n",
      "reached here\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generated agent kernel code!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 18:43:54,874 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/concepts/low_level/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generated JSON code!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 18:44:27,774 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/concepts/low_level/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generated updated JSON code!\n",
      "User (q/Q to quit): q\n",
      "AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "cached_human_responses = [\"hi!\", \"rag prompt\", \"1 rag, 2 none, 3 no, 4 no\", \"red\", \"q\"]\n",
    "cached_response_index = 0\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"User (q/Q to quit): \")\n",
    "    except:\n",
    "        user = cached_human_responses[cached_response_index]\n",
    "        cached_response_index += 1\n",
    "    print(f\"User (q/Q to quit): {user}\")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in infograph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"prompt\" in output:\n",
    "        print(\"Done!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebd08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
