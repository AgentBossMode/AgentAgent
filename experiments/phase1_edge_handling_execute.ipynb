{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4625d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\agentagent\\AgentAgent\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from phase1_edge_handling import edge_builder_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09eee34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"conditional_rand\" : \"\"\"\n",
    "Write a conditional edge from node: src to one of the nodes [\"node1\", \"node2\", \"node3\"]\n",
    "The condition is use a random number to select any of the node\"\"\",\n",
    "\"deterministic_parallel\": \"\"\"Add edge from node1 to node 2 and node 3\"\"\",\n",
    "\"deterministic_1\": \"Add edge from node 1 to node2\",\n",
    "\"conditional_state_tool_call\": \"Write a conditional_edge, if the the last message in messages field had a tool_call, then route to tools node, else END\",\n",
    "\"code_and_edge_non_conditional\":\n",
    "    \"\"\"\n",
    "<GraphNodeImplementation>\n",
    "def plan_step(state: OverallState) -> OverallState:\n",
    "    \\\"\\\"\\\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\\\"\\\"\\\"\n",
    "    \n",
    "    # Extract the input from the state\n",
    "    user_input = state['input']\n",
    "    \n",
    "    # Initialize the structured LLM with the Plan schema\n",
    "    structured_llm = llm.with_structured_output(Plan)\n",
    "    \n",
    "    # Generate the structured plan using the input\n",
    "    plan: Plan = structured_llm.invoke(\n",
    "        f\"Please create a structured plan based on the following input: {{user_input}}. \"\n",
    "        \"The plan should clearly outline the steps to take in order to achieve the requested outcome, \"\n",
    "        \"and provide detailed information for each step in a format that includes titles and descriptions.\"\n",
    "    )\n",
    "    \n",
    "    # Update the state with the generated plan\n",
    "    state['plan'] = [{'title': title, 'description': description} for title, description in zip(plan.titles, plan.descriptions)]\n",
    "    \n",
    "    return state\n",
    "</GraphNodeImplementation>\n",
    "\n",
    "<EdgeInformation>\n",
    "\"source\": \"planner\",\n",
    "      \"target\": \"agent\",\n",
    "      \"routing_conditions\": \"After planning, execute the first step.\",\n",
    "      \"conditional\": false\n",
    "</EdgeInformation>\n",
    "    \"\"\",\n",
    "    \"supervisor\": \"\"\"\n",
    "<GraphNodeImplementation>\n",
    "class Router(TypedDict):\n",
    "    \\\"\\\"\\\"Worker to route to next. If no workers needed, route to FINISH.\\\"\\\"\\\"\n",
    "    next: Literal[*options]\n",
    "    action: str = Field(\"the action to be taken by the next worker\")\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "    \n",
    "members = [\"food_logger\", \"workout_tracker\"]\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "\n",
    "def supervisor(state: State):\n",
    "    system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {{members}}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    return {\"next\": goto, \"action\": response[\"action\"]}\n",
    "    </GraphNodeImplementation>\n",
    "    <EdgeInformation>\n",
    "    { \n",
    "      \"source\": \"supervisor\", \n",
    "      \"target\": \"food_logger\", \n",
    "      \"target_info\": \"uses state action in its implementation\",\n",
    "      \"routing_conditions\": \"If the supervisor decides to route to food_logger based on user input.\", \n",
    "      \"conditional\": true \n",
    "    },\n",
    "    { \n",
    "      \"source\": \"supervisor\", \n",
    "      \"target\": \"workout_tracker\",\n",
    "      \"target_info\": \"uses state action in its implementation\",\n",
    "      \"routing_conditions\": \"If the supervisor decides to route to workout_tracker based on user input.\", \n",
    "      \"conditional\": true \n",
    "    },\n",
    "    { \n",
    "      \"source\": \"supervisor\", \n",
    "      \"target\": \"__END__\", \n",
    "      \"routing_conditions\": \"If the supervisor decides to finish the process.\", \n",
    "      \"conditional\": true\n",
    "    }\n",
    "    </Edgeinformation>\n",
    "    \"\"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c51485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "uuid = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid)}}\n",
    "\n",
    "result = edge_builder_agent.invoke({\"messages\": [HumanMessage(content = input_dict[\"supervisor\"])]},config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
