{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "openai_api_type=\"azure\",\n",
    "openai_api_version=os.environ[\"OPENAI_API_EMBEDDING_VERSION\"],\n",
    "openai_api_key=os.environ[\"OPENAI_API_EMBEDDING_KEY\"],\n",
    "azure_endpoint=os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"],\n",
    "deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"],\n",
    "model=os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "validate_base_url=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 15:18:19,663 - INFO - HTTP Request: POST https://kanis-m8htxgs7-eastus.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_neo4j import Neo4jVector\n",
    "\n",
    "url = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "\n",
    "vector_store = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name=\"neo4j\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        # logging.FileHandler(\"scraper.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html2text in d:\\agentagent\\agentagent\\myenv\\lib\\site-packages (2024.2.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install html2text\n",
    "import html2text\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "async def parse_url_to_doc(url: str) -> str:\n",
    "    try:\n",
    "        timeout = aiohttp.ClientTimeout(total=10)  # Set timeout to 3 seconds\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, timeout= timeout) as response:\n",
    "                if response.status != 200:\n",
    "                    logger.warning(f\"Failed to fetch {url}: Status code {response.status}\")\n",
    "                    return None\n",
    "                html_content = await response.text()\n",
    "                soup = BeautifulSoup(html_content, 'html.parser')\n",
    "                target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "\n",
    "                if not target_div:\n",
    "                    target_div = soup.find('article') #langraph\n",
    "                \n",
    "                if not target_div:\n",
    "                    target_div = soup.find(\"div\", id=\"content-area\")\n",
    "                \n",
    "                if not target_div:\n",
    "                    target_div = soup.find(\"textarea\", id=\"read-only-cursor-text-area\")\n",
    "\n",
    "                if not target_div:\n",
    "                    return None\n",
    "\n",
    "                return Document(page_content=html2text.html2text(str(target_div)), metadata={\"source\": url})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in parsing {url}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Concepts\n",
      "\n",
      "# Tools\n",
      "\n",
      "Enable LLMs to perform actions through your server\n",
      "\n",
      "Tools are a powerful primitive in the Model Context Protocol (MCP) that enable\n",
      "servers to expose executable functionality to clients. Through tools, LLMs can\n",
      "interact with external systems, perform computations, and take actions in the\n",
      "real world.\n",
      "\n",
      "Tools are designed to be **model-controlled** , meaning that tools are exposed\n",
      "from servers to clients with the intention of the AI model being able to\n",
      "automatically invoke them (with a human in the loop to grant approval).\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Overview\n",
      "\n",
      "Tools in MCP allow servers to expose executable functions that can be invoked\n",
      "by clients and used by LLMs to perform actions. Key aspects of tools include:\n",
      "\n",
      "  * **Discovery** : Clients can list available tools through the `tools/list` endpoint\n",
      "  * **Invocation** : Tools are called using the `tools/call` endpoint, where servers perform the requested operation and return results\n",
      "  * **Flexibility** : Tools can range from simple calculations to complex API interactions\n",
      "\n",
      "Like [resources](/docs/concepts/resources), tools are identified by unique\n",
      "names and can include descriptions to guide their usage. However, unlike\n",
      "resources, tools represent dynamic operations that can modify state or\n",
      "interact with external systems.\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Tool definition structure\n",
      "\n",
      "Each tool is defined with the following structure:\n",
      "\n",
      "    \n",
      "    \n",
      "    {\n",
      "      name: string;          // Unique identifier for the tool\n",
      "      description?: string;  // Human-readable description\n",
      "      inputSchema: {         // JSON Schema for the tool's parameters\n",
      "        type: \"object\",\n",
      "        properties: { ... }  // Tool-specific parameters\n",
      "      }\n",
      "    }\n",
      "    \n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Implementing tools\n",
      "\n",
      "Hereâ€™s an example of implementing a basic tool in an MCP server:\n",
      "\n",
      "  * TypeScript\n",
      "  * Python\n",
      "\n",
      "    \n",
      "    \n",
      "    const server = new Server({\n",
      "      name: \"example-server\",\n",
      "      version: \"1.0.0\"\n",
      "    }, {\n",
      "      capabilities: {\n",
      "        tools: {}\n",
      "      }\n",
      "    });\n",
      "    \n",
      "    // Define available tools\n",
      "    server.setRequestHandler(ListToolsRequestSchema, async () => {\n",
      "      return {\n",
      "        tools: [{\n",
      "          name: \"calculate_sum\",\n",
      "          description: \"Add two numbers together\",\n",
      "          inputSchema: {\n",
      "            type: \"object\",\n",
      "            properties: {\n",
      "              a: { type: \"number\" },\n",
      "              b: { type: \"number\" }\n",
      "            },\n",
      "            required: [\"a\", \"b\"]\n",
      "          }\n",
      "        }]\n",
      "      };\n",
      "    });\n",
      "    \n",
      "    // Handle tool execution\n",
      "    server.setRequestHandler(CallToolRequestSchema, async (request) => {\n",
      "      if (request.params.name === \"calculate_sum\") {\n",
      "        const { a, b } = request.params.arguments;\n",
      "        return {\n",
      "          content: [\n",
      "            {\n",
      "              type: \"text\",\n",
      "              text: String(a + b)\n",
      "            }\n",
      "          ]\n",
      "        };\n",
      "      }\n",
      "      throw new Error(\"Tool not found\");\n",
      "    });\n",
      "    \n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Example tool patterns\n",
      "\n",
      "Here are some examples of types of tools that a server could provide:\n",
      "\n",
      "###\n",
      "\n",
      "â€‹\n",
      "\n",
      "System operations\n",
      "\n",
      "Tools that interact with the local system:\n",
      "\n",
      "    \n",
      "    \n",
      "    {\n",
      "      name: \"execute_command\",\n",
      "      description: \"Run a shell command\",\n",
      "      inputSchema: {\n",
      "        type: \"object\",\n",
      "        properties: {\n",
      "          command: { type: \"string\" },\n",
      "          args: { type: \"array\", items: { type: \"string\" } }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    \n",
      "\n",
      "###\n",
      "\n",
      "â€‹\n",
      "\n",
      "API integrations\n",
      "\n",
      "Tools that wrap external APIs:\n",
      "\n",
      "    \n",
      "    \n",
      "    {\n",
      "      name: \"github_create_issue\",\n",
      "      description: \"Create a GitHub issue\",\n",
      "      inputSchema: {\n",
      "        type: \"object\",\n",
      "        properties: {\n",
      "          title: { type: \"string\" },\n",
      "          body: { type: \"string\" },\n",
      "          labels: { type: \"array\", items: { type: \"string\" } }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    \n",
      "\n",
      "###\n",
      "\n",
      "â€‹\n",
      "\n",
      "Data processing\n",
      "\n",
      "Tools that transform or analyze data:\n",
      "\n",
      "    \n",
      "    \n",
      "    {\n",
      "      name: \"analyze_csv\",\n",
      "      description: \"Analyze a CSV file\",\n",
      "      inputSchema: {\n",
      "        type: \"object\",\n",
      "        properties: {\n",
      "          filepath: { type: \"string\" },\n",
      "          operations: {\n",
      "            type: \"array\",\n",
      "            items: {\n",
      "              enum: [\"sum\", \"average\", \"count\"]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    \n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Best practices\n",
      "\n",
      "When implementing tools:\n",
      "\n",
      "  1. Provide clear, descriptive names and descriptions\n",
      "  2. Use detailed JSON Schema definitions for parameters\n",
      "  3. Include examples in tool descriptions to demonstrate how the model should use them\n",
      "  4. Implement proper error handling and validation\n",
      "  5. Use progress reporting for long operations\n",
      "  6. Keep tool operations focused and atomic\n",
      "  7. Document expected return value structures\n",
      "  8. Implement proper timeouts\n",
      "  9. Consider rate limiting for resource-intensive operations\n",
      "  10. Log tool usage for debugging and monitoring\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Security considerations\n",
      "\n",
      "When exposing tools:\n",
      "\n",
      "###\n",
      "\n",
      "â€‹\n",
      "\n",
      "Input validation\n",
      "\n",
      "  * Validate all parameters against the schema\n",
      "  * Sanitize file paths and system commands\n",
      "  * Validate URLs and external identifiers\n",
      "  * Check parameter sizes and ranges\n",
      "  * Prevent command injection\n",
      "\n",
      "###\n",
      "\n",
      "â€‹\n",
      "\n",
      "Access control\n",
      "\n",
      "  * Implement authentication where needed\n",
      "  * Use appropriate authorization checks\n",
      "  * Audit tool usage\n",
      "  * Rate limit requests\n",
      "  * Monitor for abuse\n",
      "\n",
      "###\n",
      "\n",
      "â€‹\n",
      "\n",
      "Error handling\n",
      "\n",
      "  * Donâ€™t expose internal errors to clients\n",
      "  * Log security-relevant errors\n",
      "  * Handle timeouts appropriately\n",
      "  * Clean up resources after errors\n",
      "  * Validate return values\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Tool discovery and updates\n",
      "\n",
      "MCP supports dynamic tool discovery:\n",
      "\n",
      "  1. Clients can list available tools at any time\n",
      "  2. Servers can notify clients when tools change using `notifications/tools/list_changed`\n",
      "  3. Tools can be added or removed during runtime\n",
      "  4. Tool definitions can be updated (though this should be done carefully)\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Error handling\n",
      "\n",
      "Tool errors should be reported within the result object, not as MCP protocol-\n",
      "level errors. This allows the LLM to see and potentially handle the error.\n",
      "When a tool encounters an error:\n",
      "\n",
      "  1. Set `isError` to `true` in the result\n",
      "  2. Include error details in the `content` array\n",
      "\n",
      "Hereâ€™s an example of proper error handling for tools:\n",
      "\n",
      "  * TypeScript\n",
      "  * Python\n",
      "\n",
      "    \n",
      "    \n",
      "    try {\n",
      "      // Tool operation\n",
      "      const result = performOperation();\n",
      "      return {\n",
      "        content: [\n",
      "          {\n",
      "            type: \"text\",\n",
      "            text: `Operation successful: ${result}`\n",
      "          }\n",
      "        ]\n",
      "      };\n",
      "    } catch (error) {\n",
      "      return {\n",
      "        isError: true,\n",
      "        content: [\n",
      "          {\n",
      "            type: \"text\",\n",
      "            text: `Error: ${error.message}`\n",
      "          }\n",
      "        ]\n",
      "      };\n",
      "    }\n",
      "    \n",
      "\n",
      "This approach allows the LLM to see that an error occurred and potentially\n",
      "take corrective action or request human intervention.\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Testing tools\n",
      "\n",
      "A comprehensive testing strategy for MCP tools should cover:\n",
      "\n",
      "  * **Functional testing** : Verify tools execute correctly with valid inputs and handle invalid inputs appropriately\n",
      "  * **Integration testing** : Test tool interaction with external systems using both real and mocked dependencies\n",
      "  * **Security testing** : Validate authentication, authorization, input sanitization, and rate limiting\n",
      "  * **Performance testing** : Check behavior under load, timeout handling, and resource cleanup\n",
      "  * **Error handling** : Ensure tools properly report errors through the MCP protocol and clean up resources\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "YesNo\n",
      "\n",
      "[Prompts](/docs/concepts/prompts)[Sampling](/docs/concepts/sampling)\n",
      "\n",
      "[github](https://github.com/modelcontextprotocol)\n",
      "\n",
      "' metadata={'source': 'https://modelcontextprotocol.io/docs/concepts/tools'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanis\\AppData\\Local\\Temp\\ipykernel_1420\\3532148005.py:1: RuntimeWarning: coroutine 'parse_url_to_doc' was never awaited\n",
      "  doc = await parse_url_to_doc(\"https://modelcontextprotocol.io/docs/concepts/tools\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "doc = await parse_url_to_doc(\"https://modelcontextprotocol.io/docs/concepts/tools\")\n",
    "\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 15:36:54,758 - WARNING - Failed to fetch https://github.com/langchain-ai/local-deep-researcher/src/: Status code 404\n"
     ]
    }
   ],
   "source": [
    "with open('../../webscraping/github_urls.json', 'r') as f:\n",
    "    urls = json.load(f)\n",
    "\n",
    "    # Generator function to yield 10 items at a time\n",
    "    def batch_iterator(iterable, batch_size):\n",
    "        for i in range(0, len(iterable), batch_size):\n",
    "            yield iterable[i:i + batch_size]\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    # Create the iterator\n",
    "    iterator = batch_iterator(urls, batch_size)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # Use the iterator\n",
    "    for batch in iterator:\n",
    "        tasks = [parse_url_to_doc(url) for url in batch]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        documents.append(results)\n",
    "    documents = [item for sublist in documents for item in sublist]\n",
    "    documents =  [item for item in documents if item != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(encoding_name=\"cl100k_base\",\n",
    "    chunk_size=400, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "len(doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11946\n"
     ]
    }
   ],
   "source": [
    "doc_len=0\n",
    "import tiktoken\n",
    "for doc in doc_splits:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(doc.page_content))\n",
    "    doc_len += num_tokens\n",
    "    \n",
    "print(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 15:37:32,941 - INFO - HTTP Request: POST https://kanis-m8htxgs7-eastus.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "iterator = batch_iterator(doc_splits, 400)\n",
    "\n",
    "for doc in iterator:\n",
    "    try:\n",
    "        vector_store.add_documents(doc)\n",
    "    except Exception as ex:\n",
    "        logger.info(f\"{ex} caught, adding a 62 second sleep and retrying again\")\n",
    "        time.sleep(62)\n",
    "        vector_store.add_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 15:38:08,922 - INFO - HTTP Request: POST https://kanis-m8htxgs7-eastus.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'https://github.com/langchain-ai/langgraph-swarm-py/blob/main/README.md'}, page_content='# ðŸ¤– LangGraph Multi-Agent Swarm\\n\\nA Python library for creating swarm-style multi-agent systems using\\n[LangGraph](https://github.com/langchain-ai/langgraph). A swarm is a type of\\n[multi-agent](https://langchain-ai.github.io/langgraph/concepts/multi_agent)\\narchitecture where agents dynamically hand off control to one another based on\\ntheir specializations. The system remembers which agent was last active,\\nensuring that on subsequent interactions, the conversation resumes with that\\nagent.\\n\\n[![Swarm](/langchain-ai/langgraph-swarm-\\npy/raw/main/static/img/swarm.png)](/langchain-ai/langgraph-swarm-\\npy/blob/main/static/img/swarm.png)\\n\\n## Features\\n\\n  * ðŸ¤– **Multi-agent collaboration** \\\\- Enable specialized agents to work together and hand off context to each other\\n  * ðŸ› ï¸ **Customizable handoff tools** \\\\- Built-in tools for communication between agents\\n\\nThis library is built on top of [LangGraph](https://github.com/langchain-\\nai/langgraph), a powerful framework for building agent applications, and comes\\nwith out-of-box support for [streaming](https://langchain-\\nai.github.io/langgraph/how-tos/#streaming), [short-term and long-term\\nmemory](https://langchain-ai.github.io/langgraph/concepts/memory/) and [human-\\nin-the-loop](https://langchain-\\nai.github.io/langgraph/concepts/human_in_the_loop/)\\n\\n## Installation\\n\\n    \\n    \\n    pip install langgraph-swarm\\n\\n## Quickstart'),\n",
       "  0.8588871955871582),\n",
       " (Document(metadata={'source': 'https://github.com/langchain-ai/langgraph-swarm-py/blob/main/README.md'}, page_content='from typing_extensions import TypedDict, Annotated\\n    \\n    from langchain_core.messages import AnyMessage\\n    from langgraph.graph import StateGraph, add_messages\\n    from langgraph_swarm import SwarmState\\n    \\n    class AliceState(TypedDict):\\n        alice_messages: Annotated[list[AnyMessage], add_messages]\\n    \\n    # see this guide to learn how you can implement a custom tool-calling agent\\n    # https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/\\n    alice = (\\n        StateGraph(AliceState)\\n        .add_node(\"model\", ...)\\n        .add_node(\"tools\", ...)\\n        .add_edge(...)\\n        ...\\n        .compile()\\n    )\\n    \\n    # wrapper calling the agent\\n    def call_alice(state: SwarmState):\\n        # you can put any input transformation from parent state -> agent state\\n        # for example, you can invoke \"alice\" with \"task_description\" populated by the LLM\\n        response = alice.invoke({\"alice_messages\": state[\"messages\"]})\\n        # you can put any output transformation from agent state -> parent state\\n        return {\"messages\": response[\"alice_messages\"]}\\n    \\n    def call_bob(state: SwarmState):\\n        ...\\n\\nThen, you can create the swarm manually in the following way:\\n\\n    \\n    \\n    from langgraph_swarm import add_active_agent_router\\n    \\n    workflow = (\\n        StateGraph(SwarmState)\\n        .add_node(\"Alice\", call_alice, destinations=(\"Bob\",))\\n        .add_node(\"Bob\", call_bob, destinations=(\"Alice\",))\\n    )\\n    # this is the router that enables us to keep track of the last active agent\\n    workflow = add_active_agent_router(\\n        builder=workflow,\\n        route_to=[\"Alice\", \"Bob\"],\\n        default_active_agent=\"Alice\",\\n    )\\n    \\n    # compile the workflow\\n    app = workflow.compile()'),\n",
       "  0.8212690353393555),\n",
       " (Document(metadata={'source': 'https://python.langchain.com/docs/concepts/agents'}, page_content=\"# Agents\\n\\nBy themselves, language models can't take actions - they just output text.\\nAgents are systems that take a high-level task and use an LLM as a reasoning\\nengine to decide what actions to take and execute those actions.\\n\\n[LangGraph](/docs/concepts/architecture/#langgraph) is an extension of\\nLangChain specifically aimed at creating highly controllable and customizable\\nagents. We recommend that you use LangGraph for building agents.\\n\\nPlease see the following resources for more information:\\n\\n  * LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\\n  * [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)\\n\\n## Legacy agent concept: AgentExecutor\\u200b\\n\\nLangChain previously introduced the `AgentExecutor` as a runtime for agents.\\nWhile it served as an excellent starting point, its limitations became\\napparent when dealing with more sophisticated and customized agents. As a\\nresult, we're gradually phasing out `AgentExecutor` in favor of more flexible\\nsolutions in LangGraph.\\n\\n### Transitioning from AgentExecutor to langgraph\\u200b\\n\\nIf you're currently using `AgentExecutor`, don't worry! We've prepared\\nresources to help you:\\n\\n  1. For those who still need to use `AgentExecutor`, we offer a comprehensive guide on [how to use AgentExecutor](/docs/how_to/agent_executor/).\\n\\n  2. However, we strongly recommend transitioning to LangGraph for improved flexibility and control. To facilitate this transition, we've created a detailed [migration guide](/docs/how_to/migrate_agent/) to help you move from `AgentExecutor` to LangGraph seamlessly.\"),\n",
       "  0.7932901382446289),\n",
       " (Document(metadata={'source': 'https://langchain-ai.github.io/langgraph'}, page_content='[ ](https://github.com/langchain-ai/langgraph/edit/main/docs/docs/index.md\\n\"Edit this page\")\\n\\n# Home\\n\\n![LangGraph Logo](static/wordmark_dark.svg) ![LangGraph\\nLogo](static/wordmark_light.svg)\\n\\n![LangGraph Logo](https://langchain-\\nai.github.io/langgraph/static/wordmark_dark.svg)\\n\\n  \\n\\n[![Version](https://img.shields.io/pypi/v/langgraph.svg)](https://pypi.org/project/langgraph/)\\n[![Downloads](https://static.pepy.tech/badge/langgraph/month)](https://pepy.tech/project/langgraph)\\n[![Open Issues](https://img.shields.io/github/issues-raw/langchain-\\nai/langgraph)](https://github.com/langchain-ai/langgraph/issues)\\n[![Docs](https://img.shields.io/badge/docs-latest-blue)](https://langchain-\\nai.github.io/langgraph/)\\n\\nNote\\n\\nLooking for the JS version? See the [JS repo](https://github.com/langchain-\\nai/langgraphjs) and the [JS docs](https://langchain-\\nai.github.io/langgraphjs/).\\n\\nLangGraph â€” used by Replit, Uber, LinkedIn, GitLab and more â€” is a low-level\\norchestration framework for building controllable agents. While langchain\\nprovides integrations and composable components to streamline LLM application\\ndevelopment, the LangGraph library enables agent orchestration â€” offering\\ncustomizable architectures, long-term memory, and human-in-the-loop to\\nreliably handle complex tasks.\\n\\n    \\n    \\n    pip install -U langgraph\\n    \\n\\nTo learn more about how to use LangGraph, check out [the\\ndocs](https://langchain-ai.github.io/langgraph/). We show a simple example\\nbelow of how to create a ReAct agent.\\n\\n    \\n    \\n    # This code depends on pip install langchain[anthropic]\\n    from langgraph.prebuilt import create_react_agent\\n    \\n    def search(query: str):\\n        \"\"\"Call to surf the web.\"\"\"\\n        if \"sf\" in query.lower() or \"san francisco\" in query.lower():\\n            return \"It\\'s 60 degrees and foggy.\"\\n        return \"It\\'s 90 degrees and sunny.\"\\n    \\n    agent = create_react_agent(\"anthropic:claude-3-7-sonnet-latest\", tools=[search])\\n    agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n    )\\n    \\n\\n## Why use LangGraph?Â¶\\n\\nLangGraph is built for developers who want to build powerful, adaptable AI\\nagents. Developers choose LangGraph for:\\n\\n  * **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\n  * **Low-level and extensible.** Build custom agents with fully descriptive, low-level primitives â€“ free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\n  * **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\nLangGraph is trusted in production and powering agents for companies like:\\n\\n  * [Klarna](https://blog.langchain.dev/customers-klarna/): Customer support bot for 85 million active users\\n  * [Elastic](https://www.elastic.co/blog/elastic-security-generative-ai-features): Security AI assistant for threat detection\\n  * [Uber](https://dpe.org/sessions/ty-smith-adam-huda/this-year-in-ubers-ai-driven-developer-productivity-revolution/): Automated unit test generation\\n  * [Replit](https://www.langchain.com/breakoutagents/replit): Code generation\\n  * And many more ([see list here](https://www.langchain.com/built-with-langgraph))\\n\\n## LangGraphâ€™s ecosystemÂ¶\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any\\nLangChain product, giving developers a full suite of tools for building\\nagents. To improve your LLM application development, pair LangGraph with:\\n\\n  * [LangSmith](http://www.langchain.com/langsmith) â€” Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time.\\n  * [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/#langgraph-platform) â€” Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams â€” and iterate quickly with visual prototyping in [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/).\\n\\n## Pairing with LangGraph PlatformÂ¶\\n\\nWhile LangGraph is our open-source agent orchestration framework, enterprises\\nthat need scalable agent deployment can benefit from [LangGraph\\nPlatform](https://langchain-\\nai.github.io/langgraph/concepts/langgraph_platform/).\\n\\nLangGraph Platform can help engineering teams:\\n\\n  * **Accelerate agent development** : Quickly create agent UXs with configurable templates and [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/) for visualizing and debugging agent interactions.\\n  * **Deploy seamlessly** : We handle the complexity of deploying your agent. LangGraph Platform includes robust APIs for memory, threads, and cron jobs plus auto-scaling task queues & servers.\\n  * **Centralize agent management & reusability**: Discover, reuse, and manage agents across the organization. Business users can also modify agents without coding.\\n\\n## Additional resourcesÂ¶\\n\\n  * [LangChain Academy](https://academy.langchain.com/courses/intro-to-langgraph): Learn the basics of LangGraph in our free, structured course.\\n  * [Tutorials](https://langchain-ai.github.io/langgraph/tutorials/): Simple walkthroughs with guided examples on getting started with LangGraph.\\n  * [Templates](https://langchain-ai.github.io/langgraph/concepts/template_applications/): Pre-built reference apps for common agentic workflows (e.g. ReAct agent, memory, retrieval etc.) that can be cloned and adapted.\\n  * [How-to Guides](https://langchain-ai.github.io/langgraph/how-tos/): Quick, actionable code snippets for topics such as streaming, adding memory & persistence, and design patterns (e.g. branching, subgraphs, etc.).\\n  * [API Reference](https://langchain-ai.github.io/langgraph/reference/graphs/): Detailed reference on core classes, methods, how to use the graph and checkpointing APIs, and higher-level prebuilt components.\\n  * [Built with LangGraph](https://www.langchain.com/built-with-langgraph): Hear how industry leaders use LangGraph to ship powerful, production-ready AI applications.\\n\\n## AcknowledgementsÂ¶'),\n",
       "  0.7849984169006348),\n",
       " (Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/high_level'}, page_content='[ ](https://github.com/langchain-\\nai/langgraph/edit/main/docs/docs/concepts/high_level.md \"Edit this page\")\\n\\n# Why LangGraph?Â¶\\n\\n## LLM applicationsÂ¶\\n\\nLLMs make it possible to embed intelligence into a new class of applications.\\nThere are many patterns for building applications that use LLMs. Workflows\\nhave scaffolding of predefined code paths around LLM calls. LLMs can direct\\nthe control flow through these predefined code paths, which some consider to\\nbe an \"agentic system\". In other cases, it\\'s possible to remove this\\nscaffolding, creating autonomous agents that can\\n[plan](https://huyenchip.com/2025/01/07/agents.html), take actions via [tool\\ncalls](https://python.langchain.com/docs/concepts/tool_calling/), and directly\\nrespond [to the feedback from their own\\nactions](https://research.google/blog/react-synergizing-reasoning-and-acting-\\nin-language-models/) with further actions.\\n\\n![Agent Workflow](../img/agent_workflow.png)\\n\\n## What LangGraph providesÂ¶\\n\\nLangGraph provides low-level supporting infrastructure that sits underneath\\n_any_ workflow or agent. It does not abstract prompts or architecture, and\\nprovides three central benefits:\\n\\n### PersistenceÂ¶\\n\\nLangGraph has a [persistence layer](https://langchain-\\nai.github.io/langgraph/concepts/persistence/), which offers a number of\\nbenefits:\\n\\n  * [Memory](https://langchain-ai.github.io/langgraph/concepts/memory/): LangGraph persists arbitrary aspects of your application\\'s state, supporting memory of conversations and other updates within and across user interactions;\\n  * [Human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/): Because state is checkpointed, execution can be interrupted and resumed, allowing for decisions, validation, and corrections via human input.\\n\\n### StreamingÂ¶\\n\\nLangGraph also provides support for [streaming](../../how-tos/#streaming)\\nworkflow / agent state to the user (or developer) over the course of\\nexecution. LangGraph supports streaming of both events ([such as feedback from\\na tool call](../../how-tos/streaming/#updates)) and [tokens from LLM\\ncalls](../../how-tos/streaming-tokens/) embedded in an application.\\n\\n### Debugging and DeploymentÂ¶\\n\\nLangGraph provides an easy onramp for testing, debugging, and deploying\\napplications via [LangGraph Platform](https://langchain-\\nai.github.io/langgraph/concepts/langgraph_platform/). This includes\\n[Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/),\\nan IDE that enables visualization, interaction, and debugging of workflows or\\nagents. This also includes numerous [options](https://langchain-\\nai.github.io/langgraph/tutorials/deployment/) for deployment.\\n\\nWas this page helpful?\\n\\nThanks for your feedback!\\n\\nThanks for your feedback! Please help us improve this page by adding to the\\ndiscussion below.\\n\\n## Comments\\n\\n'),\n",
       "  0.7819156646728516),\n",
       " (Document(metadata={'source': 'https://github.com/langchain-ai/langgraph-swarm-py/blob/main/README.md'}, page_content='## Installation\\n\\n    \\n    \\n    pip install langgraph-swarm\\n\\n## Quickstart\\n\\n    \\n    \\n    pip install langgraph-swarm langchain-openai\\n    \\n    export OPENAI_API_KEY=<your_api_key>\\n    \\n    \\n    from langchain_openai import ChatOpenAI\\n    \\n    from langgraph.checkpoint.memory import InMemorySaver\\n    from langgraph.prebuilt import create_react_agent\\n    from langgraph_swarm import create_handoff_tool, create_swarm\\n    \\n    model = ChatOpenAI(model=\"gpt-4o\")\\n    \\n    def add(a: int, b: int) -> int:\\n        \"\"\"Add two numbers\"\"\"\\n        return a + b\\n    \\n    alice = create_react_agent(\\n        model,\\n        [add, create_handoff_tool(agent_name=\"Bob\")],\\n        prompt=\"You are Alice, an addition expert.\",\\n        name=\"Alice\",\\n    )\\n    \\n    bob = create_react_agent(\\n        model,\\n        [create_handoff_tool(agent_name=\"Alice\", description=\"Transfer to Alice, she can help with math\")],\\n        prompt=\"You are Bob, you speak like a pirate.\",\\n        name=\"Bob\",\\n    )\\n    \\n    checkpointer = InMemorySaver()\\n    workflow = create_swarm(\\n        [alice, bob],\\n        default_active_agent=\"Alice\"\\n    )\\n    app = workflow.compile(checkpointer=checkpointer)\\n    \\n    config = {\"configurable\": {\"thread_id\": \"1\"}}\\n    turn_1 = app.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"i\\'d like to speak to Bob\"}]},\\n        config,\\n    )\\n    print(turn_1)\\n    turn_2 = app.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s 5 + 7?\"}]},\\n        config,\\n    )\\n    print(turn_2)\\n\\n## Memory'),\n",
       "  0.7813315391540527),\n",
       " (Document(metadata={'source': 'https://python.langchain.com/docs/how_to/chatbots_tools'}, page_content=\"This [LangSmith\\ntrace](https://smith.langchain.com/public/9e6b000d-08aa-4c5a-ac83-2fdf549523cb/r)\\nshows what's going on under the hood.\\n\\n## Further reading\\u200b\\n\\nFor more on how to build agents, check these [LangGraph](https://langchain-\\nai.github.io/langgraph/) guides:\\n\\n  * [agents conceptual guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\\n  * [agents tutorials](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/)\\n  * [create_react_agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/)\\n\\nFor more on tool usage, you can also check out [this use case\\nsection](/docs/how_to/#tools).\"),\n",
       "  0.7812042236328125),\n",
       " (Document(metadata={'source': 'https://langchain-ai.github.io/langgraph'}, page_content='[ ](https://github.com/langchain-ai/langgraph/edit/main/docs/docs/index.md\\n\"Edit this page\")\\n\\n# Home\\n\\n![LangGraph Logo](static/wordmark_dark.svg) ![LangGraph\\nLogo](static/wordmark_light.svg)\\n\\n![LangGraph Logo](https://langchain-\\nai.github.io/langgraph/static/wordmark_dark.svg)\\n\\n  \\n\\n[![Version](https://img.shields.io/pypi/v/langgraph.svg)](https://pypi.org/project/langgraph/)\\n[![Downloads](https://static.pepy.tech/badge/langgraph/month)](https://pepy.tech/project/langgraph)\\n[![Open Issues](https://img.shields.io/github/issues-raw/langchain-\\nai/langgraph)](https://github.com/langchain-ai/langgraph/issues)\\n[![Docs](https://img.shields.io/badge/docs-latest-blue)](https://langchain-\\nai.github.io/langgraph/)\\n\\nNote\\n\\nLooking for the JS version? See the [JS repo](https://github.com/langchain-\\nai/langgraphjs) and the [JS docs](https://langchain-\\nai.github.io/langgraphjs/).\\n\\nLangGraph â€” used by Replit, Uber, LinkedIn, GitLab and more â€” is a low-level\\norchestration framework for building controllable agents. While langchain\\nprovides integrations and composable components to streamline LLM application\\ndevelopment, the LangGraph library enables agent orchestration â€” offering\\ncustomizable architectures, long-term memory, and human-in-the-loop to\\nreliably handle complex tasks.\\n\\n    \\n    \\n    pip install -U langgraph\\n    \\n\\nTo learn more about how to use LangGraph, check out [the\\ndocs](https://langchain-ai.github.io/langgraph/). We show a simple example\\nbelow of how to create a ReAct agent.\\n\\n    \\n    \\n    # This code depends on pip install langchain[anthropic]\\n    from langgraph.prebuilt import create_react_agent\\n    \\n    def search(query: str):\\n        \"\"\"Call to surf the web.\"\"\"\\n        if \"sf\" in query.lower() or \"san francisco\" in query.lower():\\n            return \"It\\'s 60 degrees and foggy.\"\\n        return \"It\\'s 90 degrees and sunny.\"\\n    \\n    agent = create_react_agent(\"anthropic:claude-3-7-sonnet-latest\", tools=[search])\\n    agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n    )\\n    \\n\\n## Why use LangGraph?Â¶\\n\\nLangGraph is built for developers who want to build powerful, adaptable AI\\nagents. Developers choose LangGraph for:\\n\\n  * **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\n  * **Low-level and extensible.** Build custom agents with fully descriptive, low-level primitives â€“ free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\n  * **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\nLangGraph is trusted in production and powering agents for companies like:\\n\\n  * [Klarna](https://blog.langchain.dev/customers-klarna/): Customer support bot for 85 million active users\\n  * [Elastic](https://www.elastic.co/blog/elastic-security-generative-ai-features): Security AI assistant for threat detection\\n  * [Uber](https://dpe.org/sessions/ty-smith-adam-huda/this-year-in-ubers-ai-driven-developer-productivity-revolution/): Automated unit test generation\\n  * [Replit](https://www.langchain.com/breakoutagents/replit): Code generation\\n  * And many more ([see list here](https://www.langchain.com/built-with-langgraph))\\n\\n## LangGraphâ€™s ecosystemÂ¶\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any\\nLangChain product, giving developers a full suite of tools for building\\nagents. To improve your LLM application development, pair LangGraph with:\\n\\n  * [LangSmith](http://www.langchain.com/langsmith) â€” Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time.\\n  * [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/#langgraph-platform) â€” Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams â€” and iterate quickly with visual prototyping in [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/).\\n\\n## Pairing with LangGraph PlatformÂ¶\\n\\nWhile LangGraph is our open-source agent orchestration framework, enterprises\\nthat need scalable agent deployment can benefit from [LangGraph\\nPlatform](https://langchain-\\nai.github.io/langgraph/concepts/langgraph_platform/).\\n\\nLangGraph Platform can help engineering teams:\\n\\n  * **Accelerate agent development** : Quickly create agent UXs with configurable templates and [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/) for visualizing and debugging agent interactions.\\n  * **Deploy seamlessly** : We handle the complexity of deploying your agent. LangGraph Platform includes robust APIs for memory, threads, and cron jobs plus auto-scaling task queues & servers.\\n  * **Centralize agent management & reusability**: Discover, reuse, and manage agents across the organization. Business users can also modify agents without coding.\\n\\n## Additional resourcesÂ¶\\n\\n  * [LangChain Academy](https://academy.langchain.com/courses/intro-to-langgraph): Learn the basics of LangGraph in our free, structured course.\\n  * [Tutorials](https://langchain-ai.github.io/langgraph/tutorials/): Simple walkthroughs with guided examples on getting started with LangGraph.\\n  * [Templates](https://langchain-ai.github.io/langgraph/concepts/template_applications/): Pre-built reference apps for common agentic workflows (e.g. ReAct agent, memory, retrieval etc.) that can be cloned and adapted.\\n  * [How-to Guides](https://langchain-ai.github.io/langgraph/how-tos/): Quick, actionable code snippets for topics such as streaming, adding memory & persistence, and design patterns (e.g. branching, subgraphs, etc.).\\n  * [API Reference](https://langchain-ai.github.io/langgraph/reference/graphs/): Detailed reference on core classes, methods, how to use the graph and checkpointing APIs, and higher-level prebuilt components.\\n  * [Built with LangGraph](https://www.langchain.com/built-with-langgraph): Hear how industry leaders use LangGraph to ship powerful, production-ready AI applications.\\n\\n## AcknowledgementsÂ¶\\n\\nLangGraph is inspired by [Pregel](https://research.google/pubs/pub37252/) and\\n[Apache Beam](https://beam.apache.org/). The public interface draws\\ninspiration from [NetworkX](https://networkx.org/documentation/latest/).\\nLangGraph is built by LangChain Inc, the creators of LangChain, but can be\\nused without LangChain.\\n\\nWas this page helpful?\\n\\nThanks for your feedback!\\n\\nThanks for your feedback! Please help us improve this page by adding to the\\ndiscussion below.\\n\\n'),\n",
       "  0.779752254486084),\n",
       " (Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/high_level'}, page_content='[ ](https://github.com/langchain-\\nai/langgraph/edit/main/docs/docs/concepts/high_level.md \"Edit this page\")\\n\\n# Why LangGraph?Â¶\\n\\n## LLM applicationsÂ¶\\n\\nLLMs make it possible to embed intelligence into a new class of applications.\\nThere are many patterns for building applications that use LLMs. Workflows\\nhave scaffolding of predefined code paths around LLM calls. LLMs can direct\\nthe control flow through these predefined code paths, which some consider to\\nbe an \"agentic system\". In other cases, it\\'s possible to remove this\\nscaffolding, creating autonomous agents that can\\n[plan](https://huyenchip.com/2025/01/07/agents.html), take actions via [tool\\ncalls](https://python.langchain.com/docs/concepts/tool_calling/), and directly\\nrespond [to the feedback from their own\\nactions](https://research.google/blog/react-synergizing-reasoning-and-acting-\\nin-language-models/) with further actions.\\n\\n![Agent Workflow](../img/agent_workflow.png)\\n\\n## What LangGraph providesÂ¶\\n\\nLangGraph provides low-level supporting infrastructure that sits underneath\\n_any_ workflow or agent. It does not abstract prompts or architecture, and\\nprovides three central benefits:\\n\\n### PersistenceÂ¶\\n\\nLangGraph has a [persistence layer](https://langchain-\\nai.github.io/langgraph/concepts/persistence/), which offers a number of\\nbenefits:\\n\\n  * [Memory](https://langchain-ai.github.io/langgraph/concepts/memory/): LangGraph persists arbitrary aspects of your application\\'s state, supporting memory of conversations and other updates within and across user interactions;\\n  * [Human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/): Because state is checkpointed, execution can be interrupted and resumed, allowing for decisions, validation, and corrections via human input.\\n\\n### StreamingÂ¶\\n\\nLangGraph also provides support for [streaming](../../how-tos/#streaming)\\nworkflow / agent state to the user (or developer) over the course of\\nexecution. LangGraph supports streaming of both events ([such as feedback from\\na tool call](../../how-tos/streaming/#updates)) and [tokens from LLM\\ncalls](../../how-tos/streaming-tokens/) embedded in an application.\\n\\n### Debugging and DeploymentÂ¶\\n\\nLangGraph provides an easy onramp for testing, debugging, and deploying\\napplications via [LangGraph Platform](https://langchain-\\nai.github.io/langgraph/concepts/langgraph_platform/). This includes\\n[Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/),\\nan IDE that enables visualization, interaction, and debugging of workflows or\\nagents. This also includes numerous [options](https://langchain-\\nai.github.io/langgraph/tutorials/deployment/) for deployment.\\n\\nWas this page helpful?\\n\\nThanks for your feedback!\\n\\nThanks for your feedback! Please help us improve this page by adding to the\\ndiscussion below.\\n\\n## Comments'),\n",
       "  0.7788877487182617),\n",
       " (Document(metadata={'source': 'https://github.com/langchain-ai/langgraph-swarm-py/blob/main/README.md'}, page_content='## Memory\\n\\nYou can add [short-term](https://langchain-ai.github.io/langgraph/how-\\ntos/persistence/) and [long-term](https://langchain-\\nai.github.io/langgraph/how-tos/cross-thread-persistence/)\\n[memory](https://langchain-ai.github.io/langgraph/concepts/memory/) to your\\nswarm multi-agent system. Since `create_swarm()` returns an instance of\\n`StateGraph` that needs to be compiled before use, you can directly pass a\\n[checkpointer](https://langchain-\\nai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver)\\nor a [store](https://langchain-\\nai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)\\ninstance to the `.compile()` method:\\n\\n    \\n    \\n    from langgraph.checkpoint.memory import InMemorySaver\\n    from langgraph.store.memory import InMemoryStore\\n    \\n    # short-term memory\\n    checkpointer = InMemorySaver()\\n    # long-term memory\\n    store = InMemoryStore()\\n    \\n    model = ...\\n    alice = ...\\n    bob = ...\\n    \\n    workflow = create_swarm(\\n        [alice, bob],\\n        default_active_agent=\"Alice\"\\n    )\\n    \\n    # Compile with checkpointer/store\\n    app = workflow.compile(\\n        checkpointer=checkpointer,\\n        store=store\\n    )\\n\\nImportant\\n\\nAdding [short-term memory](https://langchain-\\nai.github.io/langgraph/concepts/persistence/) is crucial for maintaining\\nconversation state across multiple interactions. Without it, the swarm would\\n\"forget\" which agent was last active and lose the conversation history. Make\\nsure to always compile the swarm with a checkpointer if you plan to use it in\\nmulti-turn conversations; e.g., `workflow.compile(checkpointer=checkpointer)`.\\n\\n## How to customize'),\n",
       "  0.7763757705688477)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search_with_relevance_scores(\"implement a langgraph swarm agent\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
