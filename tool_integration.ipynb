{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e3a2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "import yaml\n",
    "import json\n",
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from typing import List\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "from typing import Annotated\n",
    "from typing import NamedTuple\n",
    "from experiments.visualization.dict_to_reactflow import dict_to_tree_positions\n",
    "from experiments.utils.fetch_docs import fetch_documents\n",
    "from experiments.phase1_json_dfs import compiler_graph\n",
    "# from experiments.code_reflection_agent import final_agent\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        # logging.FileHandler(\"scraper.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "agent_architecture_urls = [\"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute\",\n",
    " \"https://langchain-ai.github.io/langgraph/tutorials/self-discover/self-discover\",\n",
    "]\n",
    "\n",
    "\n",
    "template = \"\"\"Your job is to get information from a user about what kind of agent they wish to build.\n",
    "\n",
    "You should get the following information from them:\n",
    "\n",
    "- What the objective of the agent is\n",
    "- Various usecases of the agent \n",
    "- Some examples of what the agent will be doing (Input and expected output pairs)\n",
    "\n",
    "If you are not able to discern this info, ask them to clarify! Do not attempt to wildly guess.\n",
    "\n",
    "After you are able to discern all the information, call the tool AgentInstruction\"\"\"\n",
    "\n",
    "\n",
    "class AgentInstructions(BaseModel):\n",
    "    \"\"\"Instructions on how to build the Agent\"\"\"\n",
    "    objective: str = Field(description= \"What is the primary objective of the agent\")\n",
    "    usecases: List[str] = Field(description= \"What are the various responsibilities of the agent which it needs to fulfill\")\n",
    "    examples : str = Field(description= \"What are some examples of the usage of the agent (input query and expected output from the agent) ?\")\n",
    "\n",
    "class ArchEvaluationReport(BaseModel):\n",
    "    \"\"\"Class to represent the architecture evaluation report\"\"\"\n",
    "    name: str = Field(description=\"Name of the agent architecture being evaluated\")\n",
    "    highlights: str = Field(description=\"Concise summary of the architecture in 5 lines\")\n",
    "    evaluation_score: int = Field(description=\"evaluation of suitability of the agentic_architecture against user requirements from 1-10, 1 being least relevant to 10 being most relevant\")\n",
    "    justification: str = Field( description=\"Justification for the score\")\n",
    "    tailored_design: str = Field(description=\"Tailored design using the architecture\")\n",
    "    \n",
    "class ArchEvaluationWithUrl(NamedTuple):\n",
    "    url: str\n",
    "    report: ArchEvaluationReport\n",
    "\n",
    "class AgentBuilderState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    arch_evaluation_reports: Annotated[List[ArchEvaluationWithUrl], operator.add] = Field(\"list of agent architectures suggested in map-reduce step\")\n",
    "    best_agent_architecture: ArchEvaluationWithUrl = Field(\"The agent architecture best suited to above requirements\")\n",
    "    json_code: str = Field(\"The json code generated\")\n",
    "    python_code: str = Field(\"The Python code generated\")\n",
    "    reactflow_json: str = Field(\"The ReactFlow code generated\")\n",
    "\n",
    "\n",
    "class ArchitectureEvaluationState(MessagesState):\n",
    "    agent_instructions: AgentInstructions = Field(\"the requirement analysis generated by the model.\")\n",
    "    url: str = Field(\"url of the agent architecture to evaluate against\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "def requirement_analysis_node(state: AgentBuilderState):\n",
    "    \n",
    "    llm_with_tool = llm.bind_tools([AgentInstructions])\n",
    "    response = llm_with_tool.invoke([SystemMessage(content=template)] + state[\"messages\"])\n",
    "    \n",
    "      # Construct the final answer from the arguments of the last tool call  \n",
    "    if len(response.tool_calls) == 0:\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    agent_instructions = response.tool_calls[0]\n",
    "    agent_instructions = AgentInstructions(**agent_instructions[\"args\"])\n",
    "    \n",
    "    return {\"messages\": [response], \"agent_instructions\": agent_instructions}\n",
    "\n",
    "ARCH_EVALUATION_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are tasked with assessing the provided agentic architecture documentation to determine its relevance and applicability to the user requirements outlined below.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Agentic Architecture Documentation:\n",
    "{agent_architecture}\n",
    "\n",
    "- User Requirements:- Objectives: {objective}\n",
    "- Use Cases: {responsibilities}\n",
    "- Examples: {examples}\n",
    "\n",
    "\n",
    "Deliverables:\n",
    "Your evaluation should be presented in the following structured format:\n",
    "\n",
    "- Architecture Name:\n",
    "Provide the name of the agent architecture being assessed.\n",
    "- Concise Identifier:\n",
    "Suggest a brief, descriptive name for the architecture that encapsulates its purpose.\n",
    "- Key Highlights (2-3 Lines):\n",
    "Identify and summarize the most significant aspects or features of the architecture.\n",
    "- Feature Summary:\n",
    "Offer a detailed overview of the architecture's unique elements, functionalities, and capabilities.\n",
    "- Relevance Score (1-10):\n",
    "Assign a score based on the alignment between the architecture's features and the user's requirements (1 = minimally relevant, 10 = highly relevant).\n",
    "- Score Justification:\n",
    "Provide a clear and concise rationale (5-10 sentences) for the relevance score, highlighting how specific features match—or fail to match—the user's objectives, use cases, and examples.\n",
    "- Implementation Proposal:\n",
    "Outline a tailored approach for leveraging the architecture to meet the user’s requirements. Be specific and actionable, addressing how it can fulfill the stated objectives and responsibilities.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def architecture_evaluation_map_node(state: AgentBuilderState):\n",
    "    return [Send(\"evaluate_against_architecture\", {\"agent_instructions\": state[\"agent_instructions\"], \"url\": url}) for url in agent_architecture_urls]\n",
    "\n",
    "def route_state(state: AgentBuilderState):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"add_tool_message\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"requirement_analysis\"\n",
    "\n",
    "def evaluate_against_architecture(state: ArchitectureEvaluationState):\n",
    "    agent_instructions: AgentInstructions = state[\"agent_instructions\"]\n",
    "    url: str = state[\"url\"]\n",
    "    llm_with_structured_output = llm.with_structured_output(ArchEvaluationReport)\n",
    "    archEvaluationReport: ArchEvaluationReport = llm_with_structured_output.invoke(\n",
    "        [SystemMessage(content=ARCH_EVALUATION_PROMPT.format(agent_architecture=fetch_documents(url),\n",
    "                                                             objective=agent_instructions.objective,\n",
    "                                                             responsibilities=agent_instructions.usecases,\n",
    "                                                             examples = agent_instructions.examples))])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Evaluated architecture {url}, arch_name: {archEvaluationReport.name}\")],\n",
    "        \"arch_evaluation_reports\": [ArchEvaluationWithUrl(url,archEvaluationReport)],\n",
    "    }\n",
    "\n",
    "def best_architecture(state: AgentBuilderState):\n",
    "    \"\"\"Select the best architecture based on the evaluation reports.\"\"\"\n",
    "    # Sort the architectures based on their evaluation scores\n",
    "    arch_reports : List[ArchEvaluationWithUrl] = state[\"arch_evaluation_reports\"]\n",
    "    sorted_architectures = sorted(arch_reports, key=lambda x: x.report.evaluation_score , reverse=True)\n",
    "    \n",
    "    # Select the best architecture (the first one in the sorted list)\n",
    "    best_architecture = sorted_architectures[0]\n",
    "    \n",
    "    print(\"found the best architecture\")\n",
    "    \n",
    "    # Return the best architecture as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Best architecture selected!\")],\n",
    "        \"best_agent_architecture\": best_architecture,\n",
    "    }\n",
    "\n",
    "\n",
    "AGENT_KERNEL_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Task Overview:\n",
    "        Design a langgraph StateGraph object implementing the {agent_architecture_name} architecture, tailored to fulfill the user requirements defined below\n",
    "\n",
    "        <Requirements>\n",
    "        Objectives: {objective}\n",
    "        usecases: {responsibilities}\n",
    "        examples: {examples}\n",
    "        </Requirements>\n",
    "\n",
    "        Provided Documentation:\n",
    "        Refer to the documentation for {agent_architecture_name} below to guide your implementation:\n",
    "        <Documentation for {agent_architecture_name}>\n",
    "        {agent_architecture}\n",
    "        </Documentation for {agent_architecture_name}>\n",
    "        \n",
    "        Implementation Suggestions:\n",
    "        Apply the {agent_architecture_name} architecture concepts and align them with the user requirements provided. Suggestions on tailoring the implementation:\n",
    "        {agent_tailored}\n",
    "        \n",
    "        Expected Output:\n",
    "        Your task is to produce a compiled StateGraph object.\n",
    "\n",
    "        Guidelines for Code Generation:\n",
    "        - Accuracy: Avoid hallucinations or speculative assumptions when writing code. Refer exclusively to the provided documentation.\n",
    "        - Understanding: Thoroughly comprehend the architecture and examples of code.\n",
    "        - Customization: Generate code tailored specifically to meet the user requirements.\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "def agent_kernel_builder(state: AgentBuilderState):\n",
    "    \"\"\"Build the agent kernel using the best architecture.\"\"\"\n",
    "    best_architecture: ArchEvaluationWithUrl = state[\"best_agent_architecture\"]\n",
    "    agent_instructions : AgentInstructions = state[\"agent_instructions\"]\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    agent_architecture_url : str = best_architecture.url\n",
    "    agent_architecture_report : ArchEvaluationReport = best_architecture.report\n",
    "    # agent_architecture_report.name\n",
    "    #agent_architecture_report.highlights\n",
    "    #agent_architecture_report.justification\n",
    "    #agent_architecture_report.tailored_design\n",
    "    \n",
    "    response =  llm.invoke([SystemMessage(content=AGENT_KERNEL_PROMPT.format(\n",
    "        objective=agent_instructions.objective,\n",
    "        responsibilities=agent_instructions.usecases,\n",
    "        examples = agent_instructions.examples,\n",
    "        # langgraph_glossary=fetch_documents(langgraph_glossary_url),\n",
    "        agent_tailored=agent_architecture_report.tailored_design,\n",
    "        agent_architecture_name = agent_architecture_report.name,\n",
    "        agent_architecture=fetch_documents(agent_architecture_url)))])\n",
    "    \n",
    "    # Return the generated agent kernel as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated agent kernel code!\")],\n",
    "        \"python_code\": response.content,\n",
    "    }\n",
    "\n",
    "CODE_TO_JSON_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with converting the following stategraph comPilation code into a JSON. \n",
    "\n",
    "Contextual documents for understanding code:\n",
    "{documents}\n",
    "\n",
    "The Input code is as follows:\n",
    "{code_snippet}\n",
    "\n",
    "OUTPUT: Explaination and JSON. Do not include any code blocks. Seperate the JSON and explaination blocks and ensure that there is an explaination for each line of JSON produced but keep the blocks seperated.\n",
    "Each Output JSON will have a nodes sections containing all the nodes and an edges section\n",
    "\n",
    "Please follow:\n",
    "1. Produce the explaination first and then the JSON after it. DO not produce the JSON first. \n",
    "2. For any conditional edges, please include all the nodes that the source of a conditional edge can reach as part of the explaination.\n",
    "3. Any Edge entry in the JSON can only be conditional(mention conditional: true) if the source for that edge acts as a source for multiple edges. If you cannot point to atleast 2 targets for 1 source, then that source will not have any conditional edges\n",
    "4. A source can have any number of targets. Please write the explaination for each source node to target node edge\n",
    "5. Please ensure that the JSON starts with __START__ node and __END__ node with the correct edges from and to them\n",
    "6. Ensure all elements in the nodes sections of the output json contain the following fields: Schema_info, input_schema, output_schema, description, function_name. Please do not return any entries in the nodes without these fields and these fields can't be empty\n",
    "7. Ensure all elements in the edges sections of the output json contain the following fields: source, target, routing_conditions, conditional. Please do not return any entries in the edges without these fields and they can't be empty\n",
    "8. Every node should be a part of atleast one edge, Please ensure this is followed\n",
    "9. Attach the code snippet for each node aswell that. Please extract it from the Input code\n",
    "\n",
    "\n",
    "Example output JSON for a node:\n",
    "                                             \n",
    "   {{\n",
    "        \"id\": \"code_node\"\n",
    "        \"schema_info\": /\"/\"/\"CodeWriterState:\n",
    "        type: TypedDict\n",
    "        fields:\n",
    "        - name: user_query\n",
    "          type: str\n",
    "        - name: execution_result\n",
    "            type: str/\"/\"/\",\n",
    "        \"input_schema\": \"CodeWriterState\",\n",
    "        \"output_schema\":\"RequiremenCodeWriterStatetAnalysisState\",\n",
    "        \"description\":\"This node analyzes the user_query, if the query is to write a code, it will make a tool call to run the proposed code. This node returns command object\",\n",
    "        \"function_name\": \"code_step\"\n",
    "    }}\n",
    "\n",
    "Example output JSON for an edge:\n",
    "edge:{{ source: \"abc\", target: \"cde\", routing_condition: \"if abc made a tool call then go to cde\", \"conditional\": true}}\n",
    "edge:{{ source: \"abc\", target: \"xyz\", routing_condition: \"if abc made an interupt to a human then go to xyz\", \"conditional\": true}}\n",
    "edge:{{ source: \"xyz\", target: \"_END_\", routing_condition: \"no nodes to go after xyz, we have our final output for this path\", \"conditional\": false}}\n",
    "\n",
    "\n",
    "High level JSON format of the graph\n",
    "\n",
    "{{\n",
    "    \"nodes\": [\n",
    "        {{ ... }},\n",
    "        {{ ... }}\n",
    "    ],\n",
    "    \"edges\": [\n",
    "        {{ ... }},\n",
    "        {{ ... }}\n",
    "    ]\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "def code_to_json_node(state: AgentBuilderState):\n",
    "    \"\"\"Convert the generated code to JSON.\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([SystemMessage(content=CODE_TO_JSON_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        ))])\n",
    "    \n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated JSON code!\")],\n",
    "        \"json_code\": json_code_ouptut.content,\n",
    "    }\n",
    "\n",
    "\n",
    "JSON_CODE_COMBINE_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are tasked with verifying and updating the provided JSON that represents the nodes and edges of the langgraph to ensure it is correct with respect to the input code.\n",
    "\n",
    "Contextual Documents for Understanding Code:\n",
    "{documents}\n",
    "\n",
    "Input Code:\n",
    "<Input code>{code_snippet}</Input code>\n",
    "JSON:\n",
    "<JSON>{node_json}</JSON>\n",
    "\n",
    "OUTPUT: JSON\n",
    "Your task is divided into two parts:\n",
    "- Validation: Verify that the JSON adheres to the rules outlined below.\n",
    "- Correction and Augmentation: If the JSON is incorrect or incomplete, update it with a clear justification for every change, and include the code snippet for each node extracted from the input code.\n",
    "\n",
    "Rules for Validation and Update:\n",
    "- Conditional Edges:- An edge can be marked as conditional: true only if its source acts as a source for multiple edges (i.e., at least two targets).\n",
    "- If the source does not meet this condition, then it cannot have conditional edges.\n",
    "\n",
    "- Edge Targets:- Each source can have any number of targets. This flexibility must be maintained.\n",
    "\n",
    "- Start and End Nodes:- The JSON must begin with the __START__ node and conclude with the __END__ node, with correct edges to and from them. Edges into the END node can also be conditional if they meet the above mentioned conditions      \n",
    "\n",
    "- Node Structure:- Each node entry in the nodes section of the JSON must include the following non-empty fields:- schema_info\n",
    "- id\n",
    "- schema_info\n",
    "- input_schema\n",
    "- output_schema\n",
    "- description\n",
    "- function_name\n",
    "\n",
    "\n",
    "- Edge Structure:- Each edge entry in the edges section of the JSON must include the following non-empty fields:- source\n",
    "- target\n",
    "- routing_conditions\n",
    "- conditional\n",
    "\n",
    "\n",
    "- Node-Edge Relationship:- Every node must be part of at least one edge. Ensure this relationship is consistently followed.\n",
    "\n",
    "- Node Code Snippets:- Attach a code field to every node in the JSON, extracted directly from the input code.\n",
    "\n",
    "- Schema Requirements:- The final JSON must conform to the schema provided below:\n",
    "\n",
    "\n",
    "Schema for JSON. Ensure the following schema is followed. No field should be missing for any node or edge:\n",
    "- Node Example:\n",
    "\n",
    "{{\n",
    "  \"code_node\": {{\n",
    "    \"id\" : \"<id of the node, similar to name>\"\n",
    "    \"schema_info\": \"<define the class structure of the state of a node>\",\n",
    "    \"input_schema\": \"<input state object>\",\n",
    "    \"output_schema\": \"<output state object>\",\n",
    "    \"description\": \"<description>\",\n",
    "    \"function_name\": \"<function_name>\",\n",
    "    \"code\": \"<python_code>\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\n",
    "- Edge Example:\n",
    "\n",
    "{{\n",
    "  \"edge\": {{\n",
    "    \"source\": \"<source_node>\",\n",
    "    \"target\": \"<target_node>\",\n",
    "    \"routing_condition\": \"<routing_condition>\",\n",
    "    \"conditional\": true/false\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\n",
    "Key Instructions:\n",
    "- Do not update any pre-existing field of the JSON unless you have an extremely strong justification for doing so.\n",
    "- Clearly document the reasoning behind any additions, updates, or modifications to the JSON. Justifications should draw inspiration from the contextual documents mentioned earlier.\n",
    "- Ensure conditional edges strictly adhere to the rules outlined above.\n",
    "- Input_Schema and output_schemas can only have value None in JSON for START and END nodes. Please follow this without fail\n",
    "- Include a code field for each code_node entry, with the exact code that corresponds to the node in the input code.\n",
    "\"\"\")\n",
    "\n",
    "json_formatter_doc = \"\"\"\n",
    "You will be given a json by the user, along with explanations and markdown, your target is to filter and only output the json schema.\n",
    "\n",
    "Output: Only serialized JSON, no explanations or markdown, no ``` notations.\n",
    "\n",
    "the response would be starting with a '{' and ending with '}'\"\"\"\n",
    "\n",
    "\n",
    "def json_better_node(state: AgentBuilderState):\n",
    "    \"\"\"Add code to the json flow\"\"\"\n",
    "    langgraph_glossary_url = \"https://langchain-ai.github.io/langgraph/concepts/low_level/\"\n",
    "    json_code_ouptut = llm.invoke([SystemMessage(content=JSON_CODE_COMBINE_PROMPT.format(\n",
    "        code_snippet=state[\"python_code\"],\n",
    "        documents = fetch_documents(langgraph_glossary_url),\n",
    "        node_json = state[\"json_code\"]\n",
    "        ))])\n",
    "\n",
    "    formatted_json = llm.invoke([SystemMessage(content=json_formatter_doc)]+ [HumanMessage(content=json_code_ouptut.content)])\n",
    "    reactflowjson = dict_to_tree_positions(json.loads(formatted_json.content))\n",
    "    # Return the JSON code as the output\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Generated updated JSON code!\")],\n",
    "        \"json_code\": formatted_json.content,\n",
    "        \"reactflow_json\" : reactflowjson\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27ab49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import httpx\n",
    "\n",
    "def fetch_documents(url: str) -> str:\n",
    "    \"\"\"Fetch a document from a URL and return the markdownified text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The markdownified text of the document.\n",
    "    \"\"\"\n",
    "    httpx_client = httpx.Client(follow_redirects=True, timeout=10)\n",
    "\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "        img_tags = soup.find_all('img')\n",
    "        for img_tag in img_tags:\n",
    "            img_tag.decompose()\n",
    "\n",
    "        target_div = soup.find('div', class_= \"theme-doc-markdown markdown\") #langchain\n",
    "        \n",
    "        if not target_div:\n",
    "            target_div = soup.find('article') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            target_div = soup.find('html') #langraph\n",
    "\n",
    "        if not target_div:\n",
    "            return html2text.html2text(str(soup))\n",
    "        \n",
    "        return html2text.html2text(str(target_div))\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_15480\\1586735054.py:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  dict_tool_link = json.load( open( \"D:\\AgentAgent\\AgentAgent\\experiments\\\\tool_creation\\\\tools_link_json.json\") )\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_15480\\1586735054.py:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  dict_tool_doc = json.load( open( \"D:\\AgentAgent\\AgentAgent\\experiments\\\\tool_creation\\\\tools_doc_json.json\") )\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dict_tool_link = json.load( open( \"D:\\AgentAgent\\AgentAgent\\experiments\\\\tool_creation\\\\tools_link_json.json\") )\n",
    "dict_tool_doc = json.load( open( \"D:\\AgentAgent\\AgentAgent\\experiments\\\\tool_creation\\\\tools_doc_json.json\") )\n",
    "def lowercase_keys(input_dict):\n",
    "    \"\"\"\n",
    "    Returns a new dictionary with all keys converted to lowercase.\n",
    "    \"\"\"\n",
    "    return {k.lower(): v for k, v in input_dict.items()}\n",
    "\n",
    "dict_tool_link = lowercase_keys(dict_tool_link)\n",
    "dict_tool_doc = lowercase_keys(dict_tool_doc)\n",
    "\n",
    "Initial_prompt = \"\"\"You are an expert python developer. You will be given a description of a python function. \n",
    "\n",
    "You job is to estimate and extract the following information:\n",
    "\n",
    "- What exactly does this python do. What is the detailed objective of the function. Please write 1-5 lines\n",
    "- Suggest or extract the name of the the function\n",
    "- What would be the inputs/arguements required into this function to make it work. Please all mentioned the type of each input\n",
    "- WHat would be output produced by this input. Please mention the output type \n",
    "\n",
    "Here is the description of the function you need to create:\n",
    "<description>\n",
    "{desc}\n",
    "</description>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class FunctionInstructions(BaseModel):\n",
    "    \"\"\"Instructions for defining a python function\"\"\"\n",
    "    objective: str = Field(description= \"what does this pythion function do\")\n",
    "    name: str = Field(description=\"name of the python function\")\n",
    "    input : List[str] = Field(description= \"what would be the input arguements to this function along with the types\")\n",
    "    output: List[str] = Field(description=\"what would be the output/return attributes for the function along with the types\")\n",
    "    name_toolkit: str = Field(description=\"what would be the toolkit/ code SDK that will be used\")\n",
    "    code: str = Field(description=\"the final python code\")\n",
    "# Annotated[str, operator.add]\n",
    "\n",
    "class CodebuilderState(BaseModel):\n",
    "    \"\"\"Instructions for defining a python function\"\"\"\n",
    "    code: str = Field(description= \"tailored code for the python function\")\n",
    "\n",
    "\n",
    "def functional_analysis_node(state: FunctionInstructions):\n",
    "  print(\"functional_analysis_node\")\n",
    "  llm_with_structured_output = llm.with_structured_output(FunctionInstructions)\n",
    "  functionalReport: FunctionInstructions = llm_with_structured_output.invoke(\n",
    "      [SystemMessage(content=Initial_prompt.format(desc = state.objective))])\n",
    "  return {  \"messages\": [AIMessage(content=\"Generated JSON code!\")],\n",
    "           \"objective\": functionalReport.objective,\n",
    "           \"name\": functionalReport.name,\n",
    "           \"input\": functionalReport.input,\n",
    "           \"output\": functionalReport.output}\n",
    "\n",
    "write_code_prompt = \"\"\"\n",
    "You are a skilled code generation assistant. Your task is to create executable code using the following information:\n",
    "- SDK Documentation: The provided documentation outlines the functionalities and usage details of the SDK. Use this as the reference for constructing your code.\n",
    "- Objective: A clear description of what the code is intended to achieve.\n",
    "- Input: The expected input for the code (e.g., variables, parameters, data types).\n",
    "- Output: The desired result or outcome of the code (e.g., format, type, or structure).\n",
    "- SDK Name: The name of the SDK that must be used in the code.\n",
    "\n",
    "Your goal is to generate executable code that:\n",
    "- Adheres to the requirements outlined above.\n",
    "- Follows standard coding practices and is optimized for readability and efficiency.\n",
    "- Utilizes the specified SDK appropriately based on the documentation provided.\n",
    "- Only return a self contained function\n",
    "- Your output should only contain a code block containing the required function and nothing else. Please do no include any explainantions\n",
    "- Write your code in python\n",
    "- Please also provide which API keys will be required and define the API keys as part of the function\n",
    "- Please also write the doc string for the python function\n",
    "- Ensure that the function you produce is decorated with @tool. That means its defination should be preceeded by '@tool' in the line above\n",
    "\n",
    "Here are some details about the python function you will be creating:\n",
    "<objective>\n",
    "{objective}\n",
    "</objective>\n",
    "\n",
    "<input schema>\n",
    "{inputs}\n",
    "</input schema>\n",
    "\n",
    "<output schema>\n",
    "{output}\n",
    "</output schema>\n",
    "\n",
    "<name of function>\n",
    "{name}\n",
    "</name of function>\n",
    "\n",
    "Documentation for SDK that might be helpful:\n",
    "<documentation>\n",
    "{docs}\n",
    "</documentation>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Best_sdk_prompt = \"\"\"\n",
    "You are a highly specialized language model designed to assist in selecting the most suitable SDK for a given use case. You are provided with the following:\n",
    "- A dictionary containing pairs of SDK names and their respective descriptions.\n",
    "- Requirements for a piece of code, including the objective, input, and output.\n",
    "\n",
    "Your task is to:\n",
    "- Identify the SDK from the provided dictionary whose description best matches the given use case described in the code requirements.\n",
    "- Also give preferences to SDKs that are generally more well known or are used more frequently in the industry (Use google tools for anything search related)\n",
    "- Return only the name of the matching SDK without any additional text or formatting.\n",
    "- Please ensure that the string you return is a valid key of the dictionary you get as input. PLEASE VERIFY THAT THE STRING YOU RETURN EXISTS AS A KEY IN THE INPUT DICTIONARY\n",
    "\n",
    "Input Example:\n",
    "Dictionary:\n",
    "{{\n",
    "\"SDK_A\": \"[SDK_CC_ABC]Provides tools for web scraping and data extraction.\",\n",
    "\"SDK_B\": \"Enables natural language processing for unstructured text.\",\n",
    "\"SDK_C\": \"Facilitates the integration of payment gateways in applications.\"\n",
    "}}\n",
    "Code Requirements:\n",
    "Objective: Extract data from multiple web pages.\n",
    "Input: URLs of the web pages.\n",
    "Output: Structured data in JSON format.\n",
    "\n",
    "Expected Output:\n",
    "SDK_A\n",
    "\n",
    "\n",
    "Input :\n",
    "<dictionary>\n",
    "{dictionary}\n",
    "</dictionary>\n",
    "\n",
    "<objective>\n",
    "{objective}\n",
    "</objective>\n",
    "\n",
    "<input schema>\n",
    "{inputs}\n",
    "</input schema>\n",
    "\n",
    "<output schema>\n",
    "{output}\n",
    "</output schema>\n",
    "\n",
    "<name of function>\n",
    "{name}\n",
    "</name of function>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sdk_production_node(state: FunctionInstructions):\n",
    "    objective_agent: str = state.objective\n",
    "    name: str = state.name\n",
    "    input_args : List[str] = state.input\n",
    "    output_args: List[str] = state.output\n",
    "    response = llm.invoke([SystemMessage(content=Best_sdk_prompt.format(\n",
    "          objective=objective_agent,\n",
    "          inputs=input_args,\n",
    "          output=output_args,\n",
    "          name=name,\n",
    "          dictionary = dict_tool_doc\n",
    "    ))])\n",
    "    code_snips = response\n",
    "    return {\n",
    "            \"name_toolkit\": response.content.lower()}\n",
    "\n",
    "def code_production_node(state: FunctionInstructions):\n",
    "    objective_agent: str = state.objective\n",
    "    name: str = state.name\n",
    "    input_args : List[str] = state.input\n",
    "    output_args: List[str] = state.output\n",
    "    toolkit: str = state.name_toolkit\n",
    "    docs = fetch_documents(dict_tool_link[toolkit])\n",
    "    response = llm.invoke([SystemMessage(content=write_code_prompt.format(\n",
    "          objective=objective_agent,\n",
    "          inputs=input_args,\n",
    "          output=output_args,\n",
    "          name=name,\n",
    "          docs = docs,\n",
    "    ))])\n",
    "    code_snips = response\n",
    "    return {\n",
    "            \"code\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a6ea643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "workflow = StateGraph(FunctionInstructions)\n",
    "workflow.add_node(\"func_analysis\", functional_analysis_node)\n",
    "workflow.add_node(\"sdk_write\", sdk_production_node)\n",
    "workflow.add_node(\"code_write\", code_production_node)\n",
    "checkpointer = InMemorySaver()\n",
    "workflow.add_edge(\"code_write\", END)\n",
    "workflow.add_edge(\"sdk_write\",\"code_write\")\n",
    "workflow.add_edge(\"func_analysis\",\"sdk_write\")\n",
    "workflow.add_edge(START, \"func_analysis\")\n",
    "tool_infograph = workflow.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c66a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class toolcollector(MessagesState):\n",
    "    total_code: List[str]\n",
    "    compiled_code: str\n",
    "test_message = \"\"\"\n",
    "def get_weather(location: str):\n",
    "    \\\"\\\"\\\"Call to get the current weather.\\\"\\\"\\\"\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    else:\n",
    "        return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_coolest_cities():\n",
    "    \\\"\\\"\\\"Get a list of coolest cities\\\"\\\"\\\"\n",
    "    return \"nyc, sf\"\n",
    "\n",
    "tools = [get_weather, get_coolest_cities]\n",
    "\n",
    "# Bind the model(llm) with tools\n",
    "model_with_tools = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\", temperature=0\n",
    ").bind_tools(tools)\n",
    "\n",
    "# Generate a tool node.\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# conditional edge\n",
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\"\"\"\n",
    "tool_desc_prompt = \"\"\"\n",
    "You are an AI assistant designed to analyze Python code. Your task is to identify all function definitions in the provided Python snippet that are decorated with @tool. You must return a dictionary where:\n",
    "- The keys are the names of the identified functions.\n",
    "- You only need to pick up a function if it is decorated with '@tool' or '@tool' just preceeds the function. Otherwise leave the function alone\n",
    "- The values are descriptions of what each function is supposed to do. If a function contains a docstring, extract it as the description. If a docstring is missing, infer the function's purpose from its structure and comments.\n",
    "Example Input:\n",
    "@tool\n",
    "def calculate_area(length, width):\n",
    "    \"Calculates the area of a rectangle.\"\n",
    "    return length * width\n",
    "\n",
    "@tool\n",
    "def greet(name):\n",
    "    return f\"Hello, {{name}}!\"\n",
    "\n",
    "\n",
    "Expected Output:\n",
    "{{\n",
    "    \"calculate_area\": \"Calculates the area of a rectangle.\",\n",
    "    \"greet\": \"Greets a user by name.\"\n",
    "}}\n",
    "\n",
    "\n",
    "Instructions:\n",
    "- Identify functions that have the @tool decorator.\n",
    "- Extract function names and descriptions (either from docstrings or inferred).\n",
    "- Return the output as a structured JSON.\n",
    "- Please only return a json object that can be converted into a json directly. DO NOT RETURN ANYTHING OTHER THAN A JSON\n",
    "\n",
    "Python code:\n",
    "<code>\n",
    "{code}\n",
    "</code>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tool_compile_prompt = \"\"\"\n",
    "You are python code writing expert. You are given 2 snippets of code, your job is to combine them. \n",
    "The first snippet of code contains a compilable code with some functions compilable but empty. \n",
    "The second snippet of code contains the defination of those functions. \n",
    "Please fo through the second snippet of code, match the function in the first snippet and replace the functional definition written in the first snippet with one found in second snippet\n",
    "\n",
    "Please only return compilable python code\n",
    "Here are the code snippets:\n",
    "<code_snippet1>\n",
    "{complete_code}\n",
    "</code_snippet1>\n",
    "<code_snippet2>\n",
    "{functions}\n",
    "</code_snippet2>\n",
    "\"\"\"\n",
    "\n",
    "import uuid\n",
    "\n",
    "def graph_map_step(state: toolcollector):\n",
    "    # Extract nodes and edges from json_objects\n",
    "    current_code = state['messages']\n",
    "    print(current_code)\n",
    "    response_1 = llm.invoke([SystemMessage(content=tool_desc_prompt.format(code = current_code))])\n",
    "    json_objects = json.loads(response_1.content)\n",
    "    print(json_objects)\n",
    "    uuid_str = uuid.uuid4()\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid_str)}}\n",
    "    send = []\n",
    "    for key in json_objects:\n",
    "        print(key + \" \" + json_objects[key])\n",
    "        for output in tool_infograph.stream({\"objective\":key + \" \" + json_objects[key], \"name\": key, \"input\":[], \"output\": [], \"name_toolkit\": \"\", \"code\":\"\"}, config, stream_mode=\"updates\"):\n",
    "            print(output)\n",
    "        send.append(tool_infograph.get_state(config).values[\"code\"])\n",
    "    return {\n",
    "        \"total_code\": send,\n",
    "        \"compiled_code\" : current_code\n",
    "    }\n",
    "\n",
    "def compile_code(state: toolcollector):\n",
    "    tool_code_list = state['total_code']\n",
    "    normal_code = state['messages']\n",
    "    full_tool_code = \" \".join(tool_code_list)\n",
    "    response = llm.invoke([SystemMessage(content=tool_compile_prompt.format(complete_code = normal_code, functions = full_tool_code))])\n",
    "    return {\n",
    "        \"messages\": response.content\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73490e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1 = StateGraph(toolcollector)\n",
    "# workflow1.add_node(\"tool_infograph\", tool_infograph)\n",
    "workflow1.add_node(\"graph_map_step\", graph_map_step)\n",
    "workflow1.add_node(\"compile_code\", compile_code)\n",
    "\n",
    "workflow1.add_edge(START, \"graph_map_step\")\n",
    "workflow1.add_edge(\"graph_map_step\",\"compile_code\")\n",
    "workflow1.add_edge(\"compile_code\", END)\n",
    "tool_compile = workflow1.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "429e9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentBuilderState)\n",
    "workflow.add_node(\"requirement_analysis\", requirement_analysis_node)\n",
    "workflow.add_node(\"evaluate_against_architecture\", evaluate_against_architecture)\n",
    "workflow.add_node(\"best_architecture\", best_architecture)\n",
    "workflow.add_node(\"agent_kernel_builder\", agent_kernel_builder)\n",
    "workflow.add_node(\"code_to_json\", code_to_json_node)\n",
    "workflow.add_node(\"json_update\", json_better_node)\n",
    "workflow.add_node(\"json_to_code\", compiler_graph)\n",
    "workflow.add_node(\"tool_compile\",tool_compile)\n",
    "# workflow.add_node(\"reflection\", final_agent)\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: AgentBuilderState):\n",
    "    \n",
    "   \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Requirements generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# workflow.add_edge(\"reflection\", END)\n",
    "workflow.add_edge(\"tool_compile\", END)\n",
    "workflow.add_edge(\"json_to_code\", \"tool_compile\")\n",
    "workflow.add_edge(\"json_update\", \"json_to_code\")\n",
    "workflow.add_edge(\"code_to_json\", \"json_update\")\n",
    "workflow.add_edge(\"agent_kernel_builder\", \"code_to_json\")\n",
    "workflow.add_edge(\"best_architecture\", \"agent_kernel_builder\")\n",
    "workflow.add_edge(\"evaluate_against_architecture\", \"best_architecture\")\n",
    "workflow.add_conditional_edges(\"add_tool_message\", architecture_evaluation_map_node,[\"evaluate_against_architecture\"])\n",
    "workflow.add_conditional_edges(\"requirement_analysis\", route_state, [\"add_tool_message\", \"requirement_analysis\", END])\n",
    "workflow.add_edge(START, \"requirement_analysis\")\n",
    "infograph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05a25a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (q/Q to quit): 1. Primary objective is handle customers, resolve their issues, fetch information for them and conflict to resolution 2. Use cases would be updating customer information, providing customers with the data they ask for, asking customers for their requirements and suggesting them products 3. example 1: input: what is the price of product x? output:  price of x is 300$ example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi Example 3: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accoutning along with, I would also suggest product z which helps with customer out reach and is generally used by customers opening new business and fits your use case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:57:02,392 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  AgentInstructions (call_wVryVUy3Sx7RlOI79Za5edSK)\n",
      " Call ID: call_wVryVUy3Sx7RlOI79Za5edSK\n",
      "  Args:\n",
      "    objective: Handle customers, resolve their issues, fetch information for them and conflict to resolution\n",
      "    usecases: ['Updating customer information', 'Providing customers with the data they ask for', 'Asking customers for their requirements', 'Suggesting products to customers']\n",
      "    examples: Example 1: input: what is the price of product x? output: price of x is 300$; Example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi; Example 3: input: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accounting along with, I would also suggest product z which helps with customer outreach and is generally used by customers opening new business and fits your use case.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Requirements generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:57:06,475 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration \"HTTP/1.1 301 Moved Permanently\"\n",
      "2025-05-15 21:57:06,482 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute \"HTTP/1.1 301 Moved Permanently\"\n",
      "2025-05-15 21:57:06,488 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor \"HTTP/1.1 301 Moved Permanently\"\n",
      "2025-05-15 21:57:06,490 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams \"HTTP/1.1 301 Moved Permanently\"\n",
      "2025-05-15 21:57:06,497 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/self-discover/self-discover \"HTTP/1.1 301 Moved Permanently\"\n",
      "2025-05-15 21:57:06,512 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:06,518 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:06,525 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:06,527 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:06,532 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/self-discover/self-discover/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:07,832 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:07,978 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:08,144 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:08,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:09,351 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams, arch_name: Hierarchical Agent Teams\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute, arch_name: Plan-and-Execute Agent Architecture\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor, arch_name: Multi-agent Supervisor Architecture\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/self-discover/self-discover, arch_name: Self-Discover Agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration, arch_name: Multi-Agent Network Architecture\n",
      "found the best architecture\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Best architecture selected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:57:15,555 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration \"HTTP/1.1 301 Moved Permanently\"\n",
      "2025-05-15 21:57:15,574 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:17,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generated agent kernel code!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:57:39,796 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/concepts/low_level/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:40,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generated JSON code!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:57:56,483 - INFO - HTTP Request: GET https://langchain-ai.github.io/langgraph/concepts/low_level/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:57:57,333 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:17,843 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generated updated JSON code!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:30,172 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identify_node': {'node_type': 'planner', 'messages': [HumanMessage(content='\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nMessagesState\\n</SchemaInfo>\\n<InputSchema>\\nMessagesState\\n</InputSchema>\\n<OutputSchema>\\nMessagesState\\n</OutputSchema>\\n<Description>\\nThis node handles customer inquiries and invokes the inquiry agent.\\n</Description>\\n<FunctionName>\\ninquiry_node\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef inquiry_node(state:MessagesState) -> MessagesState:\\n    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type MessagesState and the function is of type MessagesState\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n', additional_kwargs={}, response_metadata={}, id='97101974-d828-4733-bce9-1c12e7700192')], 'node_info': '\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nMessagesState\\n</SchemaInfo>\\n<InputSchema>\\nMessagesState\\n</InputSchema>\\n<OutputSchema>\\nMessagesState\\n</OutputSchema>\\n<Description>\\nThis node handles customer inquiries and invokes the inquiry agent.\\n</Description>\\n<FunctionName>\\ninquiry_node\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef inquiry_node(state:MessagesState) -> MessagesState:\\n    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type MessagesState and the function is of type MessagesState\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:30,500 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identify_node': {'node_type': 'planner', 'messages': [HumanMessage(content='\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nMessagesState\\n</SchemaInfo>\\n<InputSchema>\\nMessagesState\\n</InputSchema>\\n<OutputSchema>\\nMessagesState\\n</OutputSchema>\\n<Description>\\nThis node suggests products based on customer needs and invokes the suggestion agent.\\n</Description>\\n<FunctionName>\\nsuggestion_node\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef suggestion_node(state:MessagesState) -> MessagesState:\\n    \"\"\"This node suggests products based on customer needs and invokes the suggestion agent.\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type MessagesState and the function is of type MessagesState\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n', additional_kwargs={}, response_metadata={}, id='3de4c043-36e6-4762-9771-558dd828e7b4')], 'node_info': '\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nMessagesState\\n</SchemaInfo>\\n<InputSchema>\\nMessagesState\\n</InputSchema>\\n<OutputSchema>\\nMessagesState\\n</OutputSchema>\\n<Description>\\nThis node suggests products based on customer needs and invokes the suggestion agent.\\n</Description>\\n<FunctionName>\\nsuggestion_node\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef suggestion_node(state:MessagesState) -> MessagesState:\\n    \"\"\"This node suggests products based on customer needs and invokes the suggestion agent.\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type MessagesState and the function is of type MessagesState\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:33,020 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:33,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:34,112 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': ['Generate a prompt that extracts customer needs from the input MessagesState and requests product suggestions accordingly.', 'Use structured output functionality to ensure the output adheres to the MessagesState schema, updating the state with suggested products.', 'Return the updated MessagesState containing the product suggestions as the final output.']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:35,080 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:35,148 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': ['Generate a prompt that instructs the model to handle customer inquiries based on the input MessagesState and produce an updated MessagesState as output.', 'Use structured output functionality to enforce that the output adheres to the MessagesState schema, ensuring type safety and consistency.', 'Implement the function to extract the input MessagesState, apply the prompt with structured output to process the inquiry, and update the state with the resulting MessagesState.', 'Return the updated MessagesState as the final output of the function.']}}\n",
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': 'Generate a prompt that extracts customer needs from the input MessagesState and requests product suggestions accordingly.', 'messages': [AIMessage(content=\"Step 1 requires generating a prompt that extracts customer needs from the input MessagesState and requests product suggestions accordingly. The 'prompt_generation' worker is best suited to create this prompt based on the provided state and description.\", additional_kwargs={}, response_metadata={}, id='2f2ab659-ca0c-4f29-a598-ffb7e57e761f')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:36,266 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_generation': {'past_steps': [('Generate a prompt that extracts customer needs from the input MessagesState and requests product suggestions accordingly.', \"Given the input MessagesState containing customer needs, generate a prompt that instructs the suggestion agent to analyze these needs and suggest the most suitable products. The prompt should clearly ask the agent to consider the customer's preferences, requirements, and context as described in the messages, and then provide relevant product recommendations. The output should be formatted as an updated MessagesState including the original conversation plus the suggestion agent's product recommendations.\")], 'messages': [HumanMessage(content=\"Given the input MessagesState containing customer needs, generate a prompt that instructs the suggestion agent to analyze these needs and suggest the most suitable products. The prompt should clearly ask the agent to consider the customer's preferences, requirements, and context as described in the messages, and then provide relevant product recommendations. The output should be formatted as an updated MessagesState including the original conversation plus the suggestion agent's product recommendations.\", additional_kwargs={}, response_metadata={}, name='prompt_generator', id='d5dca310-08a0-469d-b2cc-1ba19cc3d607')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:36,808 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': 'Generate a prompt that instructs the model to handle customer inquiries based on the input MessagesState and produce an updated MessagesState as output.', 'messages': [AIMessage(content='Step 1 requires generating a prompt that instructs the model to handle customer inquiries based on the input MessagesState and produce an updated MessagesState as output. The prompt_generation worker specializes in creating such prompts, making it the appropriate choice to execute this step.', additional_kwargs={}, response_metadata={}, id='e8a247d9-2b18-4654-bc1c-9e12cf0617d7')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:37,706 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:38,646 - INFO - HTTP Request: POST https://kanis-m8htxgs7-eastus.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:40,405 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replan': {'plan': ['Use structured output functionality to ensure the output adheres to the MessagesState schema, updating the state with suggested products.', 'Return the updated MessagesState containing the product suggestions as the final output.']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:41,770 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai_node_gen_supervisor': {'next': 'structured_output_generation', 'task': 'Use structured output functionality to ensure the output adheres to the MessagesState schema, updating the state with suggested products.', 'messages': [AIMessage(content=\"The step requires using structured output functionality to ensure the output adheres to the MessagesState schema and updates the state with suggested products. The 'structured_output_generation' worker specializes in generating outputs that conform to specified schemas, making it the appropriate choice to execute this step.\", additional_kwargs={}, response_metadata={}, id='2f34451d-33ff-4ef4-a4c3-47948382795b')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:43,609 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_generation': {'past_steps': [('Generate a prompt that instructs the model to handle customer inquiries based on the input MessagesState and produce an updated MessagesState as output.', \"You are an inquiry agent designed to handle customer inquiries. You receive an input state of type MessagesState containing the current conversation messages. Your task is to analyze the incoming customer inquiry from the MessagesState, generate an appropriate and helpful response, and update the MessagesState with this response. Ensure the response is clear, polite, and addresses the customer's question or concern effectively. Return the updated MessagesState reflecting the new message from the inquiry agent.\")], 'messages': [HumanMessage(content=\"You are an inquiry agent designed to handle customer inquiries. You receive an input state of type MessagesState containing the current conversation messages. Your task is to analyze the incoming customer inquiry from the MessagesState, generate an appropriate and helpful response, and update the MessagesState with this response. Ensure the response is clear, polite, and addresses the customer's question or concern effectively. Return the updated MessagesState reflecting the new message from the inquiry agent.\", additional_kwargs={}, response_metadata={}, name='prompt_generator', id='96baaa50-3f51-4fa0-98b4-c34d81f15e56')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:44,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'structured_output_generation': {'past_steps': [('Use structured output functionality to ensure the output adheres to the MessagesState schema, updating the state with suggested products.', 'There is no need for structured output functionality here because the input and output are both of type MessagesState, which is already a structured format. The function simply updates the MessagesState with product suggestions, and no additional structured output enforcement is required.')], 'messages': [HumanMessage(content='There is no need for structured output functionality here because the input and output are both of type MessagesState, which is already a structured format. The function simply updates the MessagesState with product suggestions, and no additional structured output enforcement is required.', additional_kwargs={}, response_metadata={}, name='struct_output_generator', id='87a3891c-130a-43b0-b3fc-13ba55a98764')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:47,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:58:47,426 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replan': {'plan': ['Use structured output functionality to enforce that the output adheres to the MessagesState schema, ensuring type safety and consistency.', 'Implement the function to extract the input MessagesState, apply the prompt with structured output to process the inquiry, and update the state with the resulting MessagesState.', 'Return the updated MessagesState as the final output of the function.']}}\n",
      "{'replan': {'plan': ['Return the updated MessagesState containing the product suggestions as the final output.']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:48,793 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai_node_gen_supervisor': {'next': 'structured_output_generation', 'task': 'Use structured output functionality to enforce that the output adheres to the MessagesState schema, ensuring type safety and consistency.', 'messages': [AIMessage(content=\"Step 1 requires enforcing that the output adheres to the MessagesState schema using structured output functionality to ensure type safety and consistency. The 'structured_output_generation' worker specializes in generating outputs that conform to specified schemas, making it the appropriate choice to execute this step.\", additional_kwargs={}, response_metadata={}, id='3e4c6634-b768-4c4b-9e32-d6da3b947286')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:50,208 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai_node_gen_supervisor': {'next': 'structured_output_generation', 'task': 'Return the updated MessagesState containing the product suggestions as the final output.', 'messages': [AIMessage(content=\"The step requires returning the updated MessagesState containing product suggestions as the final output. The 'structured_output_generation' worker is best suited to generate and return the updated structured output based on the input state and the description provided.\", additional_kwargs={}, response_metadata={}, id='3a40351d-8e24-4aee-b3b1-719df8aff71d')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:51,694 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'structured_output_generation': {'past_steps': [('Return the updated MessagesState containing the product suggestions as the final output.', \"There is no need for structured output functionality. Since both input and output are of type MessagesState and the function simply updates the state with product suggestions, the existing structured format is sufficient without requiring the LLM's with_structured_output() method.\")], 'messages': [HumanMessage(content=\"There is no need for structured output functionality. Since both input and output are of type MessagesState and the function simply updates the state with product suggestions, the existing structured format is sufficient without requiring the LLM's with_structured_output() method.\", additional_kwargs={}, response_metadata={}, name='struct_output_generator', id='07868ef0-62c8-48c3-9499-a051d391cbc6')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:53,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replan': {'response': 'The plan to return the updated MessagesState containing the product suggestions as the final output has been fully executed. No further steps are needed.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:54,573 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'structured_output_generation': {'past_steps': [('Use structured output functionality to enforce that the output adheres to the MessagesState schema, ensuring type safety and consistency.', 'This node processes customer inquiries by taking a MessagesState as input and returning an updated MessagesState as output. Since both input and output are of the same type MessagesState, and the output is expected to be a consistent, verifiable data format (updated conversation messages), using structured output is beneficial here.\\n\\nReasons to use structured output in this node:\\n- Ensures the model\\'s output strictly conforms to the MessagesState schema, reducing hallucinations or format errors.\\n- Simplifies prompting since the schema enforces the output format.\\n- Provides reliable type-safety, so the updated MessagesState can be used directly in downstream workflows.\\n- Facilitates integration with other components expecting MessagesState objects.\\n- Makes the output predictable and easier to test or debug.\\n\\nTherefore, this node requires the LLM\\'s with_structured_output() function with MessagesState as the structured output class.\\n\\nBelow is the code snippet demonstrating how to use structured output for this node:\\n\\n```python\\nfrom some_module import MessagesState  # Assuming MessagesState is imported from the relevant module\\n\\ndef inquiry_node(state: MessagesState) -> MessagesState:\\n    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\\n    structured_llm = llm.with_structured_output(MessagesState)\\n    updated_state: MessagesState = structured_llm.invoke(state)\\n    return updated_state\\n```\\n\\nThis ensures the LLM output is always a valid MessagesState instance, updated with the inquiry agent\\'s response.')], 'messages': [HumanMessage(content='This node processes customer inquiries by taking a MessagesState as input and returning an updated MessagesState as output. Since both input and output are of the same type MessagesState, and the output is expected to be a consistent, verifiable data format (updated conversation messages), using structured output is beneficial here.\\n\\nReasons to use structured output in this node:\\n- Ensures the model\\'s output strictly conforms to the MessagesState schema, reducing hallucinations or format errors.\\n- Simplifies prompting since the schema enforces the output format.\\n- Provides reliable type-safety, so the updated MessagesState can be used directly in downstream workflows.\\n- Facilitates integration with other components expecting MessagesState objects.\\n- Makes the output predictable and easier to test or debug.\\n\\nTherefore, this node requires the LLM\\'s with_structured_output() function with MessagesState as the structured output class.\\n\\nBelow is the code snippet demonstrating how to use structured output for this node:\\n\\n```python\\nfrom some_module import MessagesState  # Assuming MessagesState is imported from the relevant module\\n\\ndef inquiry_node(state: MessagesState) -> MessagesState:\\n    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\\n    structured_llm = llm.with_structured_output(MessagesState)\\n    updated_state: MessagesState = structured_llm.invoke(state)\\n    return updated_state\\n```\\n\\nThis ensures the LLM output is always a valid MessagesState instance, updated with the inquiry agent\\'s response.', additional_kwargs={}, response_metadata={}, name='struct_output_generator', id='d8c6f696-ab49-4096-99a3-98b6fe337f48')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:57,465 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replan': {'response': 'The plan has been fully executed as per the OriginalPlan. The prompt generation, use of structured output to enforce the MessagesState schema, implementation of the function to process the inquiry and update the state, and returning the updated MessagesState have all been completed successfully.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:58:59,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_compiler': {'final_code': '```python\\nfrom some_module import MessagesState  # Assuming MessagesState is imported from the relevant module\\n\\ndef inquiry_node(state: MessagesState) -> MessagesState:\\n    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\\n    # Use the LLM with structured output to ensure the output conforms to MessagesState schema\\n    structured_llm = llm.with_structured_output(MessagesState)\\n    updated_state: MessagesState = structured_llm.invoke(state)\\n    return updated_state\\n```'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:00,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:01,449 - INFO - HTTP Request: POST https://kanis-m8htxgs7-eastus.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:04,422 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_compiler': {'final_code': '```python\\nfrom typing import Any\\n\\n# Assuming MessagesState is a class or type representing the conversation state,\\n# which contains a list of messages, each message being a dict with keys like \\'role\\' and \\'content\\'.\\n# Since the exact implementation of MessagesState is not provided, we will treat it as a dict-like object\\n# with a \\'messages\\' key containing a list of messages.\\n\\ndef suggestion_node(state: Any) -> Any:\\n    \"\"\"This node suggests products based on customer needs and invokes the suggestion agent.\"\"\"\\n    # Extract the conversation messages from the state\\n    messages = state.get(\"messages\", [])\\n\\n    # Extract customer needs from the conversation messages\\n    # For simplicity, we assume customer needs are described in user messages\\n    customer_needs = []\\n    for msg in messages:\\n        if msg.get(\"role\") == \"user\":\\n            customer_needs.append(msg.get(\"content\", \"\"))\\n\\n    # Construct a prompt for the suggestion agent to analyze customer needs and suggest products\\n    prompt = (\\n        \"You are a product suggestion agent. Based on the following customer needs, \"\\n        \"analyze their preferences, requirements, and context, then suggest the most suitable products.\\\\n\\\\n\"\\n        \"Customer needs:\\\\n\"\\n        + \"\\\\n\".join(f\"- {need}\" for need in customer_needs)\\n        + \"\\\\n\\\\nPlease provide relevant product recommendations.\"\\n    )\\n\\n    # Append the prompt as a system message to the conversation to invoke the suggestion agent\\n    messages.append({\"role\": \"system\", \"content\": prompt})\\n\\n    # Here, in a real system, the suggestion agent would process the prompt and generate product suggestions.\\n    # Since this is a blackbox, we simulate the suggestion agent\\'s response by appending a placeholder message.\\n    # In practice, this would be replaced by the actual agent\\'s output.\\n\\n    # Placeholder for product suggestions (to be replaced by actual agent output)\\n    product_suggestions = (\\n        \"Based on your needs, we suggest the following products:\\\\n\"\\n        \"1. Product A - Description and benefits.\\\\n\"\\n        \"2. Product B - Description and benefits.\\\\n\"\\n        \"3. Product C - Description and benefits.\"\\n    )\\n\\n    # Append the suggestion agent\\'s response as an assistant message\\n    messages.append({\"role\": \"assistant\", \"content\": product_suggestions})\\n\\n    # Update the state with the new messages list\\n    updated_state = dict(state)\\n    updated_state[\"messages\"] = messages\\n\\n    return updated_state\\n```'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:05,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:05,305 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:05,545 - INFO - HTTP Request: POST https://kanis-m8htxgs7-eastus.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:08,777 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:23,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```python\n",
      "from langgraph import Graph, InMemoryCheckpointer\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
      "from langchain.output_parsers import StructuredOutputParser\n",
      "from pydantic import BaseModel\n",
      "from typing import List, Dict, Any\n",
      "\n",
      "# Define MessagesState as a Pydantic model for structured output\n",
      "class Message(BaseModel):\n",
      "    role: str\n",
      "    content: str\n",
      "\n",
      "class MessagesState(BaseModel):\n",
      "    messages: List[Message]\n",
      "\n",
      "# Initialize the LLM\n",
      "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
      "\n",
      "# Inquiry node implementation using structured output with langchain\n",
      "def inquiry_node(state: MessagesState) -> MessagesState:\n",
      "    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\n",
      "    # Use the LLM with structured output to ensure the output conforms to MessagesState schema\n",
      "    parser = StructuredOutputParser(pydantic_object=MessagesState)\n",
      "    prompt_messages = [HumanMessage(content=state.json())]\n",
      "    response = llm.generate([prompt_messages])\n",
      "    # Parse the LLM output to MessagesState\n",
      "    parsed = parser.parse(response.generations[0][0].text)\n",
      "    return parsed\n",
      "\n",
      "# Suggestion node implementation using langchain LLM invocation\n",
      "def suggestion_node(state: MessagesState) -> MessagesState:\n",
      "    \"\"\"This node suggests products based on customer needs and invokes the suggestion agent.\"\"\"\n",
      "    messages = [msg.dict() for msg in state.messages]\n",
      "\n",
      "    # Extract customer needs from user messages\n",
      "    customer_needs = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\n",
      "\n",
      "    # Construct prompt for suggestion agent\n",
      "    prompt = (\n",
      "        \"You are a product suggestion agent. Based on the following customer needs, \"\n",
      "        \"analyze their preferences, requirements, and context, then suggest the most suitable products.\\n\\n\"\n",
      "        \"Customer needs:\\n\"\n",
      "        + \"\\n\".join(f\"- {need}\" for need in customer_needs)\n",
      "        + \"\\n\\nPlease provide relevant product recommendations.\"\n",
      "    )\n",
      "\n",
      "    # Append system message with prompt\n",
      "    messages.append({\"role\": \"system\", \"content\": prompt})\n",
      "\n",
      "    # Convert messages to langchain BaseMessage list\n",
      "    lc_messages: List[BaseMessage] = []\n",
      "    for m in messages:\n",
      "        if m[\"role\"] == \"system\":\n",
      "            lc_messages.append(SystemMessage(content=m[\"content\"]))\n",
      "        elif m[\"role\"] == \"user\":\n",
      "            lc_messages.append(HumanMessage(content=m[\"content\"]))\n",
      "        elif m[\"role\"] == \"assistant\":\n",
      "            lc_messages.append(AIMessage(content=m[\"content\"]))\n",
      "        else:\n",
      "            # fallback to HumanMessage for unknown roles\n",
      "            lc_messages.append(HumanMessage(content=m[\"content\"]))\n",
      "\n",
      "    # Invoke LLM to get product suggestions\n",
      "    response = llm(lc_messages)\n",
      "\n",
      "    # Append assistant message with suggestions\n",
      "    messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
      "\n",
      "    # Return updated state\n",
      "    updated_state = MessagesState(messages=[Message(**msg) for msg in messages])\n",
      "    return updated_state\n",
      "\n",
      "# Create the graph and add nodes\n",
      "graph = Graph()\n",
      "\n",
      "graph.add_node(\"inquiry\", inquiry_node)\n",
      "graph.add_node(\"suggestion\", suggestion_node)\n",
      "\n",
      "# Add edges as per the workflow (all non-conditional)\n",
      "graph.add_edge(\"__START__\", \"inquiry\")\n",
      "graph.add_edge(\"inquiry\", \"suggestion\")\n",
      "graph.add_edge(\"inquiry\", \"__END__\")\n",
      "graph.add_edge(\"suggestion\", \"inquiry\")\n",
      "graph.add_edge(\"suggestion\", \"__END__\")\n",
      "\n",
      "# Compile the graph with InMemoryCheckpointer\n",
      "final_app = graph.compile(checkpointer=InMemoryCheckpointer())\n",
      "```\n",
      "[HumanMessage(content='1. Primary objective is handle customers, resolve their issues, fetch information for them and conflict to resolution 2. Use cases would be updating customer information, providing customers with the data they ask for, asking customers for their requirements and suggesting them products 3. example 1: input: what is the price of product x? output:  price of x is 300$ example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi Example 3: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accoutning along with, I would also suggest product z which helps with customer out reach and is generally used by customers opening new business and fits your use case', additional_kwargs={}, response_metadata={}, id='b10d7c7a-687e-4996-a00a-8219cd258f09'), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_wVryVUy3Sx7RlOI79Za5edSK', 'function': {'arguments': '{\"objective\":\"Handle customers, resolve their issues, fetch information for them and conflict to resolution\",\"usecases\":[\"Updating customer information\",\"Providing customers with the data they ask for\",\"Asking customers for their requirements\",\"Suggesting products to customers\"],\"examples\":\"Example 1: input: what is the price of product x? output: price of x is 300$; Example 2: input: Please update my address to \\\\\"delhi\\\\\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi; Example 3: input: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accounting along with, I would also suggest product z which helps with customer outreach and is generally used by customers opening new business and fits your use case.\"}', 'name': 'AgentInstructions'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090'}, id='run-21a1593a-af81-47aa-81dd-9229cc69fc6e-0', tool_calls=[{'name': 'AgentInstructions', 'args': {'objective': 'Handle customers, resolve their issues, fetch information for them and conflict to resolution', 'usecases': ['Updating customer information', 'Providing customers with the data they ask for', 'Asking customers for their requirements', 'Suggesting products to customers'], 'examples': 'Example 1: input: what is the price of product x? output: price of x is 300$; Example 2: input: Please update my address to \"delhi\" output: Address updated, here are your new user details-> Name: abc, age 24, Address: Delhi; Example 3: input: I am opening up a bakery and need to setup my supply chain and billing output: We have product x that will output your supply chain monitoring and product Y that would automate your billing and accounting along with, I would also suggest product z which helps with customer outreach and is generally used by customers opening new business and fits your use case.'}, 'id': 'call_wVryVUy3Sx7RlOI79Za5edSK', 'type': 'tool_call'}]), ToolMessage(content='Requirements generated!', id='e67d7944-55ba-41ed-bcae-39603208d6b8', tool_call_id='call_wVryVUy3Sx7RlOI79Za5edSK'), AIMessage(content='Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration, arch_name: Multi-Agent Network Architecture', additional_kwargs={}, response_metadata={}, id='41b1b5b9-3bc7-41d5-93d4-fb53d8e9e02f'), AIMessage(content='Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor, arch_name: Multi-agent Supervisor Architecture', additional_kwargs={}, response_metadata={}, id='eb16b806-a7e9-4739-bdb3-1d3d63799b21'), AIMessage(content='Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams, arch_name: Hierarchical Agent Teams', additional_kwargs={}, response_metadata={}, id='2950e63c-07bd-4b02-80cc-a51cb96f6bb6'), AIMessage(content='Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute, arch_name: Plan-and-Execute Agent Architecture', additional_kwargs={}, response_metadata={}, id='30f6c8c4-2124-4bce-8f5f-75c3401c68d7'), AIMessage(content='Evaluated architecture https://langchain-ai.github.io/langgraph/tutorials/self-discover/self-discover, arch_name: Self-Discover Agent', additional_kwargs={}, response_metadata={}, id='ff6eecb0-99d9-4910-a83b-16755ec67bc2'), AIMessage(content='Best architecture selected!', additional_kwargs={}, response_metadata={}, id='886394ed-1f5b-4eb0-8186-e760a5baa278'), AIMessage(content='Generated agent kernel code!', additional_kwargs={}, response_metadata={}, id='9af8a881-5ded-40e3-9cb4-37412d786ac8'), AIMessage(content='Generated JSON code!', additional_kwargs={}, response_metadata={}, id='dbfb170c-0dea-4eff-82b4-329b1184242c'), AIMessage(content='Generated updated JSON code!', additional_kwargs={}, response_metadata={}, id='9606834a-58d6-4e81-8d03-d8c2b125dce1'), AIMessage(content='```python\\nfrom langgraph import Graph, InMemoryCheckpointer\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage\\nfrom langchain.output_parsers import StructuredOutputParser\\nfrom pydantic import BaseModel\\nfrom typing import List, Dict, Any\\n\\n# Define MessagesState as a Pydantic model for structured output\\nclass Message(BaseModel):\\n    role: str\\n    content: str\\n\\nclass MessagesState(BaseModel):\\n    messages: List[Message]\\n\\n# Initialize the LLM\\nllm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\\n\\n# Inquiry node implementation using structured output with langchain\\ndef inquiry_node(state: MessagesState) -> MessagesState:\\n    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\\n    # Use the LLM with structured output to ensure the output conforms to MessagesState schema\\n    parser = StructuredOutputParser(pydantic_object=MessagesState)\\n    prompt_messages = [HumanMessage(content=state.json())]\\n    response = llm.generate([prompt_messages])\\n    # Parse the LLM output to MessagesState\\n    parsed = parser.parse(response.generations[0][0].text)\\n    return parsed\\n\\n# Suggestion node implementation using langchain LLM invocation\\ndef suggestion_node(state: MessagesState) -> MessagesState:\\n    \"\"\"This node suggests products based on customer needs and invokes the suggestion agent.\"\"\"\\n    messages = [msg.dict() for msg in state.messages]\\n\\n    # Extract customer needs from user messages\\n    customer_needs = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\\n\\n    # Construct prompt for suggestion agent\\n    prompt = (\\n        \"You are a product suggestion agent. Based on the following customer needs, \"\\n        \"analyze their preferences, requirements, and context, then suggest the most suitable products.\\\\n\\\\n\"\\n        \"Customer needs:\\\\n\"\\n        + \"\\\\n\".join(f\"- {need}\" for need in customer_needs)\\n        + \"\\\\n\\\\nPlease provide relevant product recommendations.\"\\n    )\\n\\n    # Append system message with prompt\\n    messages.append({\"role\": \"system\", \"content\": prompt})\\n\\n    # Convert messages to langchain BaseMessage list\\n    lc_messages: List[BaseMessage] = []\\n    for m in messages:\\n        if m[\"role\"] == \"system\":\\n            lc_messages.append(SystemMessage(content=m[\"content\"]))\\n        elif m[\"role\"] == \"user\":\\n            lc_messages.append(HumanMessage(content=m[\"content\"]))\\n        elif m[\"role\"] == \"assistant\":\\n            lc_messages.append(AIMessage(content=m[\"content\"]))\\n        else:\\n            # fallback to HumanMessage for unknown roles\\n            lc_messages.append(HumanMessage(content=m[\"content\"]))\\n\\n    # Invoke LLM to get product suggestions\\n    response = llm(lc_messages)\\n\\n    # Append assistant message with suggestions\\n    messages.append({\"role\": \"assistant\", \"content\": response.content})\\n\\n    # Return updated state\\n    updated_state = MessagesState(messages=[Message(**msg) for msg in messages])\\n    return updated_state\\n\\n# Create the graph and add nodes\\ngraph = Graph()\\n\\ngraph.add_node(\"inquiry\", inquiry_node)\\ngraph.add_node(\"suggestion\", suggestion_node)\\n\\n# Add edges as per the workflow (all non-conditional)\\ngraph.add_edge(\"__START__\", \"inquiry\")\\ngraph.add_edge(\"inquiry\", \"suggestion\")\\ngraph.add_edge(\"inquiry\", \"__END__\")\\ngraph.add_edge(\"suggestion\", \"inquiry\")\\ngraph.add_edge(\"suggestion\", \"__END__\")\\n\\n# Compile the graph with InMemoryCheckpointer\\nfinal_app = graph.compile(checkpointer=InMemoryCheckpointer())\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 766, 'prompt_tokens': 1241, 'total_tokens': 2007, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_38647f5e19', 'id': 'chatcmpl-BXVkDSQSNwfUskB61prNrlbYCq1iZ', 'finish_reason': 'stop', 'logprobs': None}, id='run-95d5dd12-4449-453b-81ad-6fe13596691e-0', usage_metadata={'input_tokens': 1241, 'output_tokens': 766, 'total_tokens': 2007, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:24,425 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inquiry_node': 'This node handles customer inquiries and invokes the inquiry agent.', 'suggestion_node': 'This node suggests products based on customer needs and invokes the suggestion agent.'}\n",
      "inquiry_node This node handles customer inquiries and invokes the inquiry agent.\n",
      "functional_analysis_node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:25,694 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'func_analysis': {'objective': 'The function handles customer inquiries by processing the input inquiry data and invoking an inquiry agent to provide a response or resolution to the customer.', 'name': 'handle_customer_inquiry', 'input': ['inquiry_data: str', 'customer_id: int'], 'output': ['response: str', 'status: bool']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:29,254 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sdk_write': {'name_toolkit': 'agentql'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:30,084 - INFO - HTTP Request: GET https://python.langchain.com/docs/integrations/tools/agentql \"HTTP/1.1 308 Permanent Redirect\"\n",
      "2025-05-15 21:59:30,125 - INFO - HTTP Request: GET https://python.langchain.com/docs/integrations/tools/agentql/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:31,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_write': {'code': '```python\\nimport os\\nfrom langchain_agentql.tools import ExtractWebDataTool\\n\\ndef handle_customer_inquiry(inquiry_data: str, customer_id: int) -> dict:\\n    \"\"\"\\n    Handles customer inquiries by processing the input inquiry data and invoking an inquiry agent \\n    to provide a response or resolution to the customer.\\n\\n    Parameters:\\n    inquiry_data (str): The inquiry data provided by the customer.\\n    customer_id (int): The unique identifier for the customer.\\n\\n    Returns:\\n    dict: A dictionary containing the response and status of the inquiry handling.\\n    \"\"\"\\n    # Define API key\\n    os.environ[\"AGENTQL_API_KEY\"] = \"YOUR_AGENTQL_API_KEY\"\\n    \\n    # Instantiate the ExtractWebDataTool\\n    extract_web_data_tool = ExtractWebDataTool()\\n    \\n    # Process the inquiry using the tool\\n    response_data = extract_web_data_tool.invoke({\\n        \"url\": \"https://example.com/inquiry\",  # Replace with actual URL if needed\\n        \"prompt\": inquiry_data\\n    })\\n    \\n    # Extract response and status\\n    response = response_data.get(\\'data\\', {}).get(\\'response\\', \\'No response found\\')\\n    status = True if response else False\\n    \\n    return {\\n        \"response\": response,\\n        \"status\": status\\n    }\\n```'}}\n",
      "suggestion_node This node suggests products based on customer needs and invokes the suggestion agent.\n",
      "functional_analysis_node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:35,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'func_analysis': {'objective': 'The function suggests products to customers based on their needs and interacts with a suggestion agent to provide tailored recommendations.', 'name': 'suggestion_node', 'input': ['customer_needs: str', 'suggestion_agent: object'], 'output': ['suggested_products: list']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:39,432 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sdk_write': {'name_toolkit': 'lemonai'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:40,135 - INFO - HTTP Request: GET https://python.langchain.com/docs/integrations/tools/lemonai \"HTTP/1.1 308 Permanent Redirect\"\n",
      "2025-05-15 21:59:40,433 - INFO - HTTP Request: GET https://python.langchain.com/docs/integrations/tools/lemonai/ \"HTTP/1.1 200 OK\"\n",
      "2025-05-15 21:59:41,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_write': {'code': '```python\\nimport os\\nfrom lemonai import execute_workflow\\nfrom langchain_openai import OpenAI\\n\\ndef suggestion_node(customer_needs: str, suggestion_agent: object) -> list:\\n    \"\"\"\\n    Suggests products to customers based on their needs and interacts with a suggestion agent to provide tailored recommendations.\\n\\n    Parameters:\\n    customer_needs (str): The needs of the customer for product suggestions.\\n    suggestion_agent (object): The suggestion agent to interact with for recommendations.\\n\\n    Returns:\\n    list: A list of suggested products based on customer needs.\\n    \"\"\"\\n    # Define API keys\\n    os.environ[\"OPENAI_API_KEY\"] = \"*INSERT OPENAI API KEY HERE*\"\\n    \\n    # Define the prompt for the suggestion agent\\n    prompt = f\"Based on the following customer needs: \\'{customer_needs}\\', suggest relevant products.\"\\n    \\n    # Initialize the model\\n    model = OpenAI(temperature=0)\\n    \\n    # Execute the workflow to get product suggestions\\n    suggested_products = execute_workflow(llm=model, prompt_string=prompt)\\n    \\n    return suggested_products\\n```'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:59:45,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "```python\n",
      "import os\n",
      "from langchain import Graph, InMemoryCheckpointer\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
      "from langchain.output_parsers import StructuredOutputParser\n",
      "from pydantic import BaseModel\n",
      "from typing import List, Dict, Any\n",
      "from langchain_agentql.tools import ExtractWebDataTool\n",
      "from lemonai import execute_workflow\n",
      "from langchain_openai import OpenAI\n",
      "\n",
      "# Define MessagesState as a Pydantic model for structured output\n",
      "class Message(BaseModel):\n",
      "    role: str\n",
      "    content: str\n",
      "\n",
      "class MessagesState(BaseModel):\n",
      "    messages: List[Message]\n",
      "\n",
      "# Initialize the LLM\n",
      "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
      "\n",
      "# Inquiry node implementation using structured output with langchain\n",
      "def inquiry_node(state: MessagesState) -> MessagesState:\n",
      "    \"\"\"This node handles customer inquiries and invokes the inquiry agent.\"\"\"\n",
      "    # Use the LLM with structured output to ensure the output conforms to MessagesState schema\n",
      "    parser = StructuredOutputParser(pydantic_object=MessagesState)\n",
      "    prompt_messages = [HumanMessage(content=state.json())]\n",
      "    response = llm.generate([prompt_messages])\n",
      "    # Parse the LLM output to MessagesState\n",
      "    parsed = parser.parse(response.generations[0][0].text)\n",
      "    return parsed\n",
      "\n",
      "def handle_customer_inquiry(inquiry_data: str, customer_id: int) -> dict:\n",
      "    \"\"\"\n",
      "    Handles customer inquiries by processing the input inquiry data and invoking an inquiry agent \n",
      "    to provide a response or resolution to the customer.\n",
      "\n",
      "    Parameters:\n",
      "    inquiry_data (str): The inquiry data provided by the customer.\n",
      "    customer_id (int): The unique identifier for the customer.\n",
      "\n",
      "    Returns:\n",
      "    dict: A dictionary containing the response and status of the inquiry handling.\n",
      "    \"\"\"\n",
      "    # Define API key\n",
      "    os.environ[\"AGENTQL_API_KEY\"] = \"YOUR_AGENTQL_API_KEY\"\n",
      "    \n",
      "    # Instantiate the ExtractWebDataTool\n",
      "    extract_web_data_tool = ExtractWebDataTool()\n",
      "    \n",
      "    # Process the inquiry using the tool\n",
      "    response_data = extract_web_data_tool.invoke({\n",
      "        \"url\": \"https://example.com/inquiry\",  # Replace with actual URL if needed\n",
      "        \"prompt\": inquiry_data\n",
      "    })\n",
      "    \n",
      "    # Extract response and status\n",
      "    response = response_data.get('data', {}).get('response', 'No response found')\n",
      "    status = True if response else False\n",
      "    \n",
      "    return {\n",
      "        \"response\": response,\n",
      "        \"status\": status\n",
      "    }\n",
      "\n",
      "# Suggestion node implementation using langchain LLM invocation\n",
      "def suggestion_node(state: MessagesState) -> MessagesState:\n",
      "    \"\"\"This node suggests products based on customer needs and invokes the suggestion agent.\"\"\"\n",
      "    messages = [msg.dict() for msg in state.messages]\n",
      "\n",
      "    # Extract customer needs from user messages\n",
      "    customer_needs = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\n",
      "\n",
      "    # Construct prompt for suggestion agent\n",
      "    prompt = (\n",
      "        \"You are a product suggestion agent. Based on the following customer needs, \"\n",
      "        \"analyze their preferences, requirements, and context, then suggest the most suitable products.\\n\\n\"\n",
      "        \"Customer needs:\\n\"\n",
      "        + \"\\n\".join(f\"- {need}\" for need in customer_needs)\n",
      "        + \"\\n\\nPlease provide relevant product recommendations.\"\n",
      "    )\n",
      "\n",
      "    # Append system message with prompt\n",
      "    messages.append({\"role\": \"system\", \"content\": prompt})\n",
      "\n",
      "    # Convert messages to langchain BaseMessage list\n",
      "    lc_messages: List[BaseMessage] = []\n",
      "    for m in messages:\n",
      "        if m[\"role\"] == \"system\":\n",
      "            lc_messages.append(SystemMessage(content=m[\"content\"]))\n",
      "        elif m[\"role\"] == \"user\":\n",
      "            lc_messages.append(HumanMessage(content=m[\"content\"]))\n",
      "        elif m[\"role\"] == \"assistant\":\n",
      "            lc_messages.append(AIMessage(content=m[\"content\"]))\n",
      "        else:\n",
      "            # fallback to HumanMessage for unknown roles\n",
      "            lc_messages.append(HumanMessage(content=m[\"content\"]))\n",
      "\n",
      "    # Invoke LLM to get product suggestions\n",
      "    response = llm(lc_messages)\n",
      "\n",
      "    # Append assistant message with suggestions\n",
      "    messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
      "\n",
      "    # Return updated state\n",
      "    updated_state = MessagesState(messages=[Message(**msg) for msg in messages])\n",
      "    return updated_state\n",
      "\n",
      "def suggestion_node(customer_needs: str, suggestion_agent: object) -> list:\n",
      "    \"\"\"\n",
      "    Suggests products to customers based on their needs and interacts with a suggestion agent to provide tailored recommendations.\n",
      "\n",
      "    Parameters:\n",
      "    customer_needs (str): The needs of the customer for product suggestions.\n",
      "    suggestion_agent (object): The suggestion agent to interact with for recommendations.\n",
      "\n",
      "    Returns:\n",
      "    list: A list of suggested products based on customer needs.\n",
      "    \"\"\"\n",
      "    # Define API keys\n",
      "    os.environ[\"OPENAI_API_KEY\"] = \"*INSERT OPENAI API KEY HERE*\"\n",
      "    \n",
      "    # Define the prompt for the suggestion agent\n",
      "    prompt = f\"Based on the following customer needs: '{customer_needs}', suggest relevant products.\"\n",
      "    \n",
      "    # Initialize the model\n",
      "    model = OpenAI(temperature=0)\n",
      "    \n",
      "    # Execute the workflow to get product suggestions\n",
      "    suggested_products = execute_workflow(llm=model, prompt_string=prompt)\n",
      "    \n",
      "    return suggested_products\n",
      "\n",
      "# Create the graph and add nodes\n",
      "graph = Graph()\n",
      "\n",
      "graph.add_node(\"inquiry\", inquiry_node)\n",
      "graph.add_node(\"suggestion\", suggestion_node)\n",
      "\n",
      "# Add edges as per the workflow (all non-conditional)\n",
      "graph.add_edge(\"__START__\", \"inquiry\")\n",
      "graph.add_edge(\"inquiry\", \"suggestion\")\n",
      "graph.add_edge(\"inquiry\", \"__END__\")\n",
      "graph.add_edge(\"suggestion\", \"inquiry\")\n",
      "graph.add_edge(\"suggestion\", \"__END__\")\n",
      "\n",
      "# Compile the graph with InMemoryCheckpointer\n",
      "final_app = graph.compile(checkpointer=InMemoryCheckpointer())\n",
      "```\n",
      "User (q/Q to quit): q\n",
      "AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "cached_human_responses = [\"hi!\", \"rag prompt\", \"1 rag, 2 none, 3 no, 4 no\", \"red\", \"q\"]\n",
    "cached_response_index = 0\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"User (q/Q to quit): \")\n",
    "    except:\n",
    "        user = cached_human_responses[cached_response_index]\n",
    "        cached_response_index += 1\n",
    "    print(f\"User (q/Q to quit): {user}\")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in infograph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"prompt\" in output:\n",
    "        print(\"Done!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154a778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
