{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import NotebookLoader, WebBaseLoader\n",
    "from pathlib import Path\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "openai_api_type=\"azure\",\n",
    "openai_api_version=os.environ[\"OPENAI_API_EMBEDDING_VERSION\"],\n",
    "openai_api_key=os.environ[\"OPENAI_API_EMBEDDING_KEY\"],\n",
    "azure_endpoint=os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"],\n",
    "deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"],\n",
    "model=os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "validate_base_url=True,\n",
    ")\n",
    "\n",
    "# Specify the directory path\n",
    "base_directory = Path(\"D:/langchain-academy\")\n",
    "notebook_files = base_directory.rglob(\"*.ipynb\")\n",
    "\n",
    "# documents = []\n",
    "# for notebook in notebook_files:\n",
    "#     loader = NotebookLoader(\n",
    "#     notebook,\n",
    "#     include_outputs=True,\n",
    "#     max_output_length=20,\n",
    "#     remove_newline=True)\n",
    "#     document = loader.load()\n",
    "#     documents.append(document[0])\n",
    "    \n",
    "# Docs to index\n",
    "urls = [\n",
    "    \"https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/concepts/multi_agent/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\"\n",
    "]\n",
    "\n",
    "# Load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "len(doc_splits)\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "ids = vector_store.add_documents(documents=doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={'k': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "results = retriever.invoke(\"What are the different multi agent architectures?\")\n",
    "relevant_docs = format_docs(results)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": relevant_docs, \"question\": \"What multi agent architecture would be appropriate to build a nutritional agent? Generate an agent design accordingly? Try generating plan in UML syntax\"})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
