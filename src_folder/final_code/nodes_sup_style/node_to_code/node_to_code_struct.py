from langgraph.types import Command
from langchain_core.messages import SystemMessage, HumanMessage
from final_code.llms.model_factory import get_model
from final_code.nodes_sup_style.node_to_code.node_to_code_base import NodeBuilderState
from typing import Literal

llm = get_model()

struc_output_prompt = """
    User will provide you with the information about the node,  you are supposed to analyze the information and see if it requires LLM (aka model)'s 'with_structured_output()' function.

Here is information about structured outputs, why and when to use structured outputs:
<AboutStructuredOutput>
Structured output is beneficial in situations where consistent and verifiable data formats are needed, especially when integrating with databases, APIs, or building complex workflows. It helps reduce hallucinations, simplifies prompting, and enables reliable type-safety, making applications more predictable and easier to evaluate. 

Here's a more detailed breakdown:
1. Reduced Hallucinations: By enforcing adherence to a JSON Schema, structured outputs minimize the chance of models generating incorrect or irrelevant data. 
2. Simplified Prompting: You don't need overly complex or specific prompts to get consistently formatted output, as the schema provides the structure. 
3. Reliable Type-Safety: Structured outputs ensure that the model always generates data that fits the defined schema, eliminating the need for validation or retries due to format errors. 
4. Building Complex Workflows: Structured outputs are particularly useful for building multi-step workflows where the output of one step serves as input for the next. 
5. Integration with Databases and APIs: When integrating with systems that require structured data formats (like databases or APIs), structured outputs ensure consistency and avoid integration problems. 
6. Function Calling and Data Extraction: Structured outputs are recommended for function calling and extracting structured data from various sources. 
7. Consistent and Verifiable Output: The predictable format of structured outputs makes it easier to test, debug, and evaluate applications that rely on them. 
8. Explicit Refusals: You can now detect model refusals programmatically when using structured outputs, as the model will explicitly return a structured error message instead of a text-based one. 

In essence, structured output provides a robust and predictable way to manage the output of language models, making them more reliable and easier to integrate into various applications. 
</AboutStructuredOutput>

Here is an example showing how to use 'with_structured_output' method is below:
<StructuredOutputExample>
Here is an example of how to use structured output. In this example, we want the LLM to generate and fill up the pydantic class Joke, based on user query. 
``` python
from typing import Optional
from pydantic import BaseModel, Field


# Pydantic class for structured output
class Joke(BaseModel):
    setup: str = Field(description="The setup of the joke")
    punchline: str = Field(description="The punchline to the joke")
    rating: Optional[int] = Field(
        default=None, description="How funny the joke is, from 1 to 10"
    )

class JokeBuilderState(MessagesState):
    joke: Joke = Field(description= "joke generated by the GenerateJoke node.")

def GenerateJoke(state: JokeBuilderState):
    structured_llm = llm.with_structured_output(Joke)
    joke: Joke = structured_llm.invoke("Tell me a joke about cats")
    return { "joke": joke }
```

Output:
Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=7)
</StructuredOutputExample>
    
<Notes> 
1. The structured output pydantic class is not to be the same as the input_schema or output_schema, need to be specific
2. Do not hallucinate or write your own code to implement structured output, refer to 'StructuredOutputExample' section
</Notes>
    
<Output>
Check if the node needs llm's structured output functionality based on 'AboutStructuredOutput' section.
If yes, you are supposed to generate the code for the structured output functionality for the llm to use. 
If not needed, just mention there is no need for structured output functionality.
</Output>
    """

def structured_output_generation(state: NodeBuilderState) -> Command[Literal["ai_node_gen_supervisor"]]:
    """Generate the code for the node."""
    # fetch_documents("https://python.langchain.com/docs/how_to/structured_output/")
    result = llm.invoke( [SystemMessage(content=struc_output_prompt)]  + state["messages"])

    return Command(
        update={
            "past_steps": [(state["task"], result.content)],
            "messages": [
                HumanMessage(content=result.content, name="struct_output_generator")
            ]
            
        },
        goto="replan",
    )
