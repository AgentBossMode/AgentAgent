{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f896dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanishkgupta/Documents/GitHub/AgentAgent/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from phase1_json_dfs import compiler_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45227260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_objects = {\n",
    "  \"nodes\": [\n",
    "    {\n",
    "      \"id\": \"__START__\",\n",
    "      \"schema_info\": \"\",\n",
    "      \"input_schema\": \"\",\n",
    "      \"output_schema\": \"\",\n",
    "      \"description\": \"Entry point of the graph.\",\n",
    "      \"function_name\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"planner\",\n",
    "      \"schema_info\": \"PlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\",\n",
    "      \"input_schema\": \"PlanExecute\",\n",
    "      \"output_schema\": \"PlanExecute\",\n",
    "      \"description\": \"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\",\n",
    "      \"function_name\": \"plan_step\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"agent\",\n",
    "      \"schema_info\": \"PlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\",\n",
    "      \"input_schema\": \"PlanExecute\",\n",
    "      \"output_schema\": \"PlanExecute\",\n",
    "      \"description\": \"Uses llm with tool binding for the stock related queries\",\n",
    "      \"function_name\": \"execute_step\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"replan\",\n",
    "      \"schema_info\": \"PlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\",\n",
    "      \"input_schema\": \"PlanExecute\",\n",
    "      \"output_schema\": \"Union[Response, Plan]\",\n",
    "      \"description\": \"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\",\n",
    "      \"function_name\": \"replan_step\"\n",
    "    },\n",
    "    {\n",
    "      \"id\":\"__END__\",\n",
    "      \"schema_info\": \"\",\n",
    "      \"input_schema\": \"\",\n",
    "      \"output_schema\": \"\",\n",
    "      \"description\": \"End point of the graph.\",\n",
    "      \"function_name\": \"\"\n",
    "    }\n",
    "  ],\n",
    "  \"edges\": [\n",
    "    {\n",
    "      \"source\": \"__START__\",\n",
    "      \"target\": \"planner\",\n",
    "      \"routing_conditions\": \"Start the planning process.\",\n",
    "      \"conditional\": False\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"planner\",\n",
    "      \"target\": \"agent\",\n",
    "      \"routing_conditions\": \"After planning, execute the first step.\",\n",
    "      \"conditional\": False\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"agent\",\n",
    "      \"target\": \"replan\",\n",
    "      \"routing_conditions\": \"After executing a step, check if replanning is needed.\",\n",
    "      \"conditional\": False\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"replan\",\n",
    "      \"target\": \"agent\",\n",
    "      \"routing_conditions\": \"If no response is generated, continue to agent for further execution.\",\n",
    "      \"conditional\": True\n",
    "    },\n",
    "    {\n",
    "      \"source\": \"replan\",\n",
    "      \"target\": \"__END__\",\n",
    "      \"routing_conditions\": \"If a response is generated, end the process.\",\n",
    "      \"conditional\": True\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "result_str =  json.dumps(json_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9244762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identify_node': {'node_type': 'planner', 'messages': [HumanMessage(content='\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nPlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\\n</SchemaInfo>\\n<InputSchema>\\nPlanExecute\\n</InputSchema>\\n<OutputSchema>\\nUnion[Response, Plan]\\n</OutputSchema>\\n<Description>\\nEvaluates progress and uses an LLM to either revise the plan or generate a final response.\\n</Description>\\n<FunctionName>\\nreplan_step\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef replan_step(state:PlanExecute) -> Union[Response, Plan]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type PlanExecute and the function is of type Union[Response, Plan]\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n', additional_kwargs={}, response_metadata={}, id='a960eae6-7425-416c-990c-63c0f02fd48e')], 'node_info': '\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nPlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\\n</SchemaInfo>\\n<InputSchema>\\nPlanExecute\\n</InputSchema>\\n<OutputSchema>\\nUnion[Response, Plan]\\n</OutputSchema>\\n<Description>\\nEvaluates progress and uses an LLM to either revise the plan or generate a final response.\\n</Description>\\n<FunctionName>\\nreplan_step\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef replan_step(state:PlanExecute) -> Union[Response, Plan]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type PlanExecute and the function is of type Union[Response, Plan]\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n'}}\n",
      "{'node_process': {'node_reports': [NodeEvaluationReport(node_name='__END__', node_code_stub='no implementation needed', edge_code='# Since there are no edges or conditional edges specified in the EdgeInformation, no edge implementation is needed.\\n\\n# No code to implement as there are no edges or routing described.')]}}\n",
      "{'identify_node': {'node_type': 'planner', 'messages': [HumanMessage(content='\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nPlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\\n</SchemaInfo>\\n<InputSchema>\\nPlanExecute\\n</InputSchema>\\n<OutputSchema>\\nPlanExecute\\n</OutputSchema>\\n<Description>\\nPlan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\\n</Description>\\n<FunctionName>\\nplan_step\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef plan_step(state:PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type PlanExecute and the function is of type PlanExecute\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n', additional_kwargs={}, response_metadata={}, id='9fd3cdd5-1a2e-4ca2-b99b-41a31183e8d1')], 'node_info': '\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nPlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\\n</SchemaInfo>\\n<InputSchema>\\nPlanExecute\\n</InputSchema>\\n<OutputSchema>\\nPlanExecute\\n</OutputSchema>\\n<Description>\\nPlan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\\n</Description>\\n<FunctionName>\\nplan_step\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef plan_step(state:PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type PlanExecute and the function is of type PlanExecute\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n'}}\n",
      "{'identify_node': {'node_type': 'planner', 'messages': [HumanMessage(content='\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nPlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\\n</SchemaInfo>\\n<InputSchema>\\nPlanExecute\\n</InputSchema>\\n<OutputSchema>\\nPlanExecute\\n</OutputSchema>\\n<Description>\\nUses llm with tool binding for the stock related queries\\n</Description>\\n<FunctionName>\\nexecute_step\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef execute_step(state:PlanExecute) -> PlanExecute:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type PlanExecute and the function is of type PlanExecute\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n', additional_kwargs={}, response_metadata={}, id='0e182244-8d3b-46db-a8ba-cd39cb1d9b79')], 'node_info': '\\nYou are provided with the following information about the node:\\n<SchemaInfo>\\nPlanExecute: TypedDict with fields input (str), plan (List[str]), past_steps (Annotated[List[Tuple], operator.add]), response (str)\\n</SchemaInfo>\\n<InputSchema>\\nPlanExecute\\n</InputSchema>\\n<OutputSchema>\\nPlanExecute\\n</OutputSchema>\\n<Description>\\nUses llm with tool binding for the stock related queries\\n</Description>\\n<FunctionName>\\nexecute_step\\n</FunctionName>\\n\\nBelow is the skeleton of the function that you need to implement:\\ndef execute_step(state:PlanExecute) -> PlanExecute:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    # Implement the function to meet the description.\\n    \\nthe state is of type PlanExecute and the function is of type PlanExecute\\nThe general idea is that the implementation would involve extracting the input from the state, and updating the state with the output. Description contains the logic for this blackbox\\n'}}\n",
      "{'node_process': {'node_reports': [NodeEvaluationReport(node_name='__START__', node_code_stub='no implementation needed', edge_code='```python\\n# Since the edge is non-conditional and always routes from __START__ to planner,\\n# we use the add_edge method directly.\\n\\ngraph.add_edge(\"__START__\", \"planner\")\\n```')]}}\n",
      "{'planner': {'plan': [\"Extract the 'input', 'plan', 'past_steps', and 'response' fields from the provided state object.\", 'Generate a prompt that instructs the LLM to evaluate the current progress based on the extracted information and decide whether to revise the plan or produce a final response.', 'Use structured output functionality to enforce a JSON schema that captures either a revised plan or a final response, ensuring type safety and consistency.', \"Return the structured output as the result of the function, which will be either a 'Plan' object with updated steps or a 'Response' object with the final answer.\"]}}\n",
      "{'planner': {'plan': ['Extract the user query from the input field of the state.', 'Generate a prompt that is designed to handle stock-related queries effectively.', 'Bind the generated prompt with the appropriate stock-related tools using the toolset_generation capability.', 'Update the plan field in the state with the steps or instructions derived from the prompt and tool binding.', 'Return the updated state with the new plan, keeping the input, past_steps, and response fields unchanged.']}}\n",
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': \"Extract the 'input', 'plan', 'past_steps', and 'response' fields from the provided state object.\", 'messages': [AIMessage(content=\"Step 1 requires extracting specific fields from the provided state object to generate a prompt for the LLM. The prompt_generation worker is best suited to create this prompt based on the extracted 'input', 'plan', 'past_steps', and 'response' fields, setting up the next step for evaluation.\", additional_kwargs={}, response_metadata={}, id='1601cafd-05db-48a5-b0d5-0140889bbaf4')]}}\n",
      "{'planner': {'plan': ['Generate a prompt that instructs the LLM to create a step-by-step plan based on the input query.', 'Use the structured output functionality of the LLM to produce the plan in a consistent, JSON-like format.', \"Extract the generated plan from the structured output and update the 'plan' field in the state with this plan.\", 'Return the updated state containing the original input, the generated plan, past steps, and response.']}}\n",
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': 'Extract the user query from the input field of the state.', 'messages': [AIMessage(content='Step 1 requires extracting the user query from the input field of the state, which is a prerequisite for generating a prompt. The prompt_generation worker is best suited to handle this extraction and prepare the prompt for subsequent steps.', additional_kwargs={}, response_metadata={}, id='bbf06baa-fa53-47a7-bd62-5c8f1019b8b5')]}}\n",
      "{'prompt_generation': {'past_steps': [(\"Extract the 'input', 'plan', 'past_steps', and 'response' fields from the provided state object.\", 'Given the current task input, the existing plan, the past steps taken, and the latest response, evaluate the progress made so far. Based on this evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task. Provide the updated plan as a list of steps if revision is needed, or provide the final response text if the task is complete.')], 'messages': [HumanMessage(content='Given the current task input, the existing plan, the past steps taken, and the latest response, evaluate the progress made so far. Based on this evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task. Provide the updated plan as a list of steps if revision is needed, or provide the final response text if the task is complete.', additional_kwargs={}, response_metadata={}, name='prompt_generator', id='e9c421a3-3d8e-40e3-a9e1-5959442960d8')]}}\n",
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': 'Generate a prompt that instructs the LLM to create a step-by-step plan based on the input query.', 'messages': [AIMessage(content=\"Step 1 requires generating a prompt that instructs the LLM to create a step-by-step plan based on the input query. The 'prompt_generation' worker is responsible for creating such prompts, so it is the appropriate worker to act next.\", additional_kwargs={}, response_metadata={}, id='4adfac88-815a-4050-87fe-3259ca1405fc')]}}\n",
      "{'prompt_generation': {'past_steps': [('Generate a prompt that instructs the LLM to create a step-by-step plan based on the input query.', 'Given the input task, generate a detailed step-by-step plan to accomplish it. Break down the task into clear, logical steps that can be followed sequentially. Provide the plan as a list of concise action items. Do not execute the steps, only produce the plan.')], 'messages': [HumanMessage(content='Given the input task, generate a detailed step-by-step plan to accomplish it. Break down the task into clear, logical steps that can be followed sequentially. Provide the plan as a list of concise action items. Do not execute the steps, only produce the plan.', additional_kwargs={}, response_metadata={}, name='prompt_generator', id='a0fd5d92-5b8c-4979-8662-3f5a370f11ec')]}}\n",
      "{'prompt_generation': {'past_steps': [('Extract the user query from the input field of the state.', \"You are an expert assistant specialized in handling stock-related queries using large language models (LLMs) with tool bindings. Given the current state containing the user's input query, a plan of steps to execute, past steps taken, and the current response, your task is to generate the next LLM prompt that will guide the model to process the stock-related query effectively. \\n\\nUse the input query to create a clear, concise prompt that instructs the LLM to utilize appropriate stock-related tools (such as stock price lookup, financial news retrieval, or market analysis) to answer the query. Incorporate the plan and past steps contextually to ensure continuity and coherence in the response generation.\\n\\nYour output should update the state by appending the new prompt or response generated by the LLM, reflecting progress in executing the plan for the stock-related query.\")], 'messages': [HumanMessage(content=\"You are an expert assistant specialized in handling stock-related queries using large language models (LLMs) with tool bindings. Given the current state containing the user's input query, a plan of steps to execute, past steps taken, and the current response, your task is to generate the next LLM prompt that will guide the model to process the stock-related query effectively. \\n\\nUse the input query to create a clear, concise prompt that instructs the LLM to utilize appropriate stock-related tools (such as stock price lookup, financial news retrieval, or market analysis) to answer the query. Incorporate the plan and past steps contextually to ensure continuity and coherence in the response generation.\\n\\nYour output should update the state by appending the new prompt or response generated by the LLM, reflecting progress in executing the plan for the stock-related query.\", additional_kwargs={}, response_metadata={}, name='prompt_generator', id='0c723924-9e66-4965-a1f7-f78502dcbbd7')]}}\n",
      "{'replan': {'plan': ['Generate a prompt that instructs the LLM to evaluate the current progress based on the extracted information and decide whether to revise the plan or produce a final response.', 'Use structured output functionality to enforce a JSON schema that captures either a revised plan or a final response, ensuring type safety and consistency.', \"Return the structured output as the result of the function, which will be either a 'Plan' object with updated steps or a 'Response' object with the final answer.\"]}}\n",
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': 'Generate a prompt that instructs the LLM to evaluate the current progress based on the extracted information and decide whether to revise the plan or produce a final response.', 'messages': [AIMessage(content=\"Step 1 requires generating a prompt that instructs the LLM to evaluate the current progress and decide on revising the plan or producing a final response. The 'prompt_generation' worker is responsible for creating such prompts, making it the appropriate next worker to execute this step.\", additional_kwargs={}, response_metadata={}, id='ec72c52b-ab21-42aa-bd80-ccd94a817435')]}}\n",
      "{'prompt_generation': {'past_steps': [('Generate a prompt that instructs the LLM to evaluate the current progress based on the extracted information and decide whether to revise the plan or produce a final response.', 'Given the task input, the current plan, the past steps taken, and the latest response, please evaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task. If revising the plan, provide the updated plan as a list of steps. If the task is complete, provide the final response text.')], 'messages': [HumanMessage(content='Given the task input, the current plan, the past steps taken, and the latest response, please evaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task. If revising the plan, provide the updated plan as a list of steps. If the task is complete, provide the final response text.', additional_kwargs={}, response_metadata={}, name='prompt_generator', id='8f42cd34-ade0-4fb9-a061-4e35206780fa')]}}\n",
      "{'replan': {'plan': ['Generate a prompt that is designed to handle stock-related queries effectively.', 'Bind the generated prompt with the appropriate stock-related tools using the toolset_generation capability.', 'Update the plan field in the state with the steps or instructions derived from the prompt and tool binding.', 'Return the updated state with the new plan, keeping the input, past_steps, and response fields unchanged.']}}\n",
      "{'ai_node_gen_supervisor': {'next': 'prompt_generation', 'task': 'Generate a prompt that is designed to handle stock-related queries effectively.', 'messages': [AIMessage(content=\"Step 1 requires generating a prompt designed to handle stock-related queries effectively. The 'prompt_generation' worker specializes in creating such prompts, making it the appropriate choice to execute this step.\", additional_kwargs={}, response_metadata={}, id='fb9eca16-97fd-4a27-9815-de9de342b69a')]}}\n",
      "{'replan': {'plan': ['Use the structured output functionality of the LLM to produce the plan in a consistent, JSON-like format.', \"Extract the generated plan from the structured output and update the 'plan' field in the state with this plan.\", 'Return the updated state containing the original input, the generated plan, past steps, and response.']}}\n",
      "{'prompt_generation': {'past_steps': [('Generate a prompt that is designed to handle stock-related queries effectively.', 'You are an expert assistant specialized in handling stock-related queries using large language models (LLMs) with tool bindings. The user has asked: \"{input}\". \\n\\nYou have a plan consisting of the following steps: {plan}. You have already completed these steps: {past_steps}.\\n\\nUsing this context, generate a clear and concise response or the next action to take, utilizing appropriate stock-related tools such as stock price lookup, financial news retrieval, or market analysis to address the user\\'s query effectively.\\n\\nUpdate the state by appending this response or action to the response field, reflecting progress in executing the plan for the stock-related query.')], 'messages': [HumanMessage(content='You are an expert assistant specialized in handling stock-related queries using large language models (LLMs) with tool bindings. The user has asked: \"{input}\". \\n\\nYou have a plan consisting of the following steps: {plan}. You have already completed these steps: {past_steps}.\\n\\nUsing this context, generate a clear and concise response or the next action to take, utilizing appropriate stock-related tools such as stock price lookup, financial news retrieval, or market analysis to address the user\\'s query effectively.\\n\\nUpdate the state by appending this response or action to the response field, reflecting progress in executing the plan for the stock-related query.', additional_kwargs={}, response_metadata={}, name='prompt_generator', id='1a2fc08f-ba91-4b70-a6e0-42560004765b')]}}\n",
      "{'replan': {'plan': ['Use structured output functionality to enforce a JSON schema that captures either a revised plan or a final response, ensuring type safety and consistency.', \"Return the structured output as the result of the function, which will be either a 'Plan' object with updated steps or a 'Response' object with the final answer.\"]}}\n",
      "{'ai_node_gen_supervisor': {'next': 'structured_output_generation', 'task': 'Use the structured output functionality of the LLM to produce the plan in a consistent, JSON-like format.', 'messages': [AIMessage(content=\"The step requires using the structured output functionality of the LLM to produce the plan in a consistent, JSON-like format. Therefore, the 'structured_output_generation' worker is the appropriate choice to execute this step.\", additional_kwargs={}, response_metadata={}, id='f458b479-b4f3-4c73-bb27-b40dc5254fcb')]}}\n",
      "{'ai_node_gen_supervisor': {'next': 'structured_output_generation', 'task': 'Use structured output functionality to enforce a JSON schema that captures either a revised plan or a final response, ensuring type safety and consistency.', 'messages': [AIMessage(content=\"The step requires enforcing a JSON schema to capture either a revised plan or a final response, ensuring type safety and consistency. The 'structured_output_generation' worker specializes in generating outputs that conform to specified JSON schemas, making it the appropriate choice to execute this step.\", additional_kwargs={}, response_metadata={}, id='04358d6b-4db7-46ae-845c-ef105c682485')]}}\n",
      "{'replan': {'plan': ['Bind the generated prompt with the appropriate stock-related tools using the toolset_generation capability.', 'Update the plan field in the state with the steps or instructions derived from the prompt and tool binding.']}}\n",
      "{'ai_node_gen_supervisor': {'next': 'toolset_generation', 'task': 'Bind the generated prompt with the appropriate stock-related tools using the toolset_generation capability.', 'messages': [AIMessage(content=\"The step requires binding the generated prompt with appropriate stock-related tools, which aligns with the capabilities of the 'toolset_generation' worker. Therefore, 'toolset_generation' should act next to perform this task.\", additional_kwargs={}, response_metadata={}, id='ff10e569-7399-403f-8f3d-09335ac9ec59')]}}\n",
      "{'structured_output_generation': {'past_steps': [('Use the structured output functionality of the LLM to produce the plan in a consistent, JSON-like format.', 'Yes, this node requires the LLM\\'s with_structured_output() function because it needs to generate a plan as a list of steps in a consistent and verifiable format, which aligns with the benefits of structured output (reliable type-safety, reduced hallucinations, and consistent output).\\n\\nHere is the code implementing the structured output functionality for the plan_step function:\\n\\n```python\\nfrom typing import List\\nfrom pydantic import BaseModel, Field\\n\\n# Define a Pydantic model for the structured output plan\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Create a structured LLM that outputs PlanOutput\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    \\n    # Invoke the LLM with the input task to generate the plan\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    \\n    # Update the state with the generated plan\\n    state[\"plan\"] = plan_output.plan\\n    \\n    # Return the updated state\\n    return state\\n```\\n\\nThis implementation ensures the plan is generated as a structured list of strings, fulfilling the node\\'s requirement and leveraging the benefits of structured output.')], 'messages': [HumanMessage(content='Yes, this node requires the LLM\\'s with_structured_output() function because it needs to generate a plan as a list of steps in a consistent and verifiable format, which aligns with the benefits of structured output (reliable type-safety, reduced hallucinations, and consistent output).\\n\\nHere is the code implementing the structured output functionality for the plan_step function:\\n\\n```python\\nfrom typing import List\\nfrom pydantic import BaseModel, Field\\n\\n# Define a Pydantic model for the structured output plan\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Create a structured LLM that outputs PlanOutput\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    \\n    # Invoke the LLM with the input task to generate the plan\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    \\n    # Update the state with the generated plan\\n    state[\"plan\"] = plan_output.plan\\n    \\n    # Return the updated state\\n    return state\\n```\\n\\nThis implementation ensures the plan is generated as a structured list of strings, fulfilling the node\\'s requirement and leveraging the benefits of structured output.', additional_kwargs={}, response_metadata={}, name='struct_output_generator', id='04bb499d-9bd8-47c6-b9b2-0308cff5c18c')]}}\n",
      "{'structured_output_generation': {'past_steps': [('Use structured output functionality to enforce a JSON schema that captures either a revised plan or a final response, ensuring type safety and consistency.', 'This node involves generating an output that can be either a revised plan (a list of steps) or a final response (text). To ensure consistent, verifiable, and type-safe outputs—especially since the output is a Union type—it is beneficial to use the LLM\\'s structured output functionality here.\\n\\nUsing structured output will:\\n- Reduce hallucinations by enforcing adherence to a schema.\\n- Ensure the output matches either a Plan or Response format.\\n- Simplify downstream processing and integration.\\n- Provide explicit refusals if the model cannot produce a valid output.\\n\\nHence, structured output is recommended.\\n\\nBelow is an example of how to implement the structured output functionality for this node:\\n\\n```python\\nfrom typing import List, Union, Literal\\nfrom pydantic import BaseModel, Field\\n\\n# Define structured output classes for Plan and Response\\n\\nclass Plan(BaseModel):\\n    type: Literal[\"plan\"] = Field(description=\"Indicates this is a plan output\")\\n    steps: List[str] = Field(description=\"Revised list of plan steps\")\\n\\nclass Response(BaseModel):\\n    type: Literal[\"response\"] = Field(description=\"Indicates this is a final response output\")\\n    text: str = Field(description=\"Final response text completing the task\")\\n\\n# Union of possible outputs\\nclass PlanOrResponse(BaseModel):\\n    __root__: Union[Plan, Response]\\n\\ndef replan_step(state: PlanExecute) -> Union[Response, Plan]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    structured_llm = llm.with_structured_output(PlanOrResponse)\\n    # Construct prompt from state.input, state.plan, state.past_steps, state.response\\n    prompt = f\"\"\"Given the task input: {state[\\'input\\']}\\nCurrent plan: {state[\\'plan\\']}\\nPast steps: {state[\\'past_steps\\']}\\nLatest response: {state[\\'response\\']}\\n\\nEvaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task.\\n\\nIf revising the plan, provide the updated plan as a list of steps.\\nIf the task is complete, provide the final response text.\\n\"\"\"\\n    output = structured_llm.invoke(prompt)\\n    # output is of type PlanOrResponse\\n    if isinstance(output.__root__, Plan):\\n        return output.__root__\\n    else:\\n        return output.__root__\\n```\\n\\nThis approach ensures the output is always either a valid Plan or Response object, making the node\\'s output predictable and easy to integrate.')], 'messages': [HumanMessage(content='This node involves generating an output that can be either a revised plan (a list of steps) or a final response (text). To ensure consistent, verifiable, and type-safe outputs—especially since the output is a Union type—it is beneficial to use the LLM\\'s structured output functionality here.\\n\\nUsing structured output will:\\n- Reduce hallucinations by enforcing adherence to a schema.\\n- Ensure the output matches either a Plan or Response format.\\n- Simplify downstream processing and integration.\\n- Provide explicit refusals if the model cannot produce a valid output.\\n\\nHence, structured output is recommended.\\n\\nBelow is an example of how to implement the structured output functionality for this node:\\n\\n```python\\nfrom typing import List, Union, Literal\\nfrom pydantic import BaseModel, Field\\n\\n# Define structured output classes for Plan and Response\\n\\nclass Plan(BaseModel):\\n    type: Literal[\"plan\"] = Field(description=\"Indicates this is a plan output\")\\n    steps: List[str] = Field(description=\"Revised list of plan steps\")\\n\\nclass Response(BaseModel):\\n    type: Literal[\"response\"] = Field(description=\"Indicates this is a final response output\")\\n    text: str = Field(description=\"Final response text completing the task\")\\n\\n# Union of possible outputs\\nclass PlanOrResponse(BaseModel):\\n    __root__: Union[Plan, Response]\\n\\ndef replan_step(state: PlanExecute) -> Union[Response, Plan]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    structured_llm = llm.with_structured_output(PlanOrResponse)\\n    # Construct prompt from state.input, state.plan, state.past_steps, state.response\\n    prompt = f\"\"\"Given the task input: {state[\\'input\\']}\\nCurrent plan: {state[\\'plan\\']}\\nPast steps: {state[\\'past_steps\\']}\\nLatest response: {state[\\'response\\']}\\n\\nEvaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task.\\n\\nIf revising the plan, provide the updated plan as a list of steps.\\nIf the task is complete, provide the final response text.\\n\"\"\"\\n    output = structured_llm.invoke(prompt)\\n    # output is of type PlanOrResponse\\n    if isinstance(output.__root__, Plan):\\n        return output.__root__\\n    else:\\n        return output.__root__\\n```\\n\\nThis approach ensures the output is always either a valid Plan or Response object, making the node\\'s output predictable and easy to integrate.', additional_kwargs={}, response_metadata={}, name='struct_output_generator', id='585f287d-d155-4678-a381-5b6c96f042f1')]}}\n",
      "{'replan': {'response': 'The plan to use structured output functionality to enforce a JSON schema for either a revised plan or a final response has been fully executed. The detailed implementation and justification have been provided. No further steps are needed.'}}\n",
      "{'replan': {'plan': ['Return the updated state containing the original input, the generated plan, past steps, and response.']}}\n",
      "{'ai_node_gen_supervisor': {'next': 'structured_output_generation', 'task': 'Return the updated state containing the original input, the generated plan, past steps, and response.', 'messages': [AIMessage(content=\"The step requires returning the updated state containing the original input, generated plan, past steps, and response. The 'structured_output_generation' worker is best suited to handle updating and returning structured data according to the PlanExecute schema.\", additional_kwargs={}, response_metadata={}, id='c599a5ce-213a-47b3-aba9-92ec5a8f8cb5')]}}\n",
      "{'toolset_generation': {'past_steps': [('Bind the generated prompt with the appropriate stock-related tools using the toolset_generation capability.', '```python\\nfrom typing import List, Tuple, Annotated, TypedDict\\nfrom langchain_core.tools import tool\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain_core.messages import SystemMessage\\nfrom langchain.chat_models import ChatAnthropic\\nfrom langgraph.graph import StateGraph, MessagesState, START, END\\n\\n# Define the tools needed by the LLM for stock-related queries\\n\\n@tool\\ndef get_stock_price(ticker: str):\\n    \"\"\"Get the current stock price for a given ticker symbol.\"\"\"\\n    # Placeholder implementation\\n    stock_prices = {\\n        \"AAPL\": \"Apple Inc. stock price is $150.\",\\n        \"GOOG\": \"Alphabet Inc. stock price is $2800.\",\\n        \"TSLA\": \"Tesla Inc. stock price is $700.\"\\n    }\\n    return stock_prices.get(ticker.upper(), \"Stock ticker not found.\")\\n\\n@tool\\ndef get_financial_news(company: str):\\n    \"\"\"Retrieve latest financial news for a given company.\"\"\"\\n    # Placeholder implementation\\n    return f\"Latest financial news for {company}: Company reports record earnings this quarter.\"\\n\\n@tool\\ndef get_market_analysis():\\n    \"\"\"Provide current market analysis summary.\"\"\"\\n    # Placeholder implementation\\n    return \"The market is bullish today with tech stocks leading the gains.\"\\n\\ntools = [get_stock_price, get_financial_news, get_market_analysis]\\n\\n# Bind the model (llm) with tools\\nmodel_with_tools = ChatAnthropic(\\n    model=\"claude-3-haiku-20240307\", temperature=0\\n).bind_tools(tools)\\n\\n# Generate a tool node.\\ntool_node = ToolNode(tools)\\n\\ndef execute_step(state: TypedDict) -> TypedDict:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    input_query = state[\"input\"]\\n    plan = state[\"plan\"]\\n    past_steps = state[\"past_steps\"]\\n    response = state[\"response\"]\\n\\n    # Prepare system message to instruct the model about the tools and task\\n    system_content = (\\n        \"You are a stock query assistant. You have access to tools like get_stock_price, \"\\n        \"get_financial_news, and get_market_analysis to help answer stock-related queries. \"\\n        \"Use these tools as needed to provide accurate and detailed responses.\"\\n    )\\n    system_message = SystemMessage(content=system_content)\\n\\n    # Prepare user messages including input query, plan and past steps context\\n    user_content = (\\n        f\"User query: {input_query}\\\\n\"\\n        f\"Plan: {plan}\\\\n\"\\n        f\"Past steps: {past_steps}\\\\n\"\\n        f\"Current response: {response}\\\\n\"\\n        \"Please analyze the query and respond using the tools if necessary.\"\\n    )\\n\\n    # Invoke the model with tools\\n    llm_response = model_with_tools.invoke([system_message, SystemMessage(content=user_content)])\\n\\n    # Update the state with the new response\\n    new_response = llm_response.content\\n    updated_state = {\\n        \"input\": input_query,\\n        \"plan\": plan,\\n        \"past_steps\": past_steps,\\n        \"response\": new_response\\n    }\\n    return updated_state\\n```')], 'messages': [HumanMessage(content='```python\\nfrom typing import List, Tuple, Annotated, TypedDict\\nfrom langchain_core.tools import tool\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain_core.messages import SystemMessage\\nfrom langchain.chat_models import ChatAnthropic\\nfrom langgraph.graph import StateGraph, MessagesState, START, END\\n\\n# Define the tools needed by the LLM for stock-related queries\\n\\n@tool\\ndef get_stock_price(ticker: str):\\n    \"\"\"Get the current stock price for a given ticker symbol.\"\"\"\\n    # Placeholder implementation\\n    stock_prices = {\\n        \"AAPL\": \"Apple Inc. stock price is $150.\",\\n        \"GOOG\": \"Alphabet Inc. stock price is $2800.\",\\n        \"TSLA\": \"Tesla Inc. stock price is $700.\"\\n    }\\n    return stock_prices.get(ticker.upper(), \"Stock ticker not found.\")\\n\\n@tool\\ndef get_financial_news(company: str):\\n    \"\"\"Retrieve latest financial news for a given company.\"\"\"\\n    # Placeholder implementation\\n    return f\"Latest financial news for {company}: Company reports record earnings this quarter.\"\\n\\n@tool\\ndef get_market_analysis():\\n    \"\"\"Provide current market analysis summary.\"\"\"\\n    # Placeholder implementation\\n    return \"The market is bullish today with tech stocks leading the gains.\"\\n\\ntools = [get_stock_price, get_financial_news, get_market_analysis]\\n\\n# Bind the model (llm) with tools\\nmodel_with_tools = ChatAnthropic(\\n    model=\"claude-3-haiku-20240307\", temperature=0\\n).bind_tools(tools)\\n\\n# Generate a tool node.\\ntool_node = ToolNode(tools)\\n\\ndef execute_step(state: TypedDict) -> TypedDict:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    input_query = state[\"input\"]\\n    plan = state[\"plan\"]\\n    past_steps = state[\"past_steps\"]\\n    response = state[\"response\"]\\n\\n    # Prepare system message to instruct the model about the tools and task\\n    system_content = (\\n        \"You are a stock query assistant. You have access to tools like get_stock_price, \"\\n        \"get_financial_news, and get_market_analysis to help answer stock-related queries. \"\\n        \"Use these tools as needed to provide accurate and detailed responses.\"\\n    )\\n    system_message = SystemMessage(content=system_content)\\n\\n    # Prepare user messages including input query, plan and past steps context\\n    user_content = (\\n        f\"User query: {input_query}\\\\n\"\\n        f\"Plan: {plan}\\\\n\"\\n        f\"Past steps: {past_steps}\\\\n\"\\n        f\"Current response: {response}\\\\n\"\\n        \"Please analyze the query and respond using the tools if necessary.\"\\n    )\\n\\n    # Invoke the model with tools\\n    llm_response = model_with_tools.invoke([system_message, SystemMessage(content=user_content)])\\n\\n    # Update the state with the new response\\n    new_response = llm_response.content\\n    updated_state = {\\n        \"input\": input_query,\\n        \"plan\": plan,\\n        \"past_steps\": past_steps,\\n        \"response\": new_response\\n    }\\n    return updated_state\\n```', additional_kwargs={}, response_metadata={}, name='toolset_generator', id='ad8f42e7-dcc6-476c-b06c-063a60497293')]}}\n",
      "{'code_compiler': {'final_code': '```python\\nfrom typing import List, Union, Literal, Tuple, Annotated\\nfrom pydantic import BaseModel, Field\\n\\n# Define structured output classes for Plan and Response\\n\\nclass Plan(BaseModel):\\n    type: Literal[\"plan\"] = Field(description=\"Indicates this is a plan output\")\\n    steps: List[str] = Field(description=\"Revised list of plan steps\")\\n\\nclass Response(BaseModel):\\n    type: Literal[\"response\"] = Field(description=\"Indicates this is a final response output\")\\n    text: str = Field(description=\"Final response text completing the task\")\\n\\n# Union of possible outputs\\nclass PlanOrResponse(BaseModel):\\n    __root__: Union[Plan, Response]\\n\\n# Define PlanExecute TypedDict as per schema info\\nfrom typing import TypedDict, List, Tuple, Annotated\\n\\nclass PlanExecute(TypedDict):\\n    input: str\\n    plan: List[str]\\n    past_steps: Annotated[List[Tuple], \"operator.add\"]\\n    response: str\\n\\ndef replan_step(state: PlanExecute) -> Union[Response, Plan]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    # Assume \\'llm\\' is a globally available LLM instance with structured output capability\\n    structured_llm = llm.with_structured_output(PlanOrResponse)\\n\\n    # Construct prompt from state fields\\n    prompt = f\"\"\"Given the task input: {state[\\'input\\']}\\nCurrent plan: {state[\\'plan\\']}\\nPast steps: {state[\\'past_steps\\']}\\nLatest response: {state[\\'response\\']}\\n\\nEvaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task.\\n\\nIf revising the plan, provide the updated plan as a list of steps.\\nIf the task is complete, provide the final response text.\\n\"\"\"\\n\\n    # Invoke the LLM with structured output\\n    output = structured_llm.invoke(prompt)\\n\\n    # output is of type PlanOrResponse\\n    # Return the inner Plan or Response object\\n    return output.__root__\\n```'}}\n",
      "{'structured_output_generation': {'past_steps': [('Return the updated state containing the original input, the generated plan, past steps, and response.', 'Yes, this node requires the LLM\\'s with_structured_output() function because it needs to generate a plan as a list of steps in a consistent and verifiable format, which aligns with the benefits of structured output (reliable type-safety, reduced hallucinations, and consistent output).\\n\\nHere is the code implementing the structured output functionality for the plan_step function:\\n\\n```python\\nfrom typing import List\\nfrom pydantic import BaseModel, Field\\n\\n# Define a Pydantic model for the structured output plan\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Create a structured LLM that outputs PlanOutput\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    \\n    # Invoke the LLM with the input task to generate the plan\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    \\n    # Update the state with the generated plan\\n    state[\"plan\"] = plan_output.plan\\n    \\n    # Return the updated state\\n    return state\\n```\\n\\nThis implementation ensures the plan is generated as a structured list of strings, fulfilling the node\\'s requirement and leveraging the benefits of structured output.')], 'messages': [HumanMessage(content='Yes, this node requires the LLM\\'s with_structured_output() function because it needs to generate a plan as a list of steps in a consistent and verifiable format, which aligns with the benefits of structured output (reliable type-safety, reduced hallucinations, and consistent output).\\n\\nHere is the code implementing the structured output functionality for the plan_step function:\\n\\n```python\\nfrom typing import List\\nfrom pydantic import BaseModel, Field\\n\\n# Define a Pydantic model for the structured output plan\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Create a structured LLM that outputs PlanOutput\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    \\n    # Invoke the LLM with the input task to generate the plan\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    \\n    # Update the state with the generated plan\\n    state[\"plan\"] = plan_output.plan\\n    \\n    # Return the updated state\\n    return state\\n```\\n\\nThis implementation ensures the plan is generated as a structured list of strings, fulfilling the node\\'s requirement and leveraging the benefits of structured output.', additional_kwargs={}, response_metadata={}, name='struct_output_generator', id='7805f6ac-5180-450f-9f71-c519b1eeed6a')]}}{'replan': {'response': 'The plan has been fully executed as per the OriginalPlan. The generated prompt has been successfully bound with the appropriate stock-related tools using the toolset_generation capability, and the state has been updated accordingly. No further steps are needed.'}}\n",
      "\n",
      "{'replan': {'response': 'The plan has been fully executed as per the OriginalPlan. The updated state now contains the original input, the generated plan, past steps, and response as required.'}}\n",
      "{'code_compiler': {'final_code': '```python\\nfrom typing import List\\nfrom pydantic import BaseModel, Field\\n\\n# Define a Pydantic model for the structured output plan\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Create a structured LLM that outputs PlanOutput\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    \\n    # Invoke the LLM with the input task to generate the plan\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    \\n    # Update the state with the generated plan\\n    state[\"plan\"] = plan_output.plan\\n    \\n    # Return the updated state\\n    return state\\n```'}}\n",
      "{'node_process': {'node_reports': [NodeEvaluationReport(node_name='planner', node_code_stub='```python\\nfrom typing import List\\nfrom pydantic import BaseModel, Field\\n\\n# Define a Pydantic model for the structured output plan\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    # Create a structured LLM that outputs PlanOutput\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    \\n    # Invoke the LLM with the input task to generate the plan\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    \\n    # Update the state with the generated plan\\n    state[\"plan\"] = plan_output.plan\\n    \\n    # Return the updated state\\n    return state\\n```', edge_code='```python\\n# Since the edge is non-conditional (always go from \\'planner\\' to \\'agent\\'),\\n# we use the add_edge method directly as per the NonConditionalEdges section.\\n\\ngraph.add_edge(\"planner\", \"agent\")\\n```')]}}\n",
      "{'node_process': {'node_reports': [NodeEvaluationReport(node_name='replan', node_code_stub='```python\\nfrom typing import List, Union, Literal, Tuple, Annotated\\nfrom pydantic import BaseModel, Field\\n\\n# Define structured output classes for Plan and Response\\n\\nclass Plan(BaseModel):\\n    type: Literal[\"plan\"] = Field(description=\"Indicates this is a plan output\")\\n    steps: List[str] = Field(description=\"Revised list of plan steps\")\\n\\nclass Response(BaseModel):\\n    type: Literal[\"response\"] = Field(description=\"Indicates this is a final response output\")\\n    text: str = Field(description=\"Final response text completing the task\")\\n\\n# Union of possible outputs\\nclass PlanOrResponse(BaseModel):\\n    __root__: Union[Plan, Response]\\n\\n# Define PlanExecute TypedDict as per schema info\\nfrom typing import TypedDict, List, Tuple, Annotated\\n\\nclass PlanExecute(TypedDict):\\n    input: str\\n    plan: List[str]\\n    past_steps: Annotated[List[Tuple], \"operator.add\"]\\n    response: str\\n\\ndef replan_step(state: PlanExecute) -> Union[Response, Plan]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    # Assume \\'llm\\' is a globally available LLM instance with structured output capability\\n    structured_llm = llm.with_structured_output(PlanOrResponse)\\n\\n    # Construct prompt from state fields\\n    prompt = f\"\"\"Given the task input: {state[\\'input\\']}\\nCurrent plan: {state[\\'plan\\']}\\nPast steps: {state[\\'past_steps\\']}\\nLatest response: {state[\\'response\\']}\\n\\nEvaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task.\\n\\nIf revising the plan, provide the updated plan as a list of steps.\\nIf the task is complete, provide the final response text.\\n\"\"\"\\n\\n    # Invoke the LLM with structured output\\n    output = structured_llm.invoke(prompt)\\n\\n    # output is of type PlanOrResponse\\n    # Return the inner Plan or Response object\\n    return output.__root__\\n```', edge_code='```python\\nfrom typing import Union, Literal\\nfrom langgraph.graph import StateGraph, END\\nfrom langgraph.types import Command\\n\\n# Assuming the replan_step node function is already defined as provided\\n\\n# Create the graph builder\\ngraph = StateGraph(PlanExecute)\\n\\n# Add the replan node\\ngraph.add_node(\"replan\", replan_step)\\n\\n# Define the routing function for conditional edges from \\'replan\\'\\ndef replan_routing_function(state: PlanExecute) -> Union[Literal[\"agent\"], Literal[END]]:\\n    # If a response is generated (i.e., output is of type Response), end the process\\n    # Otherwise, continue to \\'agent\\' for further execution\\n    # We check if the \\'response\\' field in state is non-empty to decide\\n    # But since replan_step returns either Plan or Response, we need to check state accordingly\\n    # Here, we assume state has a key or flag indicating if response is generated\\n    # Since state is PlanExecute, we check if \\'response\\' is non-empty string\\n    if state[\"response\"]:\\n        return END\\n    else:\\n        return \"agent\"\\n\\n# Add conditional edges from \\'replan\\' node using the routing function\\ngraph.add_conditional_edges(\"replan\", replan_routing_function, {END: END, \"agent\": \"agent\"})\\n\\n# Note: The \\'agent\\' node should be added elsewhere in the graph definition\\n\\n# The graph now routes conditionally from \\'replan\\' to either \\'agent\\' or END based on response presence\\n```\\n\\n# Explanation:\\n# - We use add_conditional_edges from \\'replan\\' with a routing function that checks the state.\\n# - If \\'response\\' in state is non-empty, we route to END to stop the graph.\\n# - Otherwise, we route to \\'agent\\' node for further execution.\\n# - This matches the edge information conditions given.\\n```')]}}\n",
      "{'code_compiler': {'final_code': '```python\\nfrom typing import List, Tuple, Annotated, TypedDict\\nfrom langchain_core.tools import tool\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain_core.messages import SystemMessage\\nfrom langchain.chat_models import ChatAnthropic\\n\\n# Define the PlanExecute TypedDict as per schema info\\nclass PlanExecute(TypedDict):\\n    input: str\\n    plan: List[str]\\n    past_steps: Annotated[List[Tuple], \"operator.add\"]\\n    response: str\\n\\n# Define the tools needed by the LLM for stock-related queries\\n\\n@tool\\ndef get_stock_price(ticker: str):\\n    \"\"\"Get the current stock price for a given ticker symbol.\"\"\"\\n    # Placeholder implementation\\n    stock_prices = {\\n        \"AAPL\": \"Apple Inc. stock price is $150.\",\\n        \"GOOG\": \"Alphabet Inc. stock price is $2800.\",\\n        \"TSLA\": \"Tesla Inc. stock price is $700.\"\\n    }\\n    return stock_prices.get(ticker.upper(), \"Stock ticker not found.\")\\n\\n@tool\\ndef get_financial_news(company: str):\\n    \"\"\"Retrieve latest financial news for a given company.\"\"\"\\n    # Placeholder implementation\\n    return f\"Latest financial news for {company}: Company reports record earnings this quarter.\"\\n\\n@tool\\ndef get_market_analysis():\\n    \"\"\"Provide current market analysis summary.\"\"\"\\n    # Placeholder implementation\\n    return \"The market is bullish today with tech stocks leading the gains.\"\\n\\ntools = [get_stock_price, get_financial_news, get_market_analysis]\\n\\n# Bind the model (llm) with tools\\nmodel_with_tools = ChatAnthropic(\\n    model=\"claude-3-haiku-20240307\", temperature=0\\n).bind_tools(tools)\\n\\ndef execute_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    input_query = state[\"input\"]\\n    plan = state[\"plan\"]\\n    past_steps = state[\"past_steps\"]\\n    response = state[\"response\"]\\n\\n    # Prepare system message to instruct the model about the tools and task\\n    system_content = (\\n        \"You are a stock query assistant. You have access to tools like get_stock_price, \"\\n        \"get_financial_news, and get_market_analysis to help answer stock-related queries. \"\\n        \"Use these tools as needed to provide accurate and detailed responses.\"\\n    )\\n    system_message = SystemMessage(content=system_content)\\n\\n    # Prepare user message including input query, plan and past steps context\\n    user_content = (\\n        f\"User query: {input_query}\\\\n\"\\n        f\"Plan: {plan}\\\\n\"\\n        f\"Past steps: {past_steps}\\\\n\"\\n        f\"Current response: {response}\\\\n\"\\n        \"Please analyze the query and respond using the tools if necessary.\"\\n    )\\n    user_message = SystemMessage(content=user_content)\\n\\n    # Invoke the model with tools\\n    llm_response = model_with_tools.invoke([system_message, user_message])\\n\\n    # Update the state with the new response\\n    new_response = llm_response.content\\n    updated_state: PlanExecute = {\\n        \"input\": input_query,\\n        \"plan\": plan,\\n        \"past_steps\": past_steps,\\n        \"response\": new_response\\n    }\\n    return updated_state\\n```'}}\n",
      "{'node_process': {'node_reports': [NodeEvaluationReport(node_name='agent', node_code_stub='```python\\nfrom typing import List, Tuple, Annotated, TypedDict\\nfrom langchain_core.tools import tool\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain_core.messages import SystemMessage\\nfrom langchain.chat_models import ChatAnthropic\\n\\n# Define the PlanExecute TypedDict as per schema info\\nclass PlanExecute(TypedDict):\\n    input: str\\n    plan: List[str]\\n    past_steps: Annotated[List[Tuple], \"operator.add\"]\\n    response: str\\n\\n# Define the tools needed by the LLM for stock-related queries\\n\\n@tool\\ndef get_stock_price(ticker: str):\\n    \"\"\"Get the current stock price for a given ticker symbol.\"\"\"\\n    # Placeholder implementation\\n    stock_prices = {\\n        \"AAPL\": \"Apple Inc. stock price is $150.\",\\n        \"GOOG\": \"Alphabet Inc. stock price is $2800.\",\\n        \"TSLA\": \"Tesla Inc. stock price is $700.\"\\n    }\\n    return stock_prices.get(ticker.upper(), \"Stock ticker not found.\")\\n\\n@tool\\ndef get_financial_news(company: str):\\n    \"\"\"Retrieve latest financial news for a given company.\"\"\"\\n    # Placeholder implementation\\n    return f\"Latest financial news for {company}: Company reports record earnings this quarter.\"\\n\\n@tool\\ndef get_market_analysis():\\n    \"\"\"Provide current market analysis summary.\"\"\"\\n    # Placeholder implementation\\n    return \"The market is bullish today with tech stocks leading the gains.\"\\n\\ntools = [get_stock_price, get_financial_news, get_market_analysis]\\n\\n# Bind the model (llm) with tools\\nmodel_with_tools = ChatAnthropic(\\n    model=\"claude-3-haiku-20240307\", temperature=0\\n).bind_tools(tools)\\n\\ndef execute_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    input_query = state[\"input\"]\\n    plan = state[\"plan\"]\\n    past_steps = state[\"past_steps\"]\\n    response = state[\"response\"]\\n\\n    # Prepare system message to instruct the model about the tools and task\\n    system_content = (\\n        \"You are a stock query assistant. You have access to tools like get_stock_price, \"\\n        \"get_financial_news, and get_market_analysis to help answer stock-related queries. \"\\n        \"Use these tools as needed to provide accurate and detailed responses.\"\\n    )\\n    system_message = SystemMessage(content=system_content)\\n\\n    # Prepare user message including input query, plan and past steps context\\n    user_content = (\\n        f\"User query: {input_query}\\\\n\"\\n        f\"Plan: {plan}\\\\n\"\\n        f\"Past steps: {past_steps}\\\\n\"\\n        f\"Current response: {response}\\\\n\"\\n        \"Please analyze the query and respond using the tools if necessary.\"\\n    )\\n    user_message = SystemMessage(content=user_content)\\n\\n    # Invoke the model with tools\\n    llm_response = model_with_tools.invoke([system_message, user_message])\\n\\n    # Update the state with the new response\\n    new_response = llm_response.content\\n    updated_state: PlanExecute = {\\n        \"input\": input_query,\\n        \"plan\": plan,\\n        \"past_steps\": past_steps,\\n        \"response\": new_response\\n    }\\n    return updated_state\\n```', edge_code='```python\\n# Since the edge from \\'agent\\' to \\'replan\\' is a non-conditional edge (always go from agent to replan after executing a step),\\n# we use the add_edge method directly as per the NonConditionalEdges section.\\n\\ngraph.add_edge(\"agent\", \"replan\")\\n```')]}}\n",
      "{'graph_compile': {'messages': [AIMessage(content='```python\\nfrom typing import List, Tuple, Annotated, Union, Literal, TypedDict\\nfrom pydantic import BaseModel, Field\\nfrom langchain.chat_models import ChatAnthropic\\nfrom langchain_core.tools import tool\\nfrom langchain_core.messages import SystemMessage\\nfrom langgraph.graph import StateGraph, END\\nfrom langgraph.types import Command\\nfrom langgraph.checkpointer import InMemoryCheckpointer\\n\\n# Define the PlanExecute TypedDict as per schema info\\nclass PlanExecute(TypedDict):\\n    input: str\\n    plan: List[str]\\n    past_steps: Annotated[List[Tuple], \"operator.add\"]\\n    response: str\\n\\n# 1. Planner node implementation: generate a plan using structured output from LLM\\nclass PlanOutput(BaseModel):\\n    plan: List[str] = Field(description=\"A list of step-by-step actions to accomplish the input task\")\\n\\ndef plan_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Plan step generates a plan based on the input using llm structured output functionality, stores it to the plan field\"\"\"\\n    structured_llm = llm.with_structured_output(PlanOutput)\\n    plan_output: PlanOutput = structured_llm.invoke(state[\"input\"])\\n    state[\"plan\"] = plan_output.plan\\n    return state\\n\\n# 2. Agent node implementation: execute a step using LLM with tool binding for stock-related queries\\n\\n@tool\\ndef get_stock_price(ticker: str):\\n    \"\"\"Get the current stock price for a given ticker symbol.\"\"\"\\n    stock_prices = {\\n        \"AAPL\": \"Apple Inc. stock price is $150.\",\\n        \"GOOG\": \"Alphabet Inc. stock price is $2800.\",\\n        \"TSLA\": \"Tesla Inc. stock price is $700.\"\\n    }\\n    return stock_prices.get(ticker.upper(), \"Stock ticker not found.\")\\n\\n@tool\\ndef get_financial_news(company: str):\\n    \"\"\"Retrieve latest financial news for a given company.\"\"\"\\n    return f\"Latest financial news for {company}: Company reports record earnings this quarter.\"\\n\\n@tool\\ndef get_market_analysis():\\n    \"\"\"Provide current market analysis summary.\"\"\"\\n    return \"The market is bullish today with tech stocks leading the gains.\"\\n\\ntools = [get_stock_price, get_financial_news, get_market_analysis]\\n\\nmodel_with_tools = ChatAnthropic(\\n    model=\"claude-3-haiku-20240307\", temperature=0\\n).bind_tools(tools)\\n\\ndef execute_step(state: PlanExecute) -> PlanExecute:\\n    \"\"\"Uses llm with tool binding for the stock related queries\"\"\"\\n    input_query = state[\"input\"]\\n    plan = state[\"plan\"]\\n    past_steps = state[\"past_steps\"]\\n    response = state[\"response\"]\\n\\n    system_content = (\\n        \"You are a stock query assistant. You have access to tools like get_stock_price, \"\\n        \"get_financial_news, and get_market_analysis to help answer stock-related queries. \"\\n        \"Use these tools as needed to provide accurate and detailed responses.\"\\n    )\\n    system_message = SystemMessage(content=system_content)\\n\\n    user_content = (\\n        f\"User query: {input_query}\\\\n\"\\n        f\"Plan: {plan}\\\\n\"\\n        f\"Past steps: {past_steps}\\\\n\"\\n        f\"Current response: {response}\\\\n\"\\n        \"Please analyze the query and respond using the tools if necessary.\"\\n    )\\n    user_message = SystemMessage(content=user_content)\\n\\n    llm_response = model_with_tools.invoke([system_message, user_message])\\n    new_response = llm_response.content\\n\\n    updated_state: PlanExecute = {\\n        \"input\": input_query,\\n        \"plan\": plan,\\n        \"past_steps\": past_steps,\\n        \"response\": new_response\\n    }\\n    return updated_state\\n\\n# 3. Replan node implementation: evaluate progress and either revise plan or generate final response\\n\\nclass Plan(BaseModel):\\n    type: Literal[\"plan\"] = Field(description=\"Indicates this is a plan output\")\\n    steps: List[str] = Field(description=\"Revised list of plan steps\")\\n\\nclass Response(BaseModel):\\n    type: Literal[\"response\"] = Field(description=\"Indicates this is a final response output\")\\n    text: str = Field(description=\"Final response text completing the task\")\\n\\nclass PlanOrResponse(BaseModel):\\n    __root__: Union[Plan, Response]\\n\\ndef replan_step(state: PlanExecute) -> Union[Plan, Response]:\\n    \"\"\"Evaluates progress and uses an LLM to either revise the plan or generate a final response.\"\"\"\\n    structured_llm = llm.with_structured_output(PlanOrResponse)\\n\\n    prompt = f\"\"\"Given the task input: {state[\\'input\\']}\\nCurrent plan: {state[\\'plan\\']}\\nPast steps: {state[\\'past_steps\\']}\\nLatest response: {state[\\'response\\']}\\n\\nEvaluate the progress made so far. Based on your evaluation, either revise and improve the plan to better achieve the input goal or generate a final response that completes the task.\\n\\nIf revising the plan, provide the updated plan as a list of steps.\\nIf the task is complete, provide the final response text.\\n\"\"\"\\n\\n    output = structured_llm.invoke(prompt)\\n    return output.__root__\\n\\n# 4. Build the graph and add nodes and edges\\n\\ngraph = StateGraph(PlanExecute)\\n\\n# Add nodes\\ngraph.add_node(\"planner\", plan_step)\\ngraph.add_node(\"agent\", execute_step)\\ngraph.add_node(\"replan\", replan_step)\\n\\n# Add edges (non-conditional)\\ngraph.add_edge(\"__START__\", \"planner\")\\ngraph.add_edge(\"planner\", \"agent\")\\ngraph.add_edge(\"agent\", \"replan\")\\n\\n# Add conditional edges from replan node\\ndef replan_routing_function(state: PlanExecute) -> Union[Literal[\"agent\"], Literal[END]]:\\n    # If a response is generated (non-empty string), end the process\\n    if state[\"response\"]:\\n        return END\\n    else:\\n        return \"agent\"\\n\\ngraph.add_conditional_edges(\"replan\", replan_routing_function, {END: END, \"agent\": \"agent\"})\\n\\n# 5. Assign a global LLM instance for use in nodes\\nllm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\\n\\n# 6. Compile the graph with InMemoryCheckpointer\\nfinal_app = graph.compile(checkpointer=InMemoryCheckpointer())\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1307, 'prompt_tokens': 2379, 'total_tokens': 3686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'id': 'chatcmpl-BSoU2cuFvCKadIxh2kOzQ86BQMaT0', 'finish_reason': 'stop', 'logprobs': None}, id='run-06895aed-6fbe-4503-b936-8ff4b0a8b1db-0', usage_metadata={'input_tokens': 2379, 'output_tokens': 1307, 'total_tokens': 3686, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import json\n",
    "uuid_str1= uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid_str1)}}\n",
    "\n",
    "for output in compiler_graph.stream({\"json_code\": result_str}, config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        print(output) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
