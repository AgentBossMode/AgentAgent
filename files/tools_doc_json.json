{"ads4gpts": "Integrate AI native advertising into your Agentic application.", "agentql": "[AgentQL](https://www.agentql.com/) tools provides web interaction and\nstructured data extraction from any web page using an [AgentQL\nquery](https://docs.agentql.com/agentql-query) or a Natural Language prompt.\nAgentQL can be used across multiple languages and web pages without breaking\nover time and change.", "ainetwork": "> [AI Network](https://www.ainetwork.ai/build-on-ain) is a layer 1 blockchain\n> designed to accommodate large-scale AI models, utilizing a decentralized GPU\n> network powered by the [$AIN token](https://www.ainetwork.ai/token),\n> enriching AI-driven `NFTs` (`AINFTs`).\n>\n> The `AINetwork Toolkit` is a set of tools for interacting with the\n> [AINetwork Blockchain](https://www.ainetwork.ai/public/whitepaper.pdf).\n> These tools allow you to transfer `AIN`, read and write values, create apps,\n> and set permissions for specific paths within the blockchain database.", "alpha_vantage": "> [Alpha Vantage](https://www.alphavantage.co) Alpha Vantage provides realtime\n> and historical financial market data through a set of powerful and\n> developer-friendly data APIs and spreadsheets.\n\nUse the `AlphaVantageAPIWrapper` to get currency exchange rates.\n\n    \n    \n    import getpass  \n    import os  \n      \n    os.environ[\"ALPHAVANTAGE_API_KEY\"] = getpass.getpass()  \n    \n    \n    \n    from langchain_community.utilities.alpha_vantage import AlphaVantageAPIWrapper  \n    \n\n**API\nReference:**[AlphaVantageAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.alpha_vantage.AlphaVantageAPIWrapper.html)\n\n    \n    \n    alpha_vantage = AlphaVantageAPIWrapper()  \n    alpha_vantage._get_exchange_rate(\"USD\", \"JPY\")  \n    \n    \n    \n    {'Realtime Currency Exchange Rate': {'1. From_Currency Code': 'USD',  \n      '2. From_Currency Name': 'United States Dollar',  \n      '3. To_Currency Code': 'JPY',  \n      '4. To_Currency Name': 'Japanese Yen',  \n      '5. Exchange Rate': '148.19900000',  \n      '6. Last Refreshed': '2023-11-30 21:43:02',  \n      '7. Time Zone': 'UTC',  \n      '8. Bid Price': '148.19590000',  \n      '9. Ask Price': '148.20420000'}}  \n    \n\nThe `_get_time_series_daily` method returns the date, daily open, daily high,\ndaily low, daily close, and daily volume of the global equity specified,\ncovering the 100 latest data points.\n\n    \n    \n    alpha_vantage._get_time_series_daily(\"IBM\")  \n    \n\nThe `_get_time_series_weekly` method returns the last trading day of the week,\nweekly open, weekly high, weekly low, weekly close, and weekly volume of the\nglobal equity specified, covering 20+ years of historical data.\n\n    \n    \n    alpha_vantage._get_time_series_weekly(\"IBM\")  \n    \n\nThe `_get_quote_endpoint` method is a lightweight alternative to the time\nseries APIs and returns the latest price and volume info for the specified\nsymbol.\n\n    \n    \n    alpha_vantage._get_quote_endpoint(\"IBM\")  \n    \n    \n    \n    {'Global Quote': {'01. symbol': 'IBM',  \n      '02. open': '156.9000',  \n      '03. high': '158.6000',  \n      '04. low': '156.8900',  \n      '05. price': '158.5400',  \n      '06. volume': '6640217',  \n      '07. latest trading day': '2023-11-30',  \n      '08. previous close': '156.4100',  \n      '09. change': '2.1300',  \n      '10. change percent': '1.3618%'}}  \n    \n\nThe `search_symbol` method returns a list of symbols and the matching company\ninformation based on the text entered.\n\n    \n    \n    alpha_vantage.search_symbols(\"IB\")  \n    \n\nThe `_get_market_news_sentiment` method returns live and historical market\nnews sentiment for a given asset.\n\n    \n    \n    alpha_vantage._get_market_news_sentiment(\"IBM\")  \n    \n\nThe `_get_top_gainers_losers` method returns the top 20 gainers, losers and\nmost active stocks in the US market.\n\n    \n    \n    alpha_vantage._get_top_gainers_losers()  \n    \n\nThe `run` method of the wrapper takes the following parameters: from_currency,\nto_currency.\n\nIt Gets the currency exchange rates for the given currency pair.\n\n    \n    \n    alpha_vantage.run(\"USD\", \"JPY\")  \n    \n    \n    \n    {'1. From_Currency Code': 'USD',  \n     '2. From_Currency Name': 'United States Dollar',  \n     '3. To_Currency Code': 'JPY',  \n     '4. To_Currency Name': 'Japanese Yen',  \n     '5. Exchange Rate': '148.19900000',  \n     '6. Last Refreshed': '2023-11-30 21:43:02',  \n     '7. Time Zone': 'UTC',  \n     '8. Bid Price': '148.19590000',  \n     '9. Ask Price': '148.20420000'}", "amadeus": "This notebook walks you through connecting LangChain to the `Amadeus` travel\nAPIs.\n\nThis `Amadeus` toolkit allows agents to make decision when it comes to travel,\nespecially searching and booking trips with flights.\n\nTo use this toolkit, you will need to have your Amadeus API keys ready,\nexplained in the [Get started Amadeus Self-Service\nAPIs](https://developers.amadeus.com/get-started/get-started-with-self-\nservice-apis-335). Once you've received a AMADEUS_CLIENT_ID and\nAMADEUS_CLIENT_SECRET, you can input them as environmental variables below.\n\nNote: Amadeus Self-Service APIs offers a test environment with [free limited\ndata](https://amadeus4dev.github.io/developer-guides/test-data/). This allows\ndevelopers to build and test their applications before deploying them to\nproduction. To access real-time data, you will need to [move to the production\nenvironment](https://amadeus4dev.github.io/developer-guides/API-Keys/moving-\nto-production/).\n\n    \n    \n    %pip install --upgrade --quiet  amadeus > /dev/null  \n    \n    \n    \n    %pip install -qU langchain-community", "apify_actors": "> [Apify Actors](https://docs.apify.com/platform/actors) are cloud programs\n> designed for a wide range of web scraping, crawling, and data extraction\n> tasks. These actors facilitate automated data gathering from the web,\n> enabling users to extract, process, and store information efficiently.\n> Actors can be used to perform tasks like scraping e-commerce sites for\n> product details, monitoring price changes, or gathering search engine\n> results. They integrate seamlessly with [Apify\n> Datasets](https://docs.apify.com/platform/storage/dataset), allowing the\n> structured data collected by actors to be stored, managed, and exported in\n> formats like JSON, CSV, or Excel for further analysis or use.", "arxiv": "This notebook goes over how to use the `arxiv` tool with an agent.\n\nFirst, you need to install the `arxiv` python package.\n\n    \n    \n    %pip install --upgrade --quiet  langchain-community arxiv  \n    \n    \n    \n    from langchain import hub  \n    from langchain.agents import AgentExecutor, create_react_agent, load_tools  \n    from langchain_openai import ChatOpenAI  \n      \n    llm = ChatOpenAI(temperature=0.0)  \n    tools = load_tools(  \n        [\"arxiv\"],  \n    )  \n    prompt = hub.pull(\"hwchase17/react\")  \n      \n    agent = create_react_agent(llm, tools, prompt)  \n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  \n    \n\n**API Reference:**[hub](https://python.langchain.com/api_reference/langchain/hub/langchain.hub.hub.html) | [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html) | [create_react_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.react.agent.create_react_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n    \n    \n    agent_executor.invoke(  \n        {  \n            \"input\": \"What's the paper 1605.08386 about?\",  \n        }  \n    )  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3mI should use the arxiv tool to search for the paper with the given identifier.  \n    Action: arxiv  \n    Action Input: 1605.08386\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2016-05-26  \n    Title: Heat-bath random walks with Markov bases  \n    Authors: Caprice Stanley, Tobias Windisch  \n    Summary: Graphs on lattice points are studied whose edges come from a finite set of  \n    allowed moves of arbitrary length. We show that the diameter of these graphs on  \n    fibers of a fixed integer matrix can be bounded from above by a constant. We  \n    then study the mixing behaviour of heat-bath random walks on these graphs. We  \n    also state explicit conditions on the set of moves so that the heat-bath random  \n    walk, a generalization of the Glauber dynamics, is an expander in fixed  \n    dimension.\u001b[0m\u001b[32;1m\u001b[1;3mThe paper \"1605.08386\" is titled \"Heat-bath random walks with Markov bases\" and is authored by Caprice Stanley and Tobias Windisch. It was published on May 26, 2016. The paper discusses the study of graphs on lattice points with edges coming from a finite set of allowed moves. It explores the diameter of these graphs and the mixing behavior of heat-bath random walks on them. The paper also discusses conditions for the heat-bath random walk to be an expander in fixed dimension.  \n    Final Answer: The paper \"1605.08386\" is about heat-bath random walks with Markov bases.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    {'input': \"What's the paper 1605.08386 about?\",  \n     'output': 'The paper \"1605.08386\" is about heat-bath random walks with Markov bases.'}", "asknews": "> [AskNews](https://asknews.app) infuses any LLM with the latest global news\n> (or historical news), using a single natural language query. Specifically,\n> AskNews is enriching over 300k articles per day by translating, summarizing,\n> extracting entities, and indexing them into hot and cold vector databases.\n> AskNews puts these vector databases on a low-latency endpoint for you. When\n> you query AskNews, you get back a prompt-optimized string that contains all\n> the most pertinent enrichments (e.g. entities, classifications, translation,\n> summarization). This means that you do not need to manage your own news RAG,\n> and you do not need to worry about how to properly convey news information\n> in a condensed way to your LLM. AskNews is also committed to transparency,\n> which is why our coverage is monitored and diversified across hundreds of\n> countries, 13 languages, and 50 thousand sources. If you'd like to track our\n> source coverage, you can visit our [transparency\n> dashboard](https://asknews.app/en/transparency).", "awslambda": "> [`Amazon AWS Lambda`](https://aws.amazon.com/pm/lambda/) is a serverless\n> computing service provided by `Amazon Web Services` (`AWS`). It helps\n> developers to build and run applications and services without provisioning\n> or managing servers. This serverless architecture enables you to focus on\n> writing and deploying code, while AWS automatically takes care of scaling,\n> patching, and managing the infrastructure required to run your applications.\n\nThis notebook goes over how to use the `AWS Lambda` Tool.\n\nBy including the `AWS Lambda` in the list of tools provided to an Agent, you\ncan grant your Agent the ability to invoke code running in your AWS Cloud for\nwhatever purposes you need.\n\nWhen an Agent uses the `AWS Lambda` tool, it will provide an argument of type\nstring which will in turn be passed into the Lambda function via the event\nparameter.\n\nFirst, you need to install `boto3` python package.\n\n    \n    \n    %pip install --upgrade --quiet  boto3 > /dev/null  \n    %pip install --upgrade --quiet langchain-community  \n    \n\nIn order for an agent to use the tool, you must provide it with the name and\ndescription that match the functionality of you lambda function's logic.\n\nYou must also provide the name of your function.\n\nNote that because this tool is effectively just a wrapper around the boto3\nlibrary, you will need to run `aws configure` in order to make use of the\ntool. For more detail, see [here](https://docs.aws.amazon.com/cli/index.html)\n\n    \n    \n    from langchain.agents import AgentType, initialize_agent, load_tools  \n    from langchain_openai import OpenAI  \n      \n    llm = OpenAI(temperature=0)  \n      \n    tools = load_tools(  \n        [\"awslambda\"],  \n        awslambda_tool_name=\"email-sender\",  \n        awslambda_tool_description=\"sends an email with the specified content to test@testing123.com\",  \n        function_name=\"testFunction1\",  \n    )  \n      \n    agent = initialize_agent(  \n        tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True  \n    )  \n      \n    agent.run(\"Send an email to test@testing123.com saying hello world.\")  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)", "azure_ai_services": "This toolkit is used to interact with the `Azure AI Services API` to achieve\nsome multimodal capabilities.\n\nCurrently There are five tools bundled in this toolkit:\n\n  * **AzureAiServicesImageAnalysisTool** : used to extract caption, objects, tags, and text from images.\n  * **AzureAiServicesDocumentIntelligenceTool** : used to extract text, tables, and key-value pairs from documents.\n  * **AzureAiServicesSpeechToTextTool** : used to transcribe speech to text.\n  * **AzureAiServicesTextToSpeechTool** : used to synthesize text to speech.\n  * **AzureAiServicesTextAnalyticsForHealthTool** : used to extract healthcare entities.\n\nFirst, you need to set up an Azure account and create an AI Services resource.\nYou can follow the instructions [here](https://learn.microsoft.com/en-\nus/azure/ai-services/multi-service-resource) to create a resource.\n\nThen, you need to get the endpoint, key and region of your resource, and set\nthem as environment variables. You can find them in the \"Keys and Endpoint\"\npage of your resource.\n\n    \n    \n    %pip install --upgrade --quiet  azure-ai-formrecognizer > /dev/null  \n    %pip install --upgrade --quiet  azure-cognitiveservices-speech > /dev/null  \n    %pip install --upgrade --quiet  azure-ai-textanalytics > /dev/null  \n    %pip install --upgrade --quiet  azure-ai-vision-imageanalysis > /dev/null  \n    %pip install -qU langchain-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"OPENAI_API_KEY\"] = \"sk-\"  \n    os.environ[\"AZURE_AI_SERVICES_KEY\"] = \"\"  \n    os.environ[\"AZURE_AI_SERVICES_ENDPOINT\"] = \"\"  \n    os.environ[\"AZURE_AI_SERVICES_REGION\"] = \"\"", "azure_cognitive_services": "This toolkit is used to interact with the `Azure Cognitive Services API` to\nachieve some multimodal capabilities.\n\nCurrently There are four tools bundled in this toolkit:\n\n  * AzureCogsImageAnalysisTool: used to extract caption, objects, tags, and text from images. (Note: this tool is not available on Mac OS yet, due to the dependency on `azure-ai-vision` package, which is only supported on Windows and Linux currently.)\n  * AzureCogsFormRecognizerTool: used to extract text, tables, and key-value pairs from documents.\n  * AzureCogsSpeech2TextTool: used to transcribe speech to text.\n  * AzureCogsText2SpeechTool: used to synthesize text to speech.\n  * AzureCogsTextAnalyticsHealthTool: used to extract healthcare entities.\n\nFirst, you need to set up an Azure account and create a Cognitive Services\nresource. You can follow the instructions\n[here](https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-\nservices-apis-create-account?tabs=multiservice%2Cwindows) to create a\nresource.\n\nThen, you need to get the endpoint, key and region of your resource, and set\nthem as environment variables. You can find them in the \"Keys and Endpoint\"\npage of your resource.\n\n    \n    \n    %pip install --upgrade --quiet  azure-ai-formrecognizer > /dev/null  \n    %pip install --upgrade --quiet  azure-cognitiveservices-speech > /dev/null  \n    %pip install --upgrade --quiet  azure-ai-textanalytics > /dev/null  \n      \n    # For Windows/Linux  \n    %pip install --upgrade --quiet  azure-ai-vision > /dev/null  \n    \n    \n    \n    %pip install -qU langchain-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"OPENAI_API_KEY\"] = \"sk-\"  \n    os.environ[\"AZURE_COGS_KEY\"] = \"\"  \n    os.environ[\"AZURE_COGS_ENDPOINT\"] = \"\"  \n    os.environ[\"AZURE_COGS_REGION\"] = \"\"", "azure_dynamic_sessions": "Azure Container Apps dynamic sessions provides a secure and scalable way to\nrun a Python code interpreter in Hyper-V isolated sandboxes. This allows your\nagents to run potentially untrusted code in a secure environment. The code\ninterpreter environment includes many popular Python packages, such as NumPy,\npandas, and scikit-learn. See the [Azure Container App\ndocs](https://learn.microsoft.com/en-us/azure/container-apps/sessions-code-\ninterpreter) for more info on how sessions work.", "bash": "Giving agents access to the shell is powerful (though risky outside a\nsandboxed environment).\n\nThe LLM can use it to execute any shell commands. A common use case for this\nis letting the LLM interact with your local file system.\n\n**Note:** Shell tool does not work with Windows OS.\n\n    \n    \n    %pip install --upgrade --quiet langchain-community  \n    \n    \n    \n    from langchain_community.tools import ShellTool  \n      \n    shell_tool = ShellTool()  \n    \n\n**API\nReference:**[ShellTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.shell.tool.ShellTool.html)\n\n    \n    \n    print(shell_tool.run({\"commands\": [\"echo 'Hello World!'\", \"time\"]}))  \n    \n    \n    \n    Hello World!  \n      \n    real\t0m0.000s  \n    user\t0m0.000s  \n    sys\t0m0.000s  \n    ``````output  \n    /Users/wfh/code/lc/lckg/langchain/tools/shell/tool.py:34: UserWarning: The shell tool has no safeguards by default. Use at your own risk.  \n      warnings.warn(", "bearly": "> Bearly Code Interpreter allows for remote execution of code. This makes it\n> perfect for a code sandbox for agents, to allow for safe implementation of\n> things like Code Interpreter\n\nGet your api key here: <https://bearly.ai/dashboard/developers>\n\n    \n    \n    %pip install --upgrade --quiet langchain-community  \n    \n\nIn this notebook, we will create an example of an agent that uses Bearly to\ninteract with data\n\n    \n    \n    from langchain_community.tools import BearlyInterpreterTool  \n    \n\n**API\nReference:**[BearlyInterpreterTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.bearly.tool.BearlyInterpreterTool.html)\n\n    \n    \n    from langchain.agents import AgentType, initialize_agent  \n    from langchain_openai import ChatOpenAI  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n\nInitialize the interpreter\n\n    \n    \n    bearly_tool = BearlyInterpreterTool(api_key=\"...\")  \n    \n\nLet's add some files to the sandbox\n\n    \n    \n    bearly_tool.add_file(  \n        source_path=\"sample_data/Bristol.pdf\", target_path=\"Bristol.pdf\", description=\"\"  \n    )  \n    bearly_tool.add_file(  \n        source_path=\"sample_data/US_GDP.csv\", target_path=\"US_GDP.csv\", description=\"\"  \n    )  \n    \n\nCreate a `Tool` object now. This is necessary, because we added the files, and\nwe want the tool description to reflect that\n\n    \n    \n    tools = [bearly_tool.as_tool()]  \n    \n    \n    \n    tools[0].name  \n    \n    \n    \n    'bearly_interpreter'  \n    \n    \n    \n    print(tools[0].description)  \n    \n    \n    \n    Evaluates python code in a sandbox environment. The environment resets on every execution. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. If you have any files outputted write them to \"output/\" relative to the execution   \n    path. Output can only be read from the directory, stdout, and stdin. Do not use things like plot.show() as it will   \n    not work instead write them out `output/` and a link to the file will be returned. print() any output and results so you can capture the output.  \n      \n    The following files available in the evaluation environment:  \n    - path: `Bristol.pdf`   \n     first four lines: []   \n     description: ``  \n    - path: `US_GDP.csv`   \n     first four lines: ['DATE,GDP\\n', '1947-01-01,243.164\\n', '1947-04-01,245.968\\n', '1947-07-01,249.585\\n']   \n     description: ``  \n    \n\nInitialize an agent\n\n    \n    \n    llm = ChatOpenAI(model=\"gpt-4\", temperature=0)  \n    agent = initialize_agent(  \n        tools,  \n        llm,  \n        agent=AgentType.OPENAI_FUNCTIONS,  \n        verbose=True,  \n        handle_parsing_errors=True,  \n    )  \n    \n    \n    \n    # Extract pdf content  \n    agent.run(\"What is the text on page 3 of the pdf?\")  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m  \n    Invoking: `bearly_interpreter` with `{'python_code': \"import PyPDF2\\n\\n# Open the PDF file in read-binary mode\\npdf_file = open('Bristol.pdf', 'rb')\\n\\n# Create a PDF file reader object\\npdf_reader = PyPDF2.PdfFileReader(pdf_file)\\n\\n# Get the text from page 3\\npage_obj = pdf_reader.getPage(2)\\npage_text = page_obj.extractText()\\n\\n# Close the PDF file\\npdf_file.close()\\n\\nprint(page_text)\"}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3m{'stdout': '', 'stderr': 'Traceback (most recent call last):\\n  File \"/tmp/project/main.py\", line 7, in <module>\\n    pdf_reader = PyPDF2.PdfFileReader(pdf_file)\\n  File \"/venv/lib/python3.10/site-packages/PyPDF2/_reader.py\", line 1974, in __init__\\n    deprecation_with_replacement(\"PdfFileReader\", \"PdfReader\", \"3.0.0\")\\n  File \"/venv/lib/python3.10/site-packages/PyPDF2/_utils.py\", line 369, in deprecation_with_replacement\\n    deprecation(DEPR_MSG_HAPPENED.format(old_name, removed_in, new_name))\\n  File \"/venv/lib/python3.10/site-packages/PyPDF2/_utils.py\", line 351, in deprecation\\n    raise DeprecationError(msg)\\nPyPDF2.errors.DeprecationError: PdfFileReader is deprecated and was removed in PyPDF2 3.0.0. Use PdfReader instead.\\n', 'fileLinks': [], 'exitCode': 1}\u001b[0m\u001b[32;1m\u001b[1;3m  \n    Invoking: `bearly_interpreter` with `{'python_code': \"from PyPDF2 import PdfReader\\n\\n# Open the PDF file\\npdf = PdfReader('Bristol.pdf')\\n\\n# Get the text from page 3\\npage = pdf.pages[2]\\npage_text = page.extract_text()\\n\\nprint(page_text)\"}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3m{'stdout': '1 COVID-19 at Work: \\nExposing h ow risk is assessed and its consequences in England and Sweden \\nPeter Andersson and Tonia Novitz* \\n1.Introduction\\nT\\nhe crisis which arose suddenly at the beginning of 2020 relating to coronavirus was immediately \\ncentred on risk. Predictions ha d to be made swiftly regarding how it would spread, who it might \\naffect and what measures could be taken to prevent exposure in everyday so cial interaction, \\nincluding in the workplace. This was in no way a straightforward assessment, because initially so \\nmuch was unknown. Those gaps in our knowledge have since, partially, been ameliorated. It is \\nevident that not all those exposed to COVID-19 become ill, and many who contract the virus remain \\nasymptomatic, so that the odds on becoming seriously ill may seem small. But those odds are also stacked against certain segments of the population. The likelihood of mortality and morbidity are associated  with age and ethnicity as well as pre -existing medical conditions (such as diabetes), but \\nalso with poverty which correlates to the extent of exposure in certain occupations.\\n1 Some risks \\narise which remain  less predictable, as previously healthy people with no signs of particular \\nvulnerability can experience serious long term illness as well and in rare cases will even die.2 \\nPerceptions of risk in different countries have led to particular measures taken, ranging from handwashing to social distancing, use of personal protective equipment (PPE) such as face coverings, and even \u2018lockdowns\u2019 which have taken various forms.\\n3 Use of testing and vaccines \\nalso bec ame part of the remedial landscape, with their availability and administration  being \\n*This paper is part of the project An  i nclusive and sustainable Swedish labour law \u2013 the way\\nahead, dnr. 2017-03134 financed by the Swedish research council led by Petra Herzfeld Olssonat Stockholm University. The authors would like to thank her and other participants, Niklas\\nBruun and Erik Sj\u00f6din for their helpful comments on earlier drafts. A much shorter article titled\\n\u2018Risk Assessment and COVID -19: Systems at work (or not) in England and Sweden\u2019 is published\\nin the (2021) Comparative Labour and Social Security Review /\\n Revue de droit compar\u00e9 du\\ntravail et de la s\u00e9curit\u00e9 sociale.\\n1 Public Health England, Disparities in the risk and outcomes of COVID-19 (2 June 2020 -\\nhttps://assets.publishing.service.gov.uk/government/uploads/ system /uploads/attachment_data/file\\n/890258/disparities_review.pdf.\\n2 Nisreen A. Alwan, \u2018Track COVID- 19 sickness, not just positive tests and deaths\u2019 ( 2020)\\n584.7820 Nature  170- 171; Elisabeth Mahase, \u2018Covid-19: What do we know about \u201clong covid\u201d?\u2019\\n(2020) BMJ  370.\\n3 Sarah Dryhurst, Claudia R. Schneider, John Kerr, Alexandra LJ Freeman, Gabriel Recchia,\\nAnne Marthe Van Der Bles, David Spiegelhalter, and Sander van der Linden, \u2018Risk perceptionsof COVID-19 around the world\u2019 (2020) 23(7- 8) Journal of Risk Research  994; W\u00e4ndi Bruine de\\nBruin, and Daniel Bennett, \u2018Relationships between initial COVID -19 risk perceptions and\\nprotective health behaviors: A national survey\u2019 (2020) 59(2) American Journal of Prev entive\\nMedicine  157; and Simon Deakin and Gaofeng Meng, \u2018The Governance of Covid- 19:\\nAnthropogenic Risk, Evolutionary Learning, and the Future of the Social State\u2019 (2020)49(4) Industrial Law Journal  539.\\n', 'stderr': '', 'fileLinks': [], 'exitCode': 0}\u001b[0m\u001b[32;1m\u001b[1;3mThe text on page 3 of the PDF is:  \n      \n    \"1 COVID-19 at Work:   \n    Exposing how risk is assessed and its consequences in England and Sweden   \n    Peter Andersson and Tonia Novitz*   \n    1.Introduction  \n    The crisis which arose suddenly at the beginning of 2020 relating to coronavirus was immediately   \n    centred on risk. Predictions had to be made swiftly regarding how it would spread, who it might   \n    affect and what measures could be taken to prevent exposure in everyday social interaction,   \n    including in the workplace. This was in no way a straightforward assessment, because initially so   \n    much was unknown. Those gaps in our knowledge have since, partially, been ameliorated. It is   \n    evident that not all those exposed to COVID-19 become ill, and many who contract the virus remain   \n    asymptomatic, so that the odds on becoming seriously ill may seem small. But those odds are also stacked against certain segments of the population. The likelihood of mortality and morbidity are associated  with age and ethnicity as well as pre-existing medical conditions (such as diabetes), but   \n    also with poverty which correlates to the extent of exposure in certain occupations.  \n    1 Some risks   \n    arise which remain  less predictable, as previously healthy people with no signs of particular   \n    vulnerability can experience serious long term illness as well and in rare cases will even die.2   \n    Perceptions of risk in different countries have led to particular measures taken, ranging from handwashing to social distancing, use of personal protective equipment (PPE) such as face coverings, and even \u2018lockdowns\u2019 which have taken various forms.  \n    3 Use of testing and vaccines   \n    also became part of the remedial landscape, with their availability and administration  being   \n    *This paper is part of the project An  inclusive and sustainable Swedish labour law \u2013 the way  \n    ahead, dnr. 2017-03134 financed by the Swedish research council led by Petra Herzfeld Olssonat Stockholm University. The authors would like to thank her and other participants, Niklas  \n    Bruun and Erik Sj\u00f6din for their helpful comments on earlier drafts. A much shorter article titled  \n    \u2018Risk Assessment and COVID -19: Systems at work (or not) in England and Sweden\u2019 is published  \n    in the (2021) Comparative Labour and Social Security Review /  \n     Revue de droit compar\u00e9 du  \n    travail et de la s\u00e9curit\u00e9 sociale.  \n    1 Public Health England, Disparities in the risk and outcomes of COVID-19 (2 June 2020 -  \n    https://assets.publishing.service.gov.uk/government/uploads/ system /uploads/attachment_data/file  \n    /890258/disparities_review.pdf.  \n    2 Nisreen A. Alwan, \u2018Track COVID- 19 sickness, not just positive tests and deaths\u2019 ( 2020)  \n    584.7820 Nature  170- 171; Elisabeth Mahase, \u2018Covid-19: What do we know about \u201clong covid\u201d?\u2019  \n    (2020) BMJ  370.  \n    3 Sarah Dryhurst, Claudia R. Schneider, John Kerr, Alexandra LJ Freeman, Gabriel Recchia,  \n    Anne Marthe Van Der Bles, David Spiegelhalter, and Sander van der Linden, \u2018Risk perceptionsof COVID-19 around the world\u2019 (2020) 23(7- 8) Journal of Risk Research  994; W\u00e4ndi Bruine de  \n    Bruin, and Daniel Bennett, \u2018Relationships between initial COVID -19 risk perceptions and  \n    protective health behaviors: A national survey\u2019 (2020) 59(2) American Journal of Preventive  \n    Medicine  157; and Simon Deakin and Gaofeng Meng, \u2018The Governance of Covid- 19:  \n    Anthropogenic Risk, Evolutionary Learning, and the Future of the Social State\u2019 (2020)49(4) Industrial Law Journal  539.\"\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    'The text on page 3 of the PDF is:\\n\\n\"1 COVID-19 at Work: \\nExposing how risk is assessed and its consequences in England and Sweden \\nPeter Andersson and Tonia Novitz* \\n1.Introduction\\nThe crisis which arose suddenly at the beginning of 2020 relating to coronavirus was immediately \\ncentred on risk. Predictions had to be made swiftly regarding how it would spread, who it might \\naffect and what measures could be taken to prevent exposure in everyday social interaction, \\nincluding in the workplace. This was in no way a straightforward assessment, because initially so \\nmuch was unknown. Those gaps in our knowledge have since, partially, been ameliorated. It is \\nevident that not all those exposed to COVID-19 become ill, and many who contract the virus remain \\nasymptomatic, so that the odds on becoming seriously ill may seem small. But those odds are also stacked against certain segments of the population. The likelihood of mortality and morbidity are associated  with age and ethnicity as well as pre-existing medical conditions (such as diabetes), but \\nalso with poverty which correlates to the extent of exposure in certain occupations.\\n1 Some risks \\narise which remain  less predictable, as previously healthy people with no signs of particular \\nvulnerability can experience serious long term illness as well and in rare cases will even die.2 \\nPerceptions of risk in different countries have led to particular measures taken, ranging from handwashing to social distancing, use of personal protective equipment (PPE) such as face coverings, and even \u2018lockdowns\u2019 which have taken various forms.\\n3 Use of testing and vaccines \\nalso became part of the remedial landscape, with their availability and administration  being \\n*This paper is part of the project An  inclusive and sustainable Swedish labour law \u2013 the way\\nahead, dnr. 2017-03134 financed by the Swedish research council led by Petra Herzfeld Olssonat Stockholm University. The authors would like to thank her and other participants, Niklas\\nBruun and Erik Sj\u00f6din for their helpful comments on earlier drafts. A much shorter article titled\\n\u2018Risk Assessment and COVID -19: Systems at work (or not) in England and Sweden\u2019 is published\\nin the (2021) Comparative Labour and Social Security Review /\\n Revue de droit compar\u00e9 du\\ntravail et de la s\u00e9curit\u00e9 sociale.\\n1 Public Health England, Disparities in the risk and outcomes of COVID-19 (2 June 2020 -\\nhttps://assets.publishing.service.gov.uk/government/uploads/ system /uploads/attachment_data/file\\n/890258/disparities_review.pdf.\\n2 Nisreen A. Alwan, \u2018Track COVID- 19 sickness, not just positive tests and deaths\u2019 ( 2020)\\n584.7820 Nature  170- 171; Elisabeth Mahase, \u2018Covid-19: What do we know about \u201clong covid\u201d?\u2019\\n(2020) BMJ  370.\\n3 Sarah Dryhurst, Claudia R. Schneider, John Kerr, Alexandra LJ Freeman, Gabriel Recchia,\\nAnne Marthe Van Der Bles, David Spiegelhalter, and Sander van der Linden, \u2018Risk perceptionsof COVID-19 around the world\u2019 (2020) 23(7- 8) Journal of Risk Research  994; W\u00e4ndi Bruine de\\nBruin, and Daniel Bennett, \u2018Relationships between initial COVID -19 risk perceptions and\\nprotective health behaviors: A national survey\u2019 (2020) 59(2) American Journal of Preventive\\nMedicine  157; and Simon Deakin and Gaofeng Meng, \u2018The Governance of Covid- 19:\\nAnthropogenic Risk, Evolutionary Learning, and the Future of the Social State\u2019 (2020)49(4) Industrial Law Journal  539.\"'  \n    \n    \n    \n    # Simple Queries  \n    agent.run(\"What was the US GDP in 2019?\")  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m  \n    Invoking: `bearly_interpreter` with `{'python_code': \"import pandas as pd\\n\\n# Load the data\\nus_gdp = pd.read_csv('US_GDP.csv')\\n\\n# Convert the 'DATE' column to datetime\\nus_gdp['DATE'] = pd.to_datetime(us_gdp['DATE'])\\n\\n# Filter the data for the year 2019\\nus_gdp_2019 = us_gdp[us_gdp['DATE'].dt.year == 2019]\\n\\n# Print the GDP for 2019\\nprint(us_gdp_2019['GDP'].values)\"}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3m{'stdout': '[21104.133 21384.775 21694.282 21902.39 ]\\n', 'stderr': '', 'fileLinks': [], 'exitCode': 0}\u001b[0m\u001b[32;1m\u001b[1;3mThe US GDP for each quarter in 2019 was as follows:  \n      \n    - Q1: 21104.133 billion dollars  \n    - Q2: 21384.775 billion dollars  \n    - Q3: 21694.282 billion dollars  \n    - Q4: 21902.39 billion dollars\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    'The US GDP for each quarter in 2019 was as follows:\\n\\n- Q1: 21104.133 billion dollars\\n- Q2: 21384.775 billion dollars\\n- Q3: 21694.282 billion dollars\\n- Q4: 21902.39 billion dollars'  \n    \n    \n    \n    # Calculations  \n    agent.run(\"What would the GDP be in 2030 if the latest GDP number grew by 50%?\")  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m  \n    Invoking: `bearly_interpreter` with `{'python_code': \"import pandas as pd\\n\\n# Load the data\\nus_gdp = pd.read_csv('US_GDP.csv')\\n\\n# Get the latest GDP\\nlatest_gdp = us_gdp['GDP'].iloc[-1]\\n\\n# Calculate the GDP in 2030 if the latest GDP number grew by 50%\\ngdp_2030 = latest_gdp * 1.5\\nprint(gdp_2030)\"}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3m{'stdout': '40594.518\\n', 'stderr': '', 'fileLinks': [], 'exitCode': 0}\u001b[0m\u001b[32;1m\u001b[1;3mIf the latest GDP number grew by 50%, the GDP in 2030 would be approximately 40,594.518 billion dollars.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    'If the latest GDP number grew by 50%, the GDP in 2030 would be approximately 40,594.518 billion dollars.'  \n    \n    \n    \n    # Chart output  \n    agent.run(\"Create a nice and labeled chart of the GDP growth over time\")  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3mCould not parse tool input: {'name': 'bearly_interpreter', 'arguments': '{\\n  \"python_code\": \"\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the data\\ndf = pd.read_csv(\\'US_GDP.csv\\')\\n\\n# Convert the \\'DATE\\' column to datetime format\\ndf[\\'DATE\\'] = pd.to_datetime(df[\\'DATE\\'])\\n\\n# Plot the data\\nplt.figure(figsize=(10,6))\\nplt.plot(df[\\'DATE\\'], df[\\'GDP\\'], label=\\'US GDP\\')\\nplt.xlabel(\\'Year\\')\\nplt.ylabel(\\'GDP (in billions)\\')\\nplt.title(\\'US GDP Over Time\\')\\nplt.legend()\\nplt.grid(True)\\nplt.savefig(\\'output/US_GDP.png\\')\\n\"\\n}'} because the `arguments` is not valid JSON.\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m  \n    Invoking: `bearly_interpreter` with `{'python_code': \"\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the data\\ndf = pd.read_csv('US_GDP.csv')\\n\\n# Convert the 'DATE' column to datetime format\\ndf['DATE'] = pd.to_datetime(df['DATE'])\\n\\n# Plot the data\\nplt.figure(figsize=(10,6))\\nplt.plot(df['DATE'], df['GDP'], label='US GDP')\\nplt.xlabel('Year')\\nplt.ylabel('GDP (in billions)')\\nplt.title('US GDP Over Time')\\nplt.legend()\\nplt.grid(True)\\nplt.savefig('output/US_GDP.png')\\n\"}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3m{'stdout': '', 'stderr': '', 'fileLinks': [{'pathname': 'US_GDP.png', 'tempLink': 'https://bearly-cubby.c559ae877a0a39985f534614a037d899.r2.cloudflarestorage.com/prod/bearly-cubby/temp/interpreter/2023_10/089daf37e9e343ba5ff21afaaa78b967c3466a550b3b11bd5c710c052b559e97/sxhM8gop2AYP88n5uHCsOJ6yTYNQm-HimZ70DcwQ4VI.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=c058d02de50a3cf0bb7e21c8e2d062c5%2F20231010%2F%2Fs3%2Faws4_request&X-Amz-Date=20231010T000000Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=104dc0d4a4b71eeea1030dda1830059920cb0f354fa00197b439eb8565bf141a', 'size': 34275}], 'exitCode': 0}\u001b[0m\u001b[32;1m\u001b[1;3mHere is the chart of the US GDP growth over time:  \n      \n    ![US GDP Over Time](https://bearly-cubby.c559ae877a0a39985f534614a037d899.r2.cloudflarestorage.com/prod/bearly-cubby/temp/interpreter/2023_10/089daf37e9e343ba5ff21afaaa78b967c3466a550b3b11bd5c710c052b559e97/sxhM8gop2AYP88n5uHCsOJ6yTYNQm-HimZ70DcwQ4VI.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=c058d02de50a3cf0bb7e21c8e2d062c5%2F20231010%2F%2Fs3%2Faws4_request&X-Amz-Date=20231010T000000Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=104dc0d4a4b71eeea1030dda1830059920cb0f354fa00197b439eb8565bf141a)  \n      \n    The x-axis represents the year and the y-axis represents the GDP in billions. The line plot shows the growth of the US GDP over time.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    'Here is the chart of the US GDP growth over time:\\n\\n![US GDP Over Time](https://bearly-cubby.c559ae877a0a39985f534614a037d899.r2.cloudflarestorage.com/prod/bearly-cubby/temp/interpreter/2023_10/089daf37e9e343ba5ff21afaaa78b967c3466a550b3b11bd5c710c052b559e97/sxhM8gop2AYP88n5uHCsOJ6yTYNQm-HimZ70DcwQ4VI.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=c058d02de50a3cf0bb7e21c8e2d062c5%2F20231010%2F%2Fs3%2Faws4_request&X-Amz-Date=20231010T000000Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=104dc0d4a4b71eeea1030dda1830059920cb0f354fa00197b439eb8565bf141a)\\n\\nThe x-axis represents the year and the y-axis represents the GDP in billions. The line plot shows the growth of the US GDP over time.'", "bing_search": "> [Bing Search](https://learn.microsoft.com/en-us/bing/search-apis/bing-web-\n> search/) is an Azure service and enables safe, ad-free, location-aware\n> search results, surfacing relevant information from billions of web\n> documents. Help your users find what they're looking for from the world-\n> wide-web by harnessing Bing's ability to comb billions of webpages, images,\n> videos, and news with a single API call.", "brave_search": "This notebook goes over how to use the Brave Search tool. Go to the [Brave\nWebsite](https://brave.com/search/api/) to sign up for a free account and get\nan API key.\n\n    \n    \n    %pip install --upgrade --quiet langchain-community  \n    \n    \n    \n    from langchain_community.tools import BraveSearch  \n    \n\n**API\nReference:**[BraveSearch](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.brave_search.tool.BraveSearch.html)\n\n    \n    \n    api_key = \"API KEY\"  \n    \n    \n    \n    tool = BraveSearch.from_api_key(api_key=api_key, search_kwargs={\"count\": 3})  \n      \n    # or if you want to get the api key from environment variable BRAVE_SEARCH_API_KEY, and leave search_kwargs empty  \n    # tool = BraveSearch()  \n      \n    # or if you want to provide just the api key, and leave search_kwargs empty  \n    # tool = BraveSearch.from_api_key(api_key=api_key)  \n      \n    # or if you want to provide just the search_kwargs and read the api key from the BRAVE_SEARCH_API_KEY environment variable  \n    # tool = BraveSearch.from_search_kwargs(search_kwargs={\"count\": 3})  \n    \n    \n    \n    tool.run(\"obama middle name\")  \n    \n    \n    \n    '[{\"title\": \"Obama\\'s Middle Name -- My Last Name -- is \\'Hussein.\\' So?\", \"link\": \"https://www.cair.com/cair_in_the_news/obamas-middle-name-my-last-name-is-hussein-so/\", \"snippet\": \"I wasn\\\\u2019t sure whether to laugh or cry a few days back listening to radio talk show host Bill Cunningham repeatedly scream Barack <strong>Obama</strong>\\\\u2019<strong>s</strong> <strong>middle</strong> <strong>name</strong> \\\\u2014 my last <strong>name</strong> \\\\u2014 as if he had anti-Muslim Tourette\\\\u2019s. \\\\u201cHussein,\\\\u201d Cunningham hissed like he was beckoning Satan when shouting the ...\"}, {\"title\": \"What\\'s up with Obama\\'s middle name? - Quora\", \"link\": \"https://www.quora.com/Whats-up-with-Obamas-middle-name\", \"snippet\": \"Answer (1 of 15): A better question would be, \\\\u201cWhat\\\\u2019s up with <strong>Obama</strong>\\\\u2019s first <strong>name</strong>?\\\\u201d President Barack Hussein <strong>Obama</strong>\\\\u2019s father\\\\u2019s <strong>name</strong> was Barack Hussein <strong>Obama</strong>. He was <strong>named</strong> after his father. Hussein, <strong>Obama</strong>\\\\u2019<strong>s</strong> <strong>middle</strong> <strong>name</strong>, is a very common Arabic <strong>name</strong>, meaning &quot;good,&quot; &quot;handsome,&quot; or ...\"}, {\"title\": \"Barack Obama | Biography, Parents, Education, Presidency, Books, ...\", \"link\": \"https://www.britannica.com/biography/Barack-Obama\", \"snippet\": \"Barack <strong>Obama</strong>, in full Barack Hussein <strong>Obama</strong> II, (born August 4, 1961, Honolulu, Hawaii, U.S.), 44th president of the United States (2009\\\\u201317) and the first African American to hold the office. Before winning the presidency, <strong>Obama</strong> represented Illinois in the U.S.\"}]'", "cassandra_database": "> `Apache Cassandra\u00ae` is a widely used database for storing transactional\n> application data. The introduction of functions and >tooling in Large\n> Language Models has opened up some exciting use cases for existing data in\n> Generative AI applications.\n\n> The `Cassandra Database` toolkit enables AI engineers to integrate agents\n> with Cassandra data efficiently, offering the following features:\n>\n>   * Fast data access through optimized queries. Most queries should run in\n> single-digit ms or less.\n>   * Schema introspection to enhance LLM reasoning capabilities\n>   * Compatibility with various Cassandra deployments, including Apache\n> Cassandra\u00ae, DataStax Enterprise\u2122, and DataStax Astra\u2122\n>   * Currently, the toolkit is limited to SELECT queries and schema\n> introspection operations. (Safety first)\n>\n\nFor more information on creating a Cassandra DB agent see the [CQL agent\ncookbook](https://github.com/langchain-\nai/langchain/blob/master/cookbook/cql_agent.ipynb)", "cdp_agentkit": "The `CDP Agentkit` toolkit contains tools that enable an LLM agent to interact\nwith the [Coinbase Developer Platform](https://docs.cdp.coinbase.com/). The\ntoolkit provides a wrapper around the CDP SDK, allowing agents to perform\nonchain operations like transfers, trades, and smart contract interactions.", "chatgpt_plugins": "Deprecated\n\nOpenAI has [deprecated plugins](https://openai.com/index/chatgpt-plugins/).\n\nThis example shows how to use ChatGPT Plugins within LangChain abstractions.\n\nNote 1: This currently only works for plugins with no auth.\n\nNote 2: There are almost certainly other ways to do this, this is just a first\npass. If you have better ideas, please open a PR!\n\n    \n    \n    %pip install --upgrade --quiet langchain-community  \n    \n    \n    \n    from langchain_community.tools import AIPluginTool  \n    \n\n**API\nReference:**[AIPluginTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.plugin.AIPluginTool.html)\n\n    \n    \n    from langchain.agents import AgentType, initialize_agent, load_tools  \n    from langchain_openai import ChatOpenAI  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n    \n    \n    tool = AIPluginTool.from_plugin_url(\"https://www.klarna.com/.well-known/ai-plugin.json\")  \n    \n    \n    \n    llm = ChatOpenAI(temperature=0)  \n    tools = load_tools([\"requests_all\"])  \n    tools += [tool]  \n      \n    agent_chain = initialize_agent(  \n        tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True  \n    )  \n    agent_chain.run(\"what t shirts are available in klarna?\")  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3mI need to check the Klarna Shopping API to see if it has information on available t shirts.  \n    Action: KlarnaProducts  \n    Action Input: None\u001b[0m  \n    Observation: \u001b[33;1m\u001b[1;3mUsage Guide: Use the Klarna plugin to get relevant product suggestions for any shopping or researching purpose. The query to be sent should not include stopwords like articles, prepositions and determinants. The api works best when searching for words that are related to products, like their name, brand, model or category. Links will always be returned and should be shown to the user.  \n      \n    OpenAPI Spec: {'openapi': '3.0.1', 'info': {'version': 'v0', 'title': 'Open AI Klarna product Api'}, 'servers': [{'url': 'https://www.klarna.com/us/shopping'}], 'tags': [{'name': 'open-ai-product-endpoint', 'description': 'Open AI Product Endpoint. Query for products.'}], 'paths': {'/public/openai/v0/products': {'get': {'tags': ['open-ai-product-endpoint'], 'summary': 'API for fetching Klarna product information', 'operationId': 'productsUsingGET', 'parameters': [{'name': 'q', 'in': 'query', 'description': 'query, must be between 2 and 100 characters', 'required': True, 'schema': {'type': 'string'}}, {'name': 'size', 'in': 'query', 'description': 'number of products returned', 'required': False, 'schema': {'type': 'integer'}}, {'name': 'budget', 'in': 'query', 'description': 'maximum price of the matching product in local currency, filters results', 'required': False, 'schema': {'type': 'integer'}}], 'responses': {'200': {'description': 'Products found', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ProductResponse'}}}}, '503': {'description': 'one or more services are unavailable'}}, 'deprecated': False}}}, 'components': {'schemas': {'Product': {'type': 'object', 'properties': {'attributes': {'type': 'array', 'items': {'type': 'string'}}, 'name': {'type': 'string'}, 'price': {'type': 'string'}, 'url': {'type': 'string'}}, 'title': 'Product'}, 'ProductResponse': {'type': 'object', 'properties': {'products': {'type': 'array', 'items': {'$ref': '#/components/schemas/Product'}}}, 'title': 'ProductResponse'}}}}\u001b[0m  \n    Thought:\u001b[32;1m\u001b[1;3mI need to use the Klarna Shopping API to search for t shirts.  \n    Action: requests_get  \n    Action Input: https://www.klarna.com/us/shopping/public/openai/v0/products?q=t%20shirts\u001b[0m  \n    Observation: \u001b[36;1m\u001b[1;3m{\"products\":[{\"name\":\"Lacoste Men's Pack of Plain T-Shirts\",\"url\":\"https://www.klarna.com/us/shopping/pl/cl10001/3202043025/Clothing/Lacoste-Men-s-Pack-of-Plain-T-Shirts/?utm_source=openai\",\"price\":\"$26.60\",\"attributes\":[\"Material:Cotton\",\"Target Group:Man\",\"Color:White,Black\"]},{\"name\":\"Hanes Men's Ultimate 6pk. Crewneck T-Shirts\",\"url\":\"https://www.klarna.com/us/shopping/pl/cl10001/3201808270/Clothing/Hanes-Men-s-Ultimate-6pk.-Crewneck-T-Shirts/?utm_source=openai\",\"price\":\"$13.82\",\"attributes\":[\"Material:Cotton\",\"Target Group:Man\",\"Color:White\"]},{\"name\":\"Nike Boy's Jordan Stretch T-shirts\",\"url\":\"https://www.klarna.com/us/shopping/pl/cl359/3201863202/Children-s-Clothing/Nike-Boy-s-Jordan-Stretch-T-shirts/?utm_source=openai\",\"price\":\"$14.99\",\"attributes\":[\"Material:Cotton\",\"Color:White,Green\",\"Model:Boy\",\"Size (Small-Large):S,XL,L,M\"]},{\"name\":\"Polo Classic Fit Cotton V-Neck T-Shirts 3-Pack\",\"url\":\"https://www.klarna.com/us/shopping/pl/cl10001/3203028500/Clothing/Polo-Classic-Fit-Cotton-V-Neck-T-Shirts-3-Pack/?utm_source=openai\",\"price\":\"$29.95\",\"attributes\":[\"Material:Cotton\",\"Target Group:Man\",\"Color:White,Blue,Black\"]},{\"name\":\"adidas Comfort T-shirts Men's 3-pack\",\"url\":\"https://www.klarna.com/us/shopping/pl/cl10001/3202640533/Clothing/adidas-Comfort-T-shirts-Men-s-3-pack/?utm_source=openai\",\"price\":\"$14.99\",\"attributes\":[\"Material:Cotton\",\"Target Group:Man\",\"Color:White,Black\",\"Neckline:Round\"]}]}\u001b[0m  \n    Thought:\u001b[32;1m\u001b[1;3mThe available t shirts in Klarna are Lacoste Men's Pack of Plain T-Shirts, Hanes Men's Ultimate 6pk. Crewneck T-Shirts, Nike Boy's Jordan Stretch T-shirts, Polo Classic Fit Cotton V-Neck T-Shirts 3-Pack, and adidas Comfort T-shirts Men's 3-pack.  \n    Final Answer: The available t shirts in Klarna are Lacoste Men's Pack of Plain T-Shirts, Hanes Men's Ultimate 6pk. Crewneck T-Shirts, Nike Boy's Jordan Stretch T-shirts, Polo Classic Fit Cotton V-Neck T-Shirts 3-Pack, and adidas Comfort T-shirts Men's 3-pack.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    \"The available t shirts in Klarna are Lacoste Men's Pack of Plain T-Shirts, Hanes Men's Ultimate 6pk. Crewneck T-Shirts, Nike Boy's Jordan Stretch T-shirts, Polo Classic Fit Cotton V-Neck T-Shirts 3-Pack, and adidas Comfort T-shirts Men's 3-pack.\"", "clickup": "> [ClickUp](https://clickup.com/) is an all-in-one productivity platform that\n> provides small and large teams across industries with flexible and\n> customizable work management solutions, tools, and functions.\n\n> It is a cloud-based project management solution for businesses of all sizes\n> featuring communication and collaboration tools to help achieve\n> organizational goals.\n    \n    \n    %pip install -qU langchain-community  \n    \n    \n    \n    %reload_ext autoreload  \n    %autoreload 2  \n    from datetime import datetime  \n      \n    from langchain.agents import AgentType, initialize_agent  \n    from langchain_community.agent_toolkits.clickup.toolkit import ClickupToolkit  \n    from langchain_community.utilities.clickup import ClickupAPIWrapper  \n    from langchain_openai import OpenAI  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [ClickupToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.clickup.toolkit.ClickupToolkit.html) | [ClickupAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.clickup.ClickupAPIWrapper.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)", "cogniswitch": "CogniSwitch is used to build production ready applications that can consume,\norganize and retrieve knowledge flawlessly. Using the framework of your\nchoice, in this case Langchain, CogniSwitch helps alleviate the stress of\ndecision making when it comes to, choosing the right storage and retrieval\nformats. It also eradicates reliability issues and hallucinations when it\ncomes to responses that are generated.", "connery": "Using the Connery toolkit and tools, you can integrate Connery Actions into\nyour LangChain agent.", "dalle_image_generator": "> [OpenAI Dall-E](https://openai.com/dall-e-3) are text-to-image models\n> developed by `OpenAI` using deep learning methodologies to generate digital\n> images from natural language descriptions, called \"prompts\".\n\nThis notebook shows how you can generate images from a prompt synthesized\nusing an OpenAI LLM. The images are generated using `Dall-E`, which uses the\nsame OpenAI API key as the LLM.\n\n    \n    \n    # Needed if you would like to display images in the notebook  \n    %pip install --upgrade --quiet  opencv-python scikit-image langchain-community  \n    \n    \n    \n    import os  \n      \n    from langchain_openai import OpenAI  \n      \n    os.environ[\"OPENAI_API_KEY\"] = \"insertapikey\"  \n    \n\n**API\nReference:**[OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)", "dappier": "[Dappier](https://dappier.com) connects any LLM or your Agentic AI to real-\ntime, rights-cleared, proprietary data from trusted sources, making your AI an\nexpert in anything. Our specialized models include Real-Time Web Search, News,\nSports, Financial Stock Market Data, Crypto Data, and exclusive content from\npremium publishers. Explore a wide range of data models in our marketplace at\n[marketplace.dappier.com](https://marketplace.dappier.com).\n\n[Dappier](https://dappier.com) delivers enriched, prompt-ready, and\ncontextually relevant data strings, optimized for seamless integration with\nLangChain. Whether you're building conversational AI, recommendation engines,\nor intelligent search, Dappier's LLM-agnostic RAG models ensure your AI has\naccess to verified, up-to-date data\u2014without the complexity of building and\nmanaging your own retrieval pipeline.\n\n# Dappier Tool\n\nThis will help you getting started with the Dappier\n[tool](https://python.langchain.com/docs/concepts/tools/). For detailed\ndocumentation of all DappierRetriever features and configurations head to the\n[API\nreference](https://python.langchain.com/en/latest/tools/langchain_dappier.tools.Dappier.DappierRealTimeSearchTool.html).", "databricks": "This notebook shows how to use UC functions as LangChain tools, with both\nLangChain and LangGraph agent APIs.\n\nSee Databricks documentation\n([AWS](https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-ddl-\ncreate-sql-function.html)|[Azure](https://learn.microsoft.com/en-\nus/azure/databricks/sql/language-manual/sql-ref-syntax-ddl-create-sql-\nfunction)|[GCP](https://docs.gcp.databricks.com/en/sql/language-manual/sql-\nref-syntax-ddl-create-sql-function.html)) to learn how to create SQL or Python\nfunctions in UC. Do not skip function and parameter comments, which are\ncritical for LLMs to call functions properly.\n\nIn this example notebook, we create a simple Python function that executes\narbitrary code and use it as a LangChain tool:\n\n    \n    \n    CREATE FUNCTION main.tools.python_exec (  \n      code STRING COMMENT 'Python code to execute. Remember to print the final result to stdout.'  \n    )  \n    RETURNS STRING  \n    LANGUAGE PYTHON  \n    COMMENT 'Executes Python code and returns its stdout.'  \n    AS $$  \n      import sys  \n      from io import StringIO  \n      stdout = StringIO()  \n      sys.stdout = stdout  \n      exec(code)  \n      return stdout.getvalue()  \n    $$  \n    \n\nIt runs in a secure and isolated environment within a Databricks SQL\nwarehouse.\n\n    \n    \n    %pip install --upgrade --quiet databricks-sdk langchain-community databricks-langchain langgraph mlflow  \n    \n    \n    \n    Note: you may need to restart the kernel to use updated packages.  \n    \n    \n    \n    from databricks_langchain import ChatDatabricks  \n      \n    llm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-70b-instruct\")  \n    \n    \n    \n    from databricks_langchain.uc_ai import (  \n        DatabricksFunctionClient,  \n        UCFunctionToolkit,  \n        set_uc_function_client,  \n    )  \n      \n    client = DatabricksFunctionClient()  \n    set_uc_function_client(client)  \n      \n    tools = UCFunctionToolkit(  \n        # Include functions as tools using their qualified names.  \n        # You can use \"{catalog_name}.{schema_name}.*\" to get all functions in a schema.  \n        function_names=[\"main.tools.python_exec\"]  \n    ).tools  \n    \n\n(Optional) To increase the retry time for getting a function execution\nresponse, set environment variable UC_TOOL_CLIENT_EXECUTION_TIMEOUT. Default\nretry time value is 120s.", "dataforseo": "> [DataForSeo](https://dataforseo.com/) provides comprehensive SEO and digital\n> marketing data solutions via API.\n>\n> The `DataForSeo API` retrieves `SERP` from the most popular search engines\n> like `Google`, `Bing`, `Yahoo`. It also allows to >get SERPs from different\n> search engine types like `Maps`, `News`, `Events`, etc.\n\nThis notebook demonstrates how to use the [DataForSeo\nAPI](https://dataforseo.com/apis) to obtain search engine results.\n\n    \n    \n    %pip install --upgrade --quiet langchain-community  \n    \n    \n    \n    from langchain_community.utilities.dataforseo_api_search import DataForSeoAPIWrapper  \n    \n\n**API\nReference:**[DataForSeoAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.dataforseo_api_search.DataForSeoAPIWrapper.html)", "dataherald": "This notebook goes over how to use the dataherald component.\n\nFirst, you need to set up your Dataherald account and get your API KEY:\n\n  1. Go to dataherald and sign up [here](https://www.dataherald.com/)\n  2. Once you are logged in your Admin Console, create an API KEY\n  3. pip install dataherald\n\nThen we will need to set some environment variables:\n\n  1. Save your API KEY into DATAHERALD_API_KEY env variable\n\n    \n    \n    pip install dataherald  \n    %pip install --upgrade --quiet langchain-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"DATAHERALD_API_KEY\"] = \"\"  \n    \n    \n    \n    from langchain_community.utilities.dataherald import DataheraldAPIWrapper  \n    \n\n**API\nReference:**[DataheraldAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.dataherald.DataheraldAPIWrapper.html)\n\n    \n    \n    dataherald = DataheraldAPIWrapper(db_connection_id=\"65fb766367dd22c99ce1a12d\")  \n    \n    \n    \n    dataherald.run(\"How many employees are in the company?\")  \n    \n    \n    \n    'select COUNT(*) from employees'", "ddg": "This guide shows over how to use the DuckDuckGo search component.", "discord": "This notebook provides a quick overview for getting started with Discord\ntooling in [langchain_discord](/docs/integrations/tools/). For more details on\neach tool and configuration, see the docstrings in your repository or relevant\ndoc pages.", "e2b_data_analysis": "[E2B's cloud environments](https://e2b.dev) are great runtime sandboxes for\nLLMs.\n\nE2B's Data Analysis sandbox allows for safe code execution in a sandboxed\nenvironment. This is ideal for building tools such as code interpreters, or\nAdvanced Data Analysis like in ChatGPT.\n\nE2B Data Analysis sandbox allows you to:\n\n  * Run Python code\n  * Generate charts via matplotlib\n  * Install Python packages dynamically during runtime\n  * Install system packages dynamically during runtime\n  * Run shell commands\n  * Upload and download files\n\nWe'll create a simple OpenAI agent that will use E2B's Data Analysis sandbox\nto perform analysis on a uploaded files using Python.\n\nGet your OpenAI API key and [E2B API key here](https://e2b.dev/docs/getting-\nstarted/api-key) and set them as environment variables.\n\nYou can find the full API documentation [here](https://e2b.dev/docs).\n\nYou'll need to install `e2b` to get started:\n\n    \n    \n    %pip install --upgrade --quiet  langchain e2b langchain-community  \n    \n    \n    \n    from langchain_community.tools import E2BDataAnalysisTool  \n    \n\n**API\nReference:**[E2BDataAnalysisTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.e2b_data_analysis.tool.E2BDataAnalysisTool.html)\n\n    \n    \n    import os  \n      \n    from langchain.agents import AgentType, initialize_agent  \n    from langchain_openai import ChatOpenAI  \n      \n    os.environ[\"E2B_API_KEY\"] = \"<E2B_API_KEY>\"  \n    os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\"  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n\nWhen creating an instance of the `E2BDataAnalysisTool`, you can pass callbacks\nto listen to the output of the sandbox. This is useful, for example, when\ncreating more responsive UI. Especially with the combination of streaming\noutput from LLMs.\n\n    \n    \n    # Artifacts are charts created by matplotlib when `plt.show()` is called  \n    def save_artifact(artifact):  \n        print(\"New matplotlib chart generated:\", artifact.name)  \n        # Download the artifact as `bytes` and leave it up to the user to display them (on frontend, for example)  \n        file = artifact.download()  \n        basename = os.path.basename(artifact.name)  \n      \n        # Save the chart to the `charts` directory  \n        with open(f\"./charts/{basename}\", \"wb\") as f:  \n            f.write(file)  \n      \n      \n    e2b_data_analysis_tool = E2BDataAnalysisTool(  \n        # Pass environment variables to the sandbox  \n        env_vars={\"MY_SECRET\": \"secret_value\"},  \n        on_stdout=lambda stdout: print(\"stdout:\", stdout),  \n        on_stderr=lambda stderr: print(\"stderr:\", stderr),  \n        on_artifact=save_artifact,  \n    )  \n    \n\nUpload an example CSV data file to the sandbox so we can analyze it with our\nagent. You can use for example [this\nfile](https://storage.googleapis.com/e2b-examples/netflix.csv) about Netflix\ntv shows.\n\n    \n    \n    with open(\"./netflix.csv\") as f:  \n        remote_path = e2b_data_analysis_tool.upload_file(  \n            file=f,  \n            description=\"Data about Netflix tv shows including their title, category, director, release date, casting, age rating, etc.\",  \n        )  \n        print(remote_path)  \n    \n    \n    \n    name='netflix.csv' remote_path='/home/user/netflix.csv' description='Data about Netflix tv shows including their title, category, director, release date, casting, age rating, etc.'  \n    \n\nCreate a `Tool` object and initialize the Langchain agent.\n\n    \n    \n    tools = [e2b_data_analysis_tool.as_tool()]  \n      \n    llm = ChatOpenAI(model=\"gpt-4\", temperature=0)  \n    agent = initialize_agent(  \n        tools,  \n        llm,  \n        agent=AgentType.OPENAI_FUNCTIONS,  \n        verbose=True,  \n        handle_parsing_errors=True,  \n    )  \n    \n\nNow we can ask the agent questions about the CSV file we uploaded earlier.\n\n    \n    \n    agent.run(  \n        \"What are the 5 longest movies on netflix released between 2000 and 2010? Create a chart with their lengths.\"  \n    )  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m  \n    Invoking: `e2b_data_analysis` with `{'python_code': \"import pandas as pd\\n\\n# Load the data\\nnetflix_data = pd.read_csv('/home/user/netflix.csv')\\n\\n# Convert the 'release_year' column to integer\\nnetflix_data['release_year'] = netflix_data['release_year'].astype(int)\\n\\n# Filter the data for movies released between 2000 and 2010\\nfiltered_data = netflix_data[(netflix_data['release_year'] >= 2000) & (netflix_data['release_year'] <= 2010) & (netflix_data['type'] == 'Movie')]\\n\\n# Remove rows where 'duration' is not available\\nfiltered_data = filtered_data[filtered_data['duration'].notna()]\\n\\n# Convert the 'duration' column to integer\\nfiltered_data['duration'] = filtered_data['duration'].str.replace(' min','').astype(int)\\n\\n# Get the top 5 longest movies\\nlongest_movies = filtered_data.nlargest(5, 'duration')\\n\\n# Create a bar chart\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(10,5))\\nplt.barh(longest_movies['title'], longest_movies['duration'], color='skyblue')\\nplt.xlabel('Duration (minutes)')\\nplt.title('Top 5 Longest Movies on Netflix (2000-2010)')\\nplt.gca().invert_yaxis()\\nplt.savefig('/home/user/longest_movies.png')\\n\\nlongest_movies[['title', 'duration']]\"}`  \n      \n      \n    \u001b[0mstdout:                              title  duration  \n    stdout: 1019                        Lagaan       224  \n    stdout: 4573                  Jodhaa Akbar       214  \n    stdout: 2731      Kabhi Khushi Kabhie Gham       209  \n    stdout: 2632  No Direction Home: Bob Dylan       208  \n    stdout: 2126          What's Your Raashee?       203  \n    \u001b[36;1m\u001b[1;3m{'stdout': \"                             title  duration\\n1019                        Lagaan       224\\n4573                  Jodhaa Akbar       214\\n2731      Kabhi Khushi Kabhie Gham       209\\n2632  No Direction Home: Bob Dylan       208\\n2126          What's Your Raashee?       203\", 'stderr': ''}\u001b[0m\u001b[32;1m\u001b[1;3mThe 5 longest movies on Netflix released between 2000 and 2010 are:  \n      \n    1. Lagaan - 224 minutes  \n    2. Jodhaa Akbar - 214 minutes  \n    3. Kabhi Khushi Kabhie Gham - 209 minutes  \n    4. No Direction Home: Bob Dylan - 208 minutes  \n    5. What's Your Raashee? - 203 minutes  \n      \n    Here is the chart showing their lengths:  \n      \n    ![Longest Movies](sandbox:/home/user/longest_movies.png)\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    \"The 5 longest movies on Netflix released between 2000 and 2010 are:\\n\\n1. Lagaan - 224 minutes\\n2. Jodhaa Akbar - 214 minutes\\n3. Kabhi Khushi Kabhie Gham - 209 minutes\\n4. No Direction Home: Bob Dylan - 208 minutes\\n5. What's Your Raashee? - 203 minutes\\n\\nHere is the chart showing their lengths:\\n\\n![Longest Movies](sandbox:/home/user/longest_movies.png)\"  \n    \n\nE2B also allows you to install both Python and system (via `apt`) packages\ndynamically during runtime like this:\n\n    \n    \n    # Install Python package  \n    e2b_data_analysis_tool.install_python_packages(\"pandas\")  \n    \n    \n    \n    stdout: Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.1)  \n    stdout: Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)  \n    stdout: Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)  \n    stdout: Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.1)  \n    stdout: Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)  \n    stdout: Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)  \n    \n\nAdditionally, you can download any file from the sandbox like this:\n\n    \n    \n    # The path is a remote path in the sandbox  \n    files_in_bytes = e2b_data_analysis_tool.download_file(\"/home/user/netflix.csv\")  \n    \n\nLastly, you can run any shell command inside the sandbox via `run_command`.\n\n    \n    \n    # Install SQLite  \n    e2b_data_analysis_tool.run_command(\"sudo apt update\")  \n    e2b_data_analysis_tool.install_system_packages(\"sqlite3\")  \n      \n    # Check the SQLite version  \n    output = e2b_data_analysis_tool.run_command(\"sqlite3 --version\")  \n    print(\"version: \", output[\"stdout\"])  \n    print(\"error: \", output[\"stderr\"])  \n    print(\"exit code: \", output[\"exit_code\"])  \n    \n    \n    \n    stderr:   \n    stderr: WARNING: apt does not have a stable CLI interface. Use with caution in scripts.  \n    stderr:   \n    stdout: Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease  \n    stdout: Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease  \n    stdout: Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease  \n    stdout: Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease  \n    stdout: Reading package lists...  \n    stdout: Building dependency tree...  \n    stdout: Reading state information...  \n    stdout: All packages are up to date.  \n    stdout: Reading package lists...  \n    stdout: Building dependency tree...  \n    stdout: Reading state information...  \n    stdout: Suggested packages:  \n    stdout:   sqlite3-doc  \n    stdout: The following NEW packages will be installed:  \n    stdout:   sqlite3  \n    stdout: 0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.  \n    stdout: Need to get 768 kB of archives.  \n    stdout: After this operation, 1873 kB of additional disk space will be used.  \n    stdout: Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sqlite3 amd64 3.37.2-2ubuntu0.1 [768 kB]  \n    stderr: debconf: delaying package configuration, since apt-utils is not installed  \n    stdout: Fetched 768 kB in 0s (2258 kB/s)  \n    stdout: Selecting previously unselected package sqlite3.  \n    (Reading database ... 23999 files and directories currently installed.)  \n    stdout: Preparing to unpack .../sqlite3_3.37.2-2ubuntu0.1_amd64.deb ...  \n    stdout: Unpacking sqlite3 (3.37.2-2ubuntu0.1) ...  \n    stdout: Setting up sqlite3 (3.37.2-2ubuntu0.1) ...  \n    stdout: 3.37.2 2022-01-06 13:25:41 872ba256cbf61d9290b571c0e6d82a20c224ca3ad82971edc46b29818d5dalt1  \n    version:  3.37.2 2022-01-06 13:25:41 872ba256cbf61d9290b571c0e6d82a20c224ca3ad82971edc46b29818d5dalt1  \n    error:    \n    exit code:  0  \n    \n\nWhen your agent is finished, don't forget to close the sandbox\n\n    \n    \n    e2b_data_analysis_tool.close()", "edenai_tools": "This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.\n\nEden AI is revolutionizing the AI landscape by uniting the best AI providers,\nempowering users to unlock limitless possibilities and tap into the true\npotential of artificial intelligence. With an all-in-one comprehensive and\nhassle-free platform, it allows users to deploy AI features to production\nlightning fast, enabling effortless access to the full breadth of AI\ncapabilities via a single API. (website: <https://edenai.co/> )\n\nBy including an Edenai tool in the list of tools provided to an Agent, you can\ngrant your Agent the ability to do multiple tasks, such as:\n\n  * speech to text\n  * text to speech\n  * text explicit content detection\n  * image explicit content detection\n  * object detection\n  * OCR invoice parsing\n  * OCR ID parsing\n\nIn this example, we will go through the process of utilizing the Edenai tools\nto create an Agent that can perform some of the tasks listed above.\n\n* * *\n\nAccessing the EDENAI's API requires an API key,\n\nwhich you can get by creating an account\n<https://app.edenai.run/user/register> and heading here\n<https://app.edenai.run/admin/account/settings>\n\nOnce we have a key we'll want to set it as the environment variable\n`EDENAI_API_KEY` or you can pass the key in directly via the edenai_api_key\nnamed parameter when initiating the EdenAI tools, e.g.\n`EdenAiTextModerationTool(edenai_api_key=\"...\")`\n\n    \n    \n    %pip install --upgrade --quiet langchain-community  \n    \n    \n    \n    from langchain_community.tools.edenai import (  \n        EdenAiExplicitImageTool,  \n        EdenAiObjectDetectionTool,  \n        EdenAiParsingIDTool,  \n        EdenAiParsingInvoiceTool,  \n        EdenAiSpeechToTextTool,  \n        EdenAiTextModerationTool,  \n        EdenAiTextToSpeechTool,  \n    )  \n    \n\n**API Reference:**[EdenAiExplicitImageTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.image_explicitcontent.EdenAiExplicitImageTool.html) | [EdenAiObjectDetectionTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.image_objectdetection.EdenAiObjectDetectionTool.html) | [EdenAiParsingIDTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.ocr_identityparser.EdenAiParsingIDTool.html) | [EdenAiParsingInvoiceTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.ocr_invoiceparser.EdenAiParsingInvoiceTool.html) | [EdenAiSpeechToTextTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.audio_speech_to_text.EdenAiSpeechToTextTool.html) | [EdenAiTextModerationTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.text_moderation.EdenAiTextModerationTool.html) | [EdenAiTextToSpeechTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.edenai.audio_text_to_speech.EdenAiTextToSpeechTool.html)\n    \n    \n    from langchain.agents import AgentType, initialize_agent  \n    from langchain_community.llms import EdenAI  \n      \n    llm = EdenAI(  \n        feature=\"text\", provider=\"openai\", params={\"temperature\": 0.2, \"max_tokens\": 250}  \n    )  \n      \n    tools = [  \n        EdenAiTextModerationTool(providers=[\"openai\"], language=\"en\"),  \n        EdenAiObjectDetectionTool(providers=[\"google\", \"api4ai\"]),  \n        EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\"),  \n        EdenAiExplicitImageTool(providers=[\"amazon\", \"google\"]),  \n        EdenAiSpeechToTextTool(providers=[\"amazon\"]),  \n        EdenAiParsingIDTool(providers=[\"amazon\", \"klippa\"], language=\"en\"),  \n        EdenAiParsingInvoiceTool(providers=[\"amazon\", \"google\"], language=\"en\"),  \n    ]  \n    agent_chain = initialize_agent(  \n        tools,  \n        llm,  \n        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  \n        verbose=True,  \n        return_intermediate_steps=True,  \n    )  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [EdenAI](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.edenai.EdenAI.html)", "eleven_labs_tts": "This notebook shows how to interact with the `ElevenLabs API` to achieve text-\nto-speech capabilities.\n\nFirst, you need to set up an ElevenLabs account. You can follow the\ninstructions [here](https://docs.elevenlabs.io/welcome/introduction).\n\n    \n    \n    %pip install --upgrade --quiet  elevenlabs langchain-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"ELEVENLABS_API_KEY\"] = \"\"", "exa_search": "Exa is a search engine fully designed for use by LLMs. Search for documents on\nthe internet using **natural language queries** , then retrieve **cleaned HTML\ncontent** from desired documents.\n\nUnlike keyword-based search (Google), Exa's neural search capabilities allow\nit to semantically understand queries and return relevant documents. For\nexample, we could search `\"fascinating article about cats\"` and compare the\nsearch results from\n[Google](https://www.google.com/search?q=fascinating+article+about+cats) and\n[Exa](https://search.exa.ai/search?q=fascinating%20article%20about%20cats&autopromptString=Here%20is%20a%20fascinating%20article%20about%20cats%3A).\nGoogle gives us SEO-optimized listicles based on the keyword \"fascinating\".\nExa just works.\n\nThis notebook goes over how to use Exa Search with LangChain.\n\nFirst, get an Exa API key and add it as an environment variable. Get $10 free\ncredit (plus more by completing certain actions like making your first search)\nby [signing up here](https://dashboard.exa.ai/).\n\n    \n    \n    import os  \n      \n    api_key = os.getenv(\"EXA_API_KEY\")  # Set your API key as an environment variable  \n    \n\nAnd install the integration package\n\n    \n    \n    %pip install --upgrade --quiet langchain-exa   \n      \n    # and some deps for this notebook  \n    %pip install --upgrade --quiet langchain langchain-openai langchain-community", "filesystem": "LangChain provides tools for interacting with a local file system out of the\nbox. This notebook walks through some of them.\n\n**Note:** these tools are not recommended for use outside a sandboxed\nenvironment!\n\n    \n    \n    %pip install -qU langchain-community  \n    \n\nFirst, we'll import the tools.\n\n    \n    \n    from tempfile import TemporaryDirectory  \n      \n    from langchain_community.agent_toolkits import FileManagementToolkit  \n      \n    # We'll make a temporary directory to avoid clutter  \n    working_directory = TemporaryDirectory()  \n    \n\n**API\nReference:**[FileManagementToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.file_management.toolkit.FileManagementToolkit.html)", "financial_datasets": "The [financial datasets](https://financialdatasets.ai/) stock market API\nprovides REST endpoints that let you get financial data for 16,000+ tickers\nspanning 30+ years.", "fmp-data": "Access financial market data through natural language queries.", "github": "The `Github` toolkit contains tools that enable an LLM agent to interact with\na github repository. The tool is a wrapper for the\n[PyGitHub](https://github.com/PyGithub/PyGithub) library.\n\nFor detailed documentation of all GithubToolkit features and configurations\nhead to the [API\nreference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.github.toolkit.GitHubToolkit.html).", "gitlab": "The `Gitlab` toolkit contains tools that enable an LLM agent to interact with\na gitlab repository. The tool is a wrapper for the [python-\ngitlab](https://github.com/python-gitlab/python-gitlab) library.", "gmail": "This will help you getting started with the GMail\n[toolkit](/docs/concepts/tools/#toolkits). This toolkit interacts with the\nGMail API to read messages, draft and send messages, and more. For detailed\ndocumentation of all GmailToolkit features and configurations head to the [API\nreference](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.toolkit.GmailToolkit.html).", "goat": "[GOAT](https://github.com/goat-sdk/goat) is the finance toolkit for AI agents.", "golden_query": "> [Golden](https://golden.com) provides a set of natural language APIs for\n> querying and enrichment using the Golden Knowledge Graph e.g. queries such\n> as: `Products from OpenAI`, `Generative ai companies with series a funding`,\n> and `rappers who invest` can be used to retrieve structured data about\n> relevant entities.\n>\n> The `golden-query` langchain tool is a wrapper on top of the [Golden Query\n> API](https://docs.golden.com/reference/query-api) which enables programmatic\n> access to these results. See the [Golden Query API\n> docs](https://docs.golden.com/reference/query-api) for more information.\n\nThis notebook goes over how to use the `golden-query` tool.\n\n  * Go to the [Golden API docs](https://docs.golden.com/) to get an overview about the Golden API.\n  * Get your API key from the [Golden API Settings](https://golden.com/settings/api) page.\n  * Save your API key into GOLDEN_API_KEY env variable\n\n    \n    \n    %pip install -qU langchain-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"GOLDEN_API_KEY\"] = \"\"  \n    \n    \n    \n    from langchain_community.utilities.golden_query import GoldenQueryAPIWrapper  \n    \n\n**API\nReference:**[GoldenQueryAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.golden_query.GoldenQueryAPIWrapper.html)\n\n    \n    \n    golden_query = GoldenQueryAPIWrapper()  \n    \n    \n    \n    import json  \n      \n    json.loads(golden_query.run(\"companies in nanotech\"))  \n    \n    \n    \n    {'results': [{'id': 4673886,  \n       'latestVersionId': 60276991,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Samsung', 'citations': []}]}]},  \n      {'id': 7008,  \n       'latestVersionId': 61087416,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Intel', 'citations': []}]}]},  \n      {'id': 24193,  \n       'latestVersionId': 60274482,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Texas Instruments', 'citations': []}]}]},  \n      {'id': 1142,  \n       'latestVersionId': 61406205,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Advanced Micro Devices', 'citations': []}]}]},  \n      {'id': 193948,  \n       'latestVersionId': 58326582,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Freescale Semiconductor', 'citations': []}]}]},  \n      {'id': 91316,  \n       'latestVersionId': 60387380,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Agilent Technologies', 'citations': []}]}]},  \n      {'id': 90014,  \n       'latestVersionId': 60388078,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Novartis', 'citations': []}]}]},  \n      {'id': 237458,  \n       'latestVersionId': 61406160,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'Analog Devices', 'citations': []}]}]},  \n      {'id': 3941943,  \n       'latestVersionId': 60382250,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'AbbVie Inc.', 'citations': []}]}]},  \n      {'id': 4178762,  \n       'latestVersionId': 60542667,  \n       'properties': [{'predicateId': 'name',  \n         'instances': [{'value': 'IBM', 'citations': []}]}]}],  \n     'next': 'https://golden.com/api/v2/public/queries/59044/results/?cursor=eyJwb3NpdGlvbiI6IFsxNzYxNiwgIklCTS04M1lQM1oiXX0%3D&pageSize=10',  \n     'previous': None}", "google_books": "", "google_calendar": "> [Google\n> Calendar](https://workspace.google.com/intl/en-419/products/calendar/) is a\n> product of Google Workspace that allows users to organize their schedules\n> and events. It is a cloud-based calendar that allows users to create, edit,\n> and delete events. It also allows users to share their calendars with\n> others.", "google_cloud_texttospeech": "> [Google Cloud Text-to-Speech](https://cloud.google.com/text-to-speech)\n> enables developers to synthesize natural-sounding speech with 100+ voices,\n> available in multiple languages and variants. It applies DeepMind\u2019s\n> groundbreaking research in WaveNet and Google\u2019s powerful neural networks to\n> deliver the highest fidelity possible.\n>\n> It supports multiple languages, including English, German, Polish, Spanish,\n> Italian, French, Portuguese, and Hindi.\n\nThis notebook shows how to interact with the `Google Cloud Text-to-Speech API`\nto achieve speech synthesis capabilities.\n\nFirst, you need to set up an Google Cloud project. You can follow the\ninstructions [here](https://cloud.google.com/text-to-speech/docs/before-you-\nbegin).\n\n    \n    \n    !pip install --upgrade langchain-google-community[texttospeech]", "google_drive": "This notebook walks through connecting a LangChain to the `Google Drive API`.", "google_finance": "This notebook goes over how to use the Google Finance Tool to get information\nfrom the Google Finance page\n\nTo get an SerpApi key key, sign up at: <https://serpapi.com/users/sign_up>.\n\nThen install google-search-results with the command:\n\npip install google-search-results\n\nThen set the environment variable SERPAPI_API_KEY to your SerpApi key\n\nOr pass the key in as a argument to the wrapper serp_api_key=\"your secret key\"\n\nUse the Tool\n\n    \n    \n    %pip install --upgrade --quiet  google-search-results langchain-community  \n    \n    \n    \n    import os  \n      \n    from langchain_community.tools.google_finance import GoogleFinanceQueryRun  \n    from langchain_community.utilities.google_finance import GoogleFinanceAPIWrapper  \n      \n    os.environ[\"SERPAPI_API_KEY\"] = \"\"  \n    tool = GoogleFinanceQueryRun(api_wrapper=GoogleFinanceAPIWrapper())  \n    \n\n**API Reference:**[GoogleFinanceQueryRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.google_finance.tool.GoogleFinanceQueryRun.html) | [GoogleFinanceAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.google_finance.GoogleFinanceAPIWrapper.html)\n    \n    \n    tool.run(\"Google\")  \n    \n\nUsing it with Langchain\n\n    \n    \n    import os  \n      \n    from langchain.agents import AgentType, initialize_agent, load_tools  \n    from langchain_openai import OpenAI  \n      \n    os.environ[\"OPENAI_API_KEY\"] = \"\"  \n    os.environ[\"SERP_API_KEY\"] = \"\"  \n    llm = OpenAI()  \n    tools = load_tools([\"google-scholar\", \"google-finance\"], llm=llm)  \n    agent = initialize_agent(  \n        tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True  \n    )  \n    agent.run(\"what is google's stock\")  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)", "google_imagen": "> [Imagen on Vertex AI](https://cloud.google.com/vertex-ai/generative-\n> ai/docs/image/overview) brings Google's state of the art image generative AI\n> capabilities to application developers. With Imagen on Vertex AI,\n> application developers can build next-generation AI products that transform\n> their user's imagination into high quality visual assets using AI\n> generation, in seconds.\n\nWith Imagen on Langchain , You can do the following tasks\n\n  * VertexAIImageGeneratorChat : Generate novel images using only a text prompt (text-to-image AI generation).\n  * VertexAIImageEditorChat : Edit an entire uploaded or generated image with a text prompt.\n  * VertexAIImageCaptioning : Get text descriptions of images with visual captioning.\n  * VertexAIVisualQnAChat : Get answers to a question about an image with Visual Question Answering (VQA).\n    * NOTE : Currently we support only only single-turn chat for Visual QnA (VQA)", "google_jobs": "This notebook goes over how to use the Google Jobs Tool to fetch current Job\npostings.\n\nFirst, you need to sign up for an `SerpApi key` key at:\n<https://serpapi.com/users/sign_up>.\n\nThen you must install `google-search-results` with the command: `pip install\ngoogle-search-results`\n\nThen you will need to set the environment variable `SERPAPI_API_KEY` to your\n`SerpApi key`\n\nIf you don't have one you can register a free account on\n<https://serpapi.com/users/sign_up> and get your api key here:\n<https://serpapi.com/manage-api-key>\n\nIf you are using conda environment, you can set up using the following\ncommands in kernal: conda activate [your env name] conda env confiv vars\nSERPAPI_API_KEY='[your serp api key]'", "google_lens": "This notebook goes over how to use the Google Lens Tool to fetch information\non an image.\n\nFirst, you need to sign up for an `SerpApi key` key at:\n<https://serpapi.com/users/sign_up>.\n\nThen you must install `requests` with the command:\n\n`pip install requests`\n\nThen you will need to set the environment variable `SERPAPI_API_KEY` to your\n`SerpApi key`\n\n[Alternatively you can pass the key in as a argument to the wrapper\n`serp_api_key=\"your secret key\"`]", "google_places": "This notebook goes through how to use Google Places API\n\n    \n    \n    %pip install --upgrade --quiet  googlemaps langchain-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"GPLACES_API_KEY\"] = \"\"  \n    \n    \n    \n    from langchain_community.tools import GooglePlacesTool  \n    \n\n**API\nReference:**[GooglePlacesTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.google_places.tool.GooglePlacesTool.html)\n\n    \n    \n    places = GooglePlacesTool()  \n    \n    \n    \n    places.run(\"al fornos\")  \n    \n    \n    \n    \"1. Delfina Restaurant\\nAddress: 3621 18th St, San Francisco, CA 94110, USA\\nPhone: (415) 552-4055\\nWebsite: https://www.delfinasf.com/\\n\\n\\n2. Piccolo Forno\\nAddress: 725 Columbus Ave, San Francisco, CA 94133, USA\\nPhone: (415) 757-0087\\nWebsite: https://piccolo-forno-sf.com/\\n\\n\\n3. L'Osteria del Forno\\nAddress: 519 Columbus Ave, San Francisco, CA 94133, USA\\nPhone: (415) 982-1124\\nWebsite: Unknown\\n\\n\\n4. Il Fornaio\\nAddress: 1265 Battery St, San Francisco, CA 94111, USA\\nPhone: (415) 986-0100\\nWebsite: https://www.ilfornaio.com/\\n\\n\"", "google_scholar": "This notebook goes through how to use Google Scholar Tool\n\n    \n    \n    %pip install --upgrade --quiet  google-search-results langchain-community  \n    \n    \n    \n    Requirement already satisfied: google-search-results in /home/mohtashimkhan/mambaforge/envs/langchain/lib/python3.9/site-packages (2.4.2)  \n    Requirement already satisfied: requests in /home/mohtashimkhan/mambaforge/envs/langchain/lib/python3.9/site-packages (from google-search-results) (2.31.0)  \n    Requirement already satisfied: charset-normalizer<4,>=2 in /home/mohtashimkhan/mambaforge/envs/langchain/lib/python3.9/site-packages (from requests->google-search-results) (3.3.0)  \n    Requirement already satisfied: idna<4,>=2.5 in /home/mohtashimkhan/mambaforge/envs/langchain/lib/python3.9/site-packages (from requests->google-search-results) (3.4)  \n    Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohtashimkhan/mambaforge/envs/langchain/lib/python3.9/site-packages (from requests->google-search-results) (1.26.17)  \n    Requirement already satisfied: certifi>=2017.4.17 in /home/mohtashimkhan/mambaforge/envs/langchain/lib/python3.9/site-packages (from requests->google-search-results) (2023.5.7)  \n    \n    \n    \n    import os  \n      \n    from langchain_community.tools.google_scholar import GoogleScholarQueryRun  \n    from langchain_community.utilities.google_scholar import GoogleScholarAPIWrapper  \n    \n\n**API Reference:**[GoogleScholarQueryRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.google_scholar.tool.GoogleScholarQueryRun.html) | [GoogleScholarAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.google_scholar.GoogleScholarAPIWrapper.html)\n    \n    \n    os.environ[\"SERP_API_KEY\"] = \"\"  \n    tool = GoogleScholarQueryRun(api_wrapper=GoogleScholarAPIWrapper())  \n    tool.run(\"LLM Models\")  \n    \n    \n    \n    'Title: Large language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?\\nAuthors: IL Alberts,K Shi\\nSummary: IL Alberts, L Mercolli, T Pyka, G Prenosil, K Shi\u2026 - European journal of \u2026, 2023 - Springer\\nTotal-Citations: 28\\n\\nTitle: Dynamic Planning with a LLM\\nAuthors: G Dagan,F Keller,A Lascarides\\nSummary: G Dagan, F Keller, A Lascarides - arXiv preprint arXiv:2308.06391, 2023 - arxiv.org\\nTotal-Citations: 3\\n\\nTitle: Openagi: When llm meets domain experts\\nAuthors: Y Ge,W Hua,J Ji,J Tan,S Xu,Y Zhang\\nSummary: Y Ge, W Hua, J Ji, J Tan, S Xu, Y Zhang - arXiv preprint arXiv:2304.04370, 2023 - arxiv.org\\nTotal-Citations: 19\\n\\nTitle: Llm-planner: Few-shot grounded planning for embodied agents with large language models\\nAuthors: CH Song\\nSummary: CH Song, J Wu, C Washington\u2026 - Proceedings of the \u2026, 2023 - openaccess.thecvf.com\\nTotal-Citations: 28\\n\\nTitle: The science of detecting llm-generated texts\\nAuthors: R Tang,YN Chuang,X Hu\\nSummary: R Tang, YN Chuang, X Hu - arXiv preprint arXiv:2303.07205, 2023 - arxiv.org\\nTotal-Citations: 23\\n\\nTitle: X-llm: Bootstrapping advanced large language models by treating multi-modalities as foreign languages\\nAuthors: F Chen,M Han,J Shi\\nSummary: F Chen, M Han, H Zhao, Q Zhang, J Shi, S Xu\u2026 - arXiv preprint arXiv \u2026, 2023 - arxiv.org\\nTotal-Citations: 12\\n\\nTitle: 3d-llm: Injecting the 3d world into large language models\\nAuthors: Y Hong,H Zhen,P Chen,S Zheng,Y Du\\nSummary: Y Hong, H Zhen, P Chen, S Zheng, Y Du\u2026 - arXiv preprint arXiv \u2026, 2023 - arxiv.org\\nTotal-Citations: 4\\n\\nTitle: The internal state of an llm knows when its lying\\nAuthors: A Azaria,T Mitchell\\nSummary: A Azaria, T Mitchell - arXiv preprint arXiv:2304.13734, 2023 - arxiv.org\\nTotal-Citations: 18\\n\\nTitle: LLM-Pruner: On the Structural Pruning of Large Language Models\\nAuthors: X Ma,G Fang,X Wang\\nSummary: X Ma, G Fang, X Wang - arXiv preprint arXiv:2305.11627, 2023 - arxiv.org\\nTotal-Citations: 15\\n\\nTitle: Large language models are few-shot testers: Exploring llm-based general bug reproduction\\nAuthors: S Kang,J Yoon,S Yoo\\nSummary: S Kang, J Yoon, S Yoo - 2023 IEEE/ACM 45th International \u2026, 2023 - ieeexplore.ieee.org\\nTotal-Citations: 17'", "google_search": "This notebook goes over how to use the google search component.\n\nFirst, you need to set up the proper API keys and environment variables. To\nset it up, create the GOOGLE_API_KEY in the Google Cloud credential console\n(<https://console.cloud.google.com/apis/credentials>) and a GOOGLE_CSE_ID\nusing the Programmable Search Engine\n(<https://programmablesearchengine.google.com/controlpanel/create>). Next, it\nis good to follow the instructions found\n[here](https://stackoverflow.com/questions/37083058/programmatically-\nsearching-google-in-python-using-custom-search).\n\nThen we will need to set some environment variables.\n\n    \n    \n    %pip install --upgrade --quiet  langchain-google-community  \n    \n    \n    \n    import os  \n      \n    os.environ[\"GOOGLE_CSE_ID\"] = \"\"  \n    os.environ[\"GOOGLE_API_KEY\"] = \"\"  \n    \n    \n    \n    from langchain_core.tools import Tool  \n    from langchain_google_community import GoogleSearchAPIWrapper  \n      \n    search = GoogleSearchAPIWrapper()  \n      \n    tool = Tool(  \n        name=\"google_search\",  \n        description=\"Search Google for recent results.\",  \n        func=search.run,  \n    )  \n    \n\n**API Reference:**[Tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.simple.Tool.html) | [GoogleSearchAPIWrapper](https://python.langchain.com/api_reference/google_community/search/langchain_google_community.search.GoogleSearchAPIWrapper.html)\n    \n    \n    tool.run(\"Obama's first name?\")  \n    \n    \n    \n    \"STATE OF HAWAII. 1 Child's First Name. (Type or print). 2. Sex. BARACK. 3. This Birth. CERTIFICATE OF LIVE BIRTH. FILE. NUMBER 151 le. lb. Middle Name. Barack Hussein Obama II is an American former politician who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic\\xa0... When Barack Obama was elected president in 2008, he became the first African American to hold ... The Middle East remained a key foreign policy challenge. Jan 19, 2017 ... Jordan Barack Treasure, New York City, born in 2008 ... Jordan Barack Treasure made national news when he was the focus of a New York newspaper\\xa0... Portrait of George Washington, the 1st President of the United States ... Portrait of Barack Obama, the 44th President of the United States\\xa0... His full name is Barack Hussein Obama II. Since the \u201cII\u201d is simply because he was named for his father, his last name is Obama. Mar 22, 2008 ... Barry Obama decided that he didn't like his nickname. A few of his friends at Occidental College had already begun to call him Barack (his\\xa0... Aug 18, 2017 ... It took him several seconds and multiple clues to remember former President Barack Obama's first name. Miller knew that every answer had to\\xa0... Feb 9, 2015 ... Michael Jordan misspelled Barack Obama's first name on 50th-birthday gift ... Knowing Obama is a Chicagoan and huge basketball fan,\\xa0... 4 days ago ... Barack Obama, in full Barack Hussein Obama II, (born August 4, 1961, Honolulu, Hawaii, U.S.), 44th president of the United States (2009\u201317) and\\xa0...\"", "google_serper": "This notebook goes over how to use the `Google Serper` component to search the\nweb. First you need to sign up for a free account at\n[serper.dev](https://serper.dev) and get your api key.\n\n    \n    \n    %pip install --upgrade --quiet  langchain-community  \n    \n    \n    \n    import os  \n    import pprint  \n      \n    os.environ[\"SERPER_API_KEY\"] = \"\"  \n    \n    \n    \n    from langchain_community.utilities import GoogleSerperAPIWrapper  \n    \n\n**API\nReference:**[GoogleSerperAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.google_serper.GoogleSerperAPIWrapper.html)\n\n    \n    \n    search = GoogleSerperAPIWrapper()  \n    \n    \n    \n    search.run(\"Obama's first name?\")  \n    \n    \n    \n    'Barack Hussein Obama II'", "google_trends": "This notebook goes over how to use the Google Trends Tool to fetch trends\ninformation.\n\nFirst, you need to sign up for an `SerpApi key` key at:\n<https://serpapi.com/users/sign_up>.\n\nThen you must install `google-search-results` with the command:\n\n`pip install google-search-results`\n\nThen you will need to set the environment variable `SERPAPI_API_KEY` to your\n`SerpApi key`\n\n[Alternatively you can pass the key in as a argument to the wrapper\n`serp_api_key=\"your secret key\"`]", "gradio_tools": "There are many 1000s of `Gradio` apps on `Hugging Face Spaces`. This library\nputs them at the tips of your LLM's fingers \ud83e\uddbe\n\nSpecifically, `gradio-tools` is a Python library for converting `Gradio` apps\ninto tools that can be leveraged by a large language model (LLM)-based agent\nto complete its task. For example, an LLM could use a `Gradio` tool to\ntranscribe a voice recording it finds online and then summarize it for you. Or\nit could use a different `Gradio` tool to apply OCR to a document on your\nGoogle Drive and then answer questions about it.\n\nIt's very easy to create you own tool if you want to use a space that's not\none of the pre-built tools. Please see this section of the gradio-tools\ndocumentation for information on how to do that. All contributions are\nwelcome!\n\n    \n    \n    %pip install --upgrade --quiet  gradio_tools langchain-community", "graphql": "> [GraphQL](https://graphql.org/) is a query language for APIs and a runtime\n> for executing those queries against your data. `GraphQL` provides a complete\n> and understandable description of the data in your API, gives clients the\n> power to ask for exactly what they need and nothing more, makes it easier to\n> evolve APIs over time, and enables powerful developer tools.\n\nBy including a `BaseGraphQLTool` in the list of tools provided to an Agent,\nyou can grant your Agent the ability to query data from GraphQL APIs for any\npurposes you need.\n\nThis Jupyter Notebook demonstrates how to use the `GraphQLAPIWrapper`\ncomponent with an Agent.\n\nIn this example, we'll be using the public `Star Wars GraphQL API` available\nat the following endpoint: <https://swapi-\ngraphql.netlify.app/.netlify/functions/index>.\n\nFirst, you need to install `httpx` and `gql` Python packages.\n\n    \n    \n    pip install httpx gql > /dev/null  \n    \n    \n    \n    %pip install --upgrade --quiet  langchain-community  \n    \n\nNow, let's create a BaseGraphQLTool instance with the specified Star Wars API\nendpoint and initialize an Agent with the tool.\n\n    \n    \n    from langchain.agents import AgentType, initialize_agent, load_tools  \n    from langchain_openai import OpenAI  \n      \n    llm = OpenAI(temperature=0)  \n      \n    tools = load_tools(  \n        [\"graphql\"],  \n        graphql_endpoint=\"https://swapi-graphql.netlify.app/.netlify/functions/index\",  \n    )  \n      \n    agent = initialize_agent(  \n        tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True  \n    )  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n\nNow, we can use the Agent to run queries against the Star Wars GraphQL API.\nLet's ask the Agent to list all the Star Wars films and their release dates.\n\n    \n    \n    graphql_fields = \"\"\"allFilms {  \n        films {  \n          title  \n          director  \n          releaseDate  \n          speciesConnection {  \n            species {  \n              name  \n              classification  \n              homeworld {  \n                name  \n              }  \n            }  \n          }  \n        }  \n      }  \n      \n    \"\"\"  \n      \n    suffix = \"Search for the titles of all the stawars films stored in the graphql database that has this schema \"  \n      \n      \n    agent.run(suffix + graphql_fields)  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m I need to query the graphql database to get the titles of all the star wars films  \n    Action: query_graphql  \n    Action Input: query { allFilms { films { title } } }\u001b[0m  \n    Observation: \u001b[36;1m\u001b[1;3m\"{\\n  \\\"allFilms\\\": {\\n    \\\"films\\\": [\\n      {\\n        \\\"title\\\": \\\"A New Hope\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"The Empire Strikes Back\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Return of the Jedi\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"The Phantom Menace\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Attack of the Clones\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Revenge of the Sith\\\"\\n      }\\n    ]\\n  }\\n}\"\u001b[0m  \n    Thought:\u001b[32;1m\u001b[1;3m I now know the titles of all the star wars films  \n    Final Answer: The titles of all the star wars films are: A New Hope, The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, and Revenge of the Sith.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    'The titles of all the star wars films are: A New Hope, The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, and Revenge of the Sith.'", "huggingface_tools": "> [Huggingface\n> Tools](https://huggingface.co/docs/transformers/v4.29.0/en/custom_tools)\n> that supporting text I/O can be loaded directly using the\n> `load_huggingface_tool` function.\n    \n    \n    # Requires transformers>=4.29.0 and huggingface_hub>=0.14.1  \n    %pip install --upgrade --quiet  transformers huggingface_hub > /dev/null  \n    \n    \n    \n    %pip install --upgrade --quiet  langchain-community  \n    \n    \n    \n    from langchain_community.agent_toolkits.load_tools import load_huggingface_tool  \n      \n    tool = load_huggingface_tool(\"lysandre/hf-model-downloads\")  \n      \n    print(f\"{tool.name}: {tool.description}\")  \n    \n\n**API\nReference:**[load_huggingface_tool](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_huggingface_tool.html)\n\n    \n    \n    model_download_counter: This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. It takes the name of the category (such as text-classification, depth-estimation, etc), and returns the name of the checkpoint  \n    \n    \n    \n    tool.run(\"text-classification\")  \n    \n    \n    \n    'facebook/bart-large-mnli'", "human_tools": "Human are AGI so they can certainly be used as a tool to help out AI agent\nwhen it is confused.\n\n    \n    \n    %pip install --upgrade --quiet  langchain-community  \n    \n    \n    \n    from langchain.agents import AgentType, initialize_agent, load_tools  \n    from langchain_openai import ChatOpenAI, OpenAI  \n      \n    llm = ChatOpenAI(temperature=0.0)  \n    math_llm = OpenAI(temperature=0.0)  \n    tools = load_tools(  \n        [\"human\", \"llm-math\"],  \n        llm=math_llm,  \n    )  \n      \n    agent_chain = initialize_agent(  \n        tools,  \n        llm,  \n        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  \n        verbose=True,  \n    )  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n\nIn the above code you can see the tool takes input directly from command line.\nYou can customize `prompt_func` and `input_func` according to your need (as\nshown below).\n\n    \n    \n    agent_chain.run(\"What's my friend Eric's surname?\")  \n    # Answer with 'Zhu'  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3mI don't know Eric's surname, so I should ask a human for guidance.  \n    Action: Human  \n    Action Input: \"What is Eric's surname?\"\u001b[0m  \n      \n    What is Eric's surname?  \n    ``````output  \n     Zhu  \n    ``````output  \n      \n    Observation: \u001b[36;1m\u001b[1;3mZhu\u001b[0m  \n    Thought:\u001b[32;1m\u001b[1;3mI now know Eric's surname is Zhu.  \n    Final Answer: Eric's surname is Zhu.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    \"Eric's surname is Zhu.\"", "hyperbrowser_browser_agent_tools": "[Hyperbrowser](https://hyperbrowser.ai) is a platform for running, running\nbrowser agents, and scaling headless browsers. It lets you launch and manage\nbrowser sessions at scale and provides easy to use solutions for any\nwebscraping needs, such as scraping a single page or crawling an entire site.\n\nKey Features:\n\n  * Instant Scalability - Spin up hundreds of browser sessions in seconds without infrastructure headaches\n  * Simple Integration - Works seamlessly with popular tools like Puppeteer and Playwright\n  * Powerful APIs - Easy to use APIs for scraping/crawling any site, and much more\n  * Bypass Anti-Bot Measures - Built-in stealth mode, ad blocking, automatic CAPTCHA solving, and rotating proxies\n\nThis notebook provides a quick overview for getting started with Hyperbrowser\ntools.\n\nFor more information about Hyperbrowser, please visit the [Hyperbrowser\nwebsite](https://hyperbrowser.ai) or if you want to check out the docs, you\ncan visit the [Hyperbrowser docs](https://docs.hyperbrowser.ai).", "hyperbrowser_web_scraping_tools": "[Hyperbrowser](https://hyperbrowser.ai) is a platform for running and scaling\nheadless browsers. It lets you launch and manage browser sessions at scale and\nprovides easy to use solutions for any webscraping needs, such as scraping a\nsingle page or crawling an entire site.\n\nKey Features:\n\n  * Instant Scalability - Spin up hundreds of browser sessions in seconds without infrastructure headaches\n  * Simple Integration - Works seamlessly with popular tools like Puppeteer and Playwright\n  * Powerful APIs - Easy to use APIs for scraping/crawling any site, and much more\n  * Bypass Anti-Bot Measures - Built-in stealth mode, ad blocking, automatic CAPTCHA solving, and rotating proxies\n\nThis notebook provides a quick overview for getting started with Hyperbrowser\nweb tools.\n\nFor more information about Hyperbrowser, please visit the [Hyperbrowser\nwebsite](https://hyperbrowser.ai) or if you want to check out the docs, you\ncan visit the [Hyperbrowser docs](https://docs.hyperbrowser.ai).", "ibm_watsonx": "> WatsonxToolkit is a wrapper for IBM\n> [watsonx.ai](https://www.ibm.com/products/watsonx-ai) Toolkit.\n\nThis example shows how to use `watsonx.ai` Toolkit using `LangChain`.", "ifttt": "This notebook shows how to use IFTTT Webhooks.\n\nFrom <https://github.com/SidU/teams-langchain-js/wiki/Connecting-IFTTT-\nServices>.", "infobip": "This notebook that shows how to use [Infobip](https://www.infobip.com/) API\nwrapper to send SMS messages, emails.\n\nInfobip provides many services, but this notebook will focus on SMS and Email\nservices. You can find more information about the API and other channels\n[here](https://www.infobip.com/docs/api).", "ionic_shopping": "[Ionic](https://www.ioniccommerce.com/) is a plug and play ecommerce\nmarketplace for AI Assistants. By including the [Ionic\nTool](https://github.com/ioniccommerce/ionic_langchain) in your agent, you are\neffortlessly providing your users with the ability to shop and transact\ndirectly within your agent, and you'll get a cut of the transaction.\n\nThis is a basic jupyter notebook demonstrating how to integrate the Ionic Tool\ninto your agent. For more information on setting up your Agent with Ionic, see\nthe Ionic [documentation](https://docs.ioniccommerce.com/introduction).\n\nThis Jupyter Notebook demonstrates how to use the Ionic tool with an Agent.\n\n**Note: The ionic-langchain package is maintained by the Ionic Commerce team,\nnot the LangChain maintainers.**\n\n* * *", "jenkins": "Tools for interacting with [Jenkins](https://www.jenkins.io/).", "jina_search": "This notebook provides a quick overview for getting started with Jina\n[tool](/docs/integrations/tools/). For detailed documentation of all Jina\nfeatures and configurations head to the [API\nreference](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html).", "jira": "This notebook goes over how to use the `Jira` toolkit.\n\nThe `Jira` toolkit allows agents to interact with a given Jira instance,\nperforming actions such as searching for issues and creating issues, the tool\nwraps the atlassian-python-api library, for more see: <https://atlassian-\npython-api.readthedocs.io/jira.html>", "json": "This notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too\nlarge to fit in the context window of an LLM. The agent is able to iteratively\nexplore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which\nyou can find [here](https://github.com/openai/openai-\nopenapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n    \n    \n    %pip install -qU langchain-community", "lemonai": "> [Lemon Agent](https://github.com/felixbrock/lemon-agent) helps you build\n> powerful AI assistants in minutes and automate workflows by allowing for\n> accurate and reliable read and write operations in tools like `Airtable`,\n> `Hubspot`, `Discord`, `Notion`, `Slack` and `Github`.\n\nSee [full docs here](https://github.com/felixbrock/lemonai-py-client).\n\nMost connectors available today are focused on read-only operations, limiting\nthe potential of LLMs. Agents, on the other hand, have a tendency to\nhallucinate from time to time due to missing context or instructions.\n\nWith `Lemon AI`, it is possible to give your agents access to well-defined\nAPIs for reliable read and write operations. In addition, `Lemon AI` functions\nallow you to further reduce the risk of hallucinations by providing a way to\nstatically define workflows that the model can rely on in case of uncertainty.", "linkup_search": "> [Linkup](https://www.linkup.so/) provides an API to connect LLMs to the web\n> and the Linkup Premium Partner sources.\n\nThis notebook provides a quick overview for getting started with\nLinkupSearchTool [tool](/docs/concepts/tools/). For detailed documentation of\nall LinkupSearchTool features and configurations head to the [API\nreference](https://python.langchain.com/api_reference/linkup/tools/linkup_langchain.search_tool.LinkupSearchTool.html).", "memgraph": "", "memorize": "Fine-tuning LLM itself to memorize information using unsupervised learning.\n\nThis tool requires LLMs that support fine-tuning. Currently, only\n`langchain.llms import GradientLLM` is supported.", "mojeek_search": "The following notebook will explain how to get results using Mojeek Search.\nPlease visit [Mojeek Website](https://www.mojeek.com/services/search/web-\nsearch-api/) to obtain an API key.\n\n    \n    \n    from langchain_community.tools import MojeekSearch  \n    \n\n**API\nReference:**[MojeekSearch](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.mojeek_search.tool.MojeekSearch.html)\n\n    \n    \n    api_key = \"KEY\"  # obtained from Mojeek Website  \n    \n    \n    \n    search = MojeekSearch.config(api_key=api_key, search_kwargs={\"t\": 10})  \n    \n\nIn `search_kwargs` you can add any search parameter that you can find on\n[Mojeek\nDocumentation](https://www.mojeek.com/support/api/search/request_parameters.html)\n\n    \n    \n    search.run(\"mojeek\")", "multion": "[MultiON](https://www.multion.ai/blog/multion-building-a-brighter-future-for-\nhumanity-with-ai-agents) has built an AI Agent that can interact with a broad\narray of web services and applications.\n\nThis notebook walks you through connecting LangChain to the `MultiOn` Client\nin your browser.\n\nThis enables custom agentic workflow that utilize the power of MultiON agents.\n\nTo use this toolkit, you will need to add `MultiOn Extension` to your browser:\n\n  * Create a [MultiON account](https://app.multion.ai/login?callbackUrl=%2Fprofile).\n  * Add [MultiOn extension for Chrome](https://multion.notion.site/Download-MultiOn-ddddcfe719f94ab182107ca2612c07a5).\n\n    \n    \n    %pip install --upgrade --quiet  multion langchain -q  \n    \n    \n    \n    %pip install -qU langchain-community  \n    \n    \n    \n    from langchain_community.agent_toolkits import MultionToolkit  \n      \n    toolkit = MultionToolkit()  \n    toolkit  \n    \n\n**API\nReference:**[MultionToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.multion.toolkit.MultionToolkit.html)\n\n    \n    \n    MultionToolkit()  \n    \n    \n    \n    tools = toolkit.get_tools()  \n    tools  \n    \n    \n    \n    [MultionCreateSession(), MultionUpdateSession(), MultionCloseSession()]", "nasa": "This notebook shows how to use agents to interact with the NASA toolkit. The\ntoolkit provides access to the NASA Image and Video Library API, with\npotential to expand and include other accessible NASA APIs in future\niterations.\n\n**Note: NASA Image and Video Library search queries can result in large\nresponses when the number of desired media results is not specified. Consider\nthis prior to using the agent with LLM token credits.**", "naver_search": "", "nuclia": "> [Nuclia](https://nuclia.com) automatically indexes your unstructured data\n> from any internal and external source, providing optimized search results\n> and generative answers. It can handle video and audio transcription, image\n> content extraction, and document parsing.\n\nThe `Nuclia Understanding API` supports the processing of unstructured data,\nincluding text, web pages, documents, and audio/video contents. It extracts\nall texts wherever it is (using speech-to-text or OCR when needed), it\nidentifies entities, it also extracts metadata, embedded files (like images in\na PDF), and web links. It also provides a summary of the content.\n\nTo use the `Nuclia Understanding API`, you need to have a `Nuclia` account.\nYou can create one for free at <https://nuclia.cloud>, and then [create a NUA\nkey](https://docs.nuclia.dev/docs/docs/using/understanding/intro).\n\n    \n    \n    %pip install --upgrade --quiet  protobuf  \n    %pip install --upgrade --quiet  nucliadb-protos  \n    \n    \n    \n    import os  \n      \n    os.environ[\"NUCLIA_ZONE\"] = \"<YOUR_ZONE>\"  # e.g. europe-1  \n    os.environ[\"NUCLIA_NUA_KEY\"] = \"<YOUR_API_KEY>\"  \n    \n    \n    \n    from langchain_community.tools.nuclia import NucliaUnderstandingAPI  \n      \n    nua = NucliaUnderstandingAPI(enable_ml=False)  \n    \n\n**API\nReference:**[NucliaUnderstandingAPI](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.nuclia.tool.NucliaUnderstandingAPI.html)\n\nYou can push files to the Nuclia Understanding API using the `push` action. As\nthe processing is done asynchronously, the results might be returned in a\ndifferent order than the files were pushed. That is why you need to provide an\n`id` to match the results with the corresponding file.\n\n    \n    \n    nua.run({\"action\": \"push\", \"id\": \"1\", \"path\": \"./report.docx\"})  \n    nua.run({\"action\": \"push\", \"id\": \"2\", \"path\": \"./interview.mp4\"})  \n    \n\nYou can now call the `pull` action in a loop until you get the JSON-formatted\nresult.\n\n    \n    \n    import time  \n      \n    pending = True  \n    data = None  \n    while pending:  \n        time.sleep(15)  \n        data = nua.run({\"action\": \"pull\", \"id\": \"1\", \"path\": None})  \n        if data:  \n            print(data)  \n            pending = False  \n        else:  \n            print(\"waiting...\")  \n    \n\nYou can also do it in one step in `async` mode, you only need to do a push,\nand it will wait until the results are pulled:\n\n    \n    \n    import asyncio  \n      \n      \n    async def process():  \n        data = await nua.arun(  \n            {\"action\": \"push\", \"id\": \"1\", \"path\": \"./talk.mp4\", \"text\": None}  \n        )  \n        print(data)  \n      \n      \n    asyncio.run(process())", "nvidia_riva": "", "office365": "> [Microsoft 365](https://www.office.com/) is a product family of productivity\n> software, collaboration and cloud-based services owned by `Microsoft`.\n>\n> Note: `Office 365` was rebranded as `Microsoft 365`.\n\nThis notebook walks through connecting LangChain to `Office365` email and\ncalendar.\n\nTo use this toolkit, you need to set up your credentials explained in the\n[Microsoft Graph authentication and authorization\noverview](https://learn.microsoft.com/en-us/graph/auth/). Once you've received\na CLIENT_ID and CLIENT_SECRET, you can input them as environmental variables\nbelow.\n\nYou can also use the [authentication instructions from\nhere](https://o365.github.io/python-o365/latest/getting_started.html#oauth-\nsetup-pre-requisite).\n\n    \n    \n    %pip install --upgrade --quiet  O365  \n    %pip install --upgrade --quiet  beautifulsoup4  # This is optional but is useful for parsing HTML messages  \n    %pip install -qU langchain-community", "openapi": "We can construct agents to consume arbitrary APIs, here APIs conformant to the\n`OpenAPI`/`Swagger` specification.\n\n    \n    \n    # NOTE: In this example. We must set `allow_dangerous_request=True` to enable the OpenAPI Agent to automatically use the Request Tool.  \n    # This can be dangerous for calling unwanted requests. Please make sure your custom OpenAPI spec (yaml) is safe.  \n    ALLOW_DANGEROUS_REQUEST = True", "openapi_nla": "`Natural Language API` Toolkits (`NLAToolkits`) permit LangChain Agents to\nefficiently plan and combine calls across endpoints.\n\nThis notebook demonstrates a sample composition of the `Speak`, `Klarna`, and\n`Spoonacluar` APIs.", "opengradient_toolkit": "This notebook shows how to build tools using the OpenGradient toolkit. This\ntoolkit gives users the ability to create custom tools based on models and\nworkflows on the [OpenGradient network](https://www.opengradient.ai/).", "openweathermap": "This notebook goes over how to use the `OpenWeatherMap` component to fetch\nweather information.\n\nFirst, you need to sign up for an `OpenWeatherMap API` key:\n\n  1. Go to OpenWeatherMap and sign up for an API key [here](https://openweathermap.org/api/)\n  2. pip install pyowm\n\nThen we will need to set some environment variables:\n\n  1. Save your API KEY into OPENWEATHERMAP_API_KEY env variable", "oracleai": "Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads\nthat allows you to query data based on semantics, rather than keywords. One of\nthe biggest benefits of Oracle AI Vector Search is that semantic search on\nunstructured data can be combined with relational search on business data in\none single system. This is not only powerful but also significantly more\neffective because you don't need to add a specialized vector database,\neliminating the pain of data fragmentation between multiple systems.\n\nIn addition, your vectors can benefit from all of Oracle Database\u2019s most\npowerful features, like the following:\n\n  * [Partitioning Support](https://www.oracle.com/database/technologies/partitioning.html)\n  * [Real Application Clusters scalability](https://www.oracle.com/database/real-application-clusters/)\n  * [Exadata smart scans](https://www.oracle.com/database/technologies/exadata/software/smartscan/)\n  * [Shard processing across geographically distributed databases](https://www.oracle.com/database/distributed-database/)\n  * [Transactions](https://docs.oracle.com/en/database/oracle/oracle-database/23/cncpt/transactions.html)\n  * [Parallel SQL](https://docs.oracle.com/en/database/oracle/oracle-database/21/vldbg/parallel-exec-intro.html#GUID-D28717E4-0F77-44F5-BB4E-234C31D4E4BA)\n  * [Disaster recovery](https://www.oracle.com/database/data-guard/)\n  * [Security](https://www.oracle.com/security/database-security/)\n  * [Oracle Machine Learning](https://www.oracle.com/artificial-intelligence/database-machine-learning/)\n  * [Oracle Graph Database](https://www.oracle.com/database/integrated-graph-database/)\n  * [Oracle Spatial and Graph](https://www.oracle.com/database/spatial/)\n  * [Oracle Blockchain](https://docs.oracle.com/en/database/oracle/oracle-database/23/arpls/dbms_blockchain_table.html#GUID-B469E277-978E-4378-A8C1-26D3FF96C9A6)\n  * [JSON](https://docs.oracle.com/en/database/oracle/oracle-database/23/adjsn/json-in-oracle-database.html)\n\nThe guide demonstrates how to use Summary Capabilities within Oracle AI Vector\nSearch to generate summary for your documents using OracleSummary.\n\nIf you are just starting with Oracle Database, consider exploring the [free\nOracle 23 AI](https://www.oracle.com/database/free/#resources) which provides\na great introduction to setting up your database environment. While working\nwith the database, it is often advisable to avoid using the system user by\ndefault; instead, you can create your own user for enhanced security and\ncustomization. For detailed steps on user creation, refer to our [end-to-end\nguide](https://github.com/langchain-\nai/langchain/blob/master/cookbook/oracleai_demo.ipynb) which also shows how to\nset up a user in Oracle. Additionally, understanding user privileges is\ncrucial for managing database security effectively. You can learn more about\nthis topic in the official [Oracle\nguide](https://docs.oracle.com/en/database/oracle/oracle-\ndatabase/19/admqs/administering-user-accounts-and-\nsecurity.html#GUID-36B21D72-1BBB-46C9-A0C9-F0D2A8591B8D) on administering user\naccounts and security.", "oxylabs": "> [Oxylabs](https://oxylabs.io/) is a market-leading web intelligence\n> collection platform, driven by the highest business, ethics, and compliance\n> standards, enabling companies worldwide to unlock data-driven insights.", "pandas": "This notebook shows how to use agents to interact with a `Pandas DataFrame`.\nIt is mostly optimized for question answering.\n\n**NOTE: this agent calls the`Python` agent under the hood, which executes LLM\ngenerated Python code - this can be bad if the LLM generated Python code is\nharmful. Use cautiously.**\n\n**NOTE: Since langchain migrated to v0.3 you should upgrade langchain_openai\nand langchain. This would avoid import errors.**\n\npip install --upgrade langchain_openai pip install --upgrade langchain\n\n    \n    \n    from langchain.agents.agent_types import AgentType  \n    from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent  \n    from langchain_openai import ChatOpenAI  \n    \n\n**API Reference:**[AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [create_pandas_dataframe_agent](https://python.langchain.com/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n    \n    \n    import pandas as pd  \n    from langchain_openai import OpenAI  \n      \n    df = pd.read_csv(  \n        \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\"  \n    )  \n    \n\n**API\nReference:**[OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)", "passio_nutrition_ai": "To best understand how NutritionAI can give your agents super food-nutrition\npowers, let's build an agent that can find that information via Passio\nNutritionAI.", "payman-tool": "PaymanAI provides functionality to send and receive payments (fiat and crypto)\non behalf of an AI Agent. To get started:\n\n  1. **Sign up** at app.paymanai.com to create an AI Agent and obtain your **API Key**.\n  2. **Set** environment variables (`PAYMAN_API_SECRET` for your API Key, `PAYMAN_ENVIRONMENT` for sandbox or production).\n\nThis notebook gives a quick overview of integrating PaymanAI into LangChain as\na tool. For complete reference, see the API documentation.", "permit": "Permit is an access control platform that provides fine-grained, real-time\npermission management using various models such as RBAC, ABAC, and ReBAC. It\nenables organizations to enforce dynamic policies across their applications,\nensuring that only authorized users can access specific resources.", "playwright": "> [Playwright](https://github.com/microsoft/playwright) is an open-source\n> automation tool developed by `Microsoft` that allows you to programmatically\n> control and automate web browsers. It is designed for end-to-end testing,\n> scraping, and automating tasks across various web browsers such as\n> `Chromium`, `Firefox`, and `WebKit`.\n\nThis toolkit is used to interact with the browser. While other tools (like the\n`Requests` tools) are fine for static sites, `PlayWright Browser` toolkits let\nyour agent navigate the web and interact with dynamically rendered sites.\n\nSome tools bundled within the `PlayWright Browser` toolkit include:\n\n  * `NavigateTool` (navigate_browser) - navigate to a URL\n  * `NavigateBackTool` (previous_page) - wait for an element to appear\n  * `ClickTool` (click_element) - click on an element (specified by selector)\n  * `ExtractTextTool` (extract_text) - use beautiful soup to extract text from the current web page\n  * `ExtractHyperlinksTool` (extract_hyperlinks) - use beautiful soup to extract hyperlinks from the current web page\n  * `GetElementsTool` (get_elements) - select elements by CSS selector\n  * `CurrentPageTool` (current_page) - get the current page URL\n\n    \n    \n    %pip install --upgrade --quiet  playwright > /dev/null  \n    %pip install --upgrade --quiet  lxml  \n      \n    # If this is your first time using playwright, you'll have to install a browser executable.  \n    # Running `playwright install` by default installs a chromium browser executable.  \n    # playwright install  \n    \n    \n    \n      \n    \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m  \n    \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m  \n    Note: you may need to restart the kernel to use updated packages.  \n      \n    \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m  \n    \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m  \n    Note: you may need to restart the kernel to use updated packages.  \n    \n    \n    \n    from langchain_community.agent_toolkits import PlayWrightBrowserToolkit  \n    \n\n**API\nReference:**[PlayWrightBrowserToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.playwright.toolkit.PlayWrightBrowserToolkit.html)\n\nAsync function to create context and launch browser:\n\n    \n    \n    from langchain_community.tools.playwright.utils import (  \n        create_async_playwright_browser,  # A synchronous browser is available, though it isn't compatible with jupyter.\\n\",\t  },  \n    )  \n    \n\n**API\nReference:**[create_async_playwright_browser](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.playwright.utils.create_async_playwright_browser.html)\n\n    \n    \n    # This import is required only for jupyter notebooks, since they have their own eventloop  \n    import nest_asyncio  \n      \n    nest_asyncio.apply()", "polygon": "This notebook shows how to use agents to interact with the [Polygon\nIO](https://polygon.io/) toolkit. The toolkit provides access to Polygon's\nStock Market Data API.", "powerbi": "This notebook showcases an agent interacting with a `Power BI Dataset`. The\nagent is answering more general questions about a dataset, as well as recover\nfrom errors.\n\nNote that, as this agent is in active development, all answers might not be\ncorrect. It runs against the [executequery\nendpoint](https://learn.microsoft.com/en-us/rest/api/power-\nbi/datasets/execute-queries), which does not allow deletes.", "prolog_tool": "LangChain tools that use Prolog rules to generate answers.", "pubmed": "> [PubMed\u00ae](https://pubmed.ncbi.nlm.nih.gov/) comprises more than 35 million\n> citations for biomedical literature from `MEDLINE`, life science journals,\n> and online books. Citations may include links to full text content from\n> PubMed Central and publisher web sites.\n\nThis notebook goes over how to use `PubMed` as a tool.\n\n    \n    \n    %pip install xmltodict  \n    \n    \n    \n    from langchain_community.tools.pubmed.tool import PubmedQueryRun  \n    \n\n**API\nReference:**[PubmedQueryRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.pubmed.tool.PubmedQueryRun.html)\n\n    \n    \n    tool = PubmedQueryRun()  \n    \n    \n    \n    tool.invoke(\"What causes lung cancer?\")  \n    \n    \n    \n    'Published: 2024-02-10\\nTitle: circEPB41L2 blocks the progression and metastasis in non-small cell lung cancer by promoting TRIP12-triggered PTBP1 ubiquitylation.\\nCopyright Information: \u00a9 2024. The Author(s).\\nSummary::\\nThe metastasis of non-small cell lung cancer (NSCLC) is the leading death cause of NSCLC patients, which requires new biomarkers for precise diagnosis and treatment. Circular RNAs (circRNAs), the novel noncoding RNA, participate in the progression of various cancers as microRNA or protein sponges. We revealed the mechanism by which circEPB41L2 (hsa_circ_0077837) blocks the aerobic glycolysis, progression and metastasis of NSCLC through modulating protein metabolism of PTBP1 by the E3 ubiquitin ligase TRIP12. With ribosomal RNA-depleted RNA seq, 57 upregulated and 327 downregulated circRNAs were identified in LUAD tissues. circEPB41L2 was selected due to its dramatically reduced levels in NSCLC tissues and NSCLC cells. Interestingly, circEPB41L2 blocked glucose uptake, lactate production, NSCLC cell proliferation, migration and invasion in vitro and in vivo. Mechanistically, acting as a scaffold, circEPB41L2 bound to the RRM1 domain of the PTBP1 and the E3 ubiquitin ligase TRIP12 to promote TRIP12-mediated PTBP1 polyubiquitylation and degradation, which could be reversed by the HECT domain mutation of TRIP12 and circEPB41L2 depletion. As a result, circEPB41L2-induced PTBP1 inhibition led to PTBP1-induced PKM2 and Vimentin activation but PKM1 and E-cadherin inactivation. These findings highlight the circEPB41L2-dependent mechanism that modulates the \"Warburg Effect\" and EMT to inhibit NSCLC development and metastasis, offering an inhibitory target for NSCLC treatment.\\n\\nPublished: 2024-01-17\\nTitle: The safety of seasonal influenza vaccination among adults prescribed immune checkpoint inhibitors: A self-controlled case series study using administrative data.\\nCopyright Information: Copyright \u00a9 2024 The Author(s). Published by Elsevier Ltd.. All rights reserv'", "python": "Sometimes, for complex calculations, rather than have an LLM generate the\nanswer directly, it can be better to have the LLM generate code to calculate\nthe answer, and then run that code to get the answer. In order to easily do\nthat, we provide a simple Python REPL to execute commands in.\n\nThis interface will only return things that are printed - therefore, if you\nwant to use it to calculate an answer, make sure to have it print out the\nanswer.\n\ncaution\n\nPython REPL can execute arbitrary code on the host machine (e.g., delete\nfiles, make network requests). Use with caution.\n\nFor more information general security guidelines, please see\n<https://python.langchain.com/docs/security/>.\n\n    \n    \n    from langchain_core.tools import Tool  \n    from langchain_experimental.utilities import PythonREPL  \n    \n\n**API Reference:**[Tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.simple.Tool.html) | [PythonREPL](https://python.langchain.com/api_reference/experimental/utilities/langchain_experimental.utilities.python.PythonREPL.html)\n    \n    \n    python_repl = PythonREPL()  \n    \n    \n    \n    python_repl.run(\"print(1+1)\")  \n    \n    \n    \n    Python REPL can execute arbitrary code. Use with caution.  \n    \n    \n    \n    '2\\n'  \n    \n    \n    \n    # You can create the tool to pass to an agent  \n    repl_tool = Tool(  \n        name=\"python_repl\",  \n        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",  \n        func=python_repl.run,  \n    )", "reddit_search": "In this notebook, we learn how the Reddit search tool works.  \nFirst make sure that you have installed praw with the command below:\n\n    \n    \n    %pip install --upgrade --quiet  praw  \n    \n\nThen you need to set you need to set up the proper API keys and environment\nvariables. You would need to create a Reddit user account and get credentials.\nSo, create a Reddit user account by going to <https://www.reddit.com> and\nsigning up.  \nThen get your credentials by going to <https://www.reddit.com/prefs/apps> and\ncreating an app.  \nYou should have your client_id and secret from creating the app. Now, you can\npaste those strings in client_id and client_secret variable.  \nNote: You can put any string for user_agent\n\n    \n    \n    client_id = \"\"  \n    client_secret = \"\"  \n    user_agent = \"\"  \n    \n    \n    \n    from langchain_community.tools.reddit_search.tool import RedditSearchRun  \n    from langchain_community.utilities.reddit_search import RedditSearchAPIWrapper  \n      \n    search = RedditSearchRun(  \n        api_wrapper=RedditSearchAPIWrapper(  \n            reddit_client_id=client_id,  \n            reddit_client_secret=client_secret,  \n            reddit_user_agent=user_agent,  \n        )  \n    )  \n    \n\n**API Reference:**[RedditSearchRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.reddit_search.tool.RedditSearchRun.html) | [RedditSearchAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.reddit_search.RedditSearchAPIWrapper.html)\n\nYou can then set your queries for example, what subreddit you want to query,\nhow many posts you want to be returned, how you would like the result to be\nsorted etc.\n\n    \n    \n    from langchain_community.tools.reddit_search.tool import RedditSearchSchema  \n      \n    search_params = RedditSearchSchema(  \n        query=\"beginner\", sort=\"new\", time_filter=\"week\", subreddit=\"python\", limit=\"2\"  \n    )  \n    \n\n**API\nReference:**[RedditSearchSchema](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.reddit_search.tool.RedditSearchSchema.html)\n\nFinally run the search and get your results\n\n    \n    \n    result = search.run(tool_input=search_params.dict())  \n    \n    \n    \n    print(result)  \n    \n\nHere is an example of printing the result.  \nNote: You may get different output depending on the newest post in the\nsubreddit but the formatting should be similar.\n\n> Searching r/python found 2 posts: Post Title: 'Setup Github Copilot in\n> Visual Studio Code' User: Feisty-Recording-715 Subreddit: r/Python: Text\n> body: \ud83d\udee0\ufe0f This tutorial is perfect for beginners looking to strengthen their\n> understanding of version control or for experienced developers seeking a\n> quick reference for GitHub setup in Visual Studio Code.\n>\n> \ud83c\udf93 By the end of this video, you'll be equipped with the skills to\n> confidently manage your codebase, collaborate with others, and contribute to\n> open-source projects on GitHub.\n>\n> Video link: <https://youtu.be/IdT1BhrSfdo?si=mV7xVpiyuhlD8Zrw>\n>\n> Your feedback is welcome Post URL:\n> <https://www.reddit.com/r/Python/comments/1823wr7/setup_github_copilot_in_visual_studio_code/>\n> Post Category: N/A. Score: 0\n>\n> Post Title: 'A Chinese Checkers game made with pygame and PySide6, with\n> custom bots support' User: HenryChess Subreddit: r/Python: Text body: GitHub\n> link: <https://github.com/henrychess/pygame-chinese-checkers>\n>\n> I'm not sure if this counts as beginner or intermediate. I think I'm still\n> in the beginner zone, so I flair it as beginner.\n>\n> This is a Chinese Checkers (aka Sternhalma) game for 2 to 3 players. The\n> bots I wrote are easy to beat, as they're mainly for debugging the game\n> logic part of the code. However, you can write up your own custom bots.\n> There is a guide at the github page. Post URL:\n> <https://www.reddit.com/r/Python/comments/181xq0u/a_chinese_checkers_game_made_with_pygame_and/>\n> Post Category: N/A. Score: 1", "requests": "We can use the Requests [toolkit](/docs/concepts/tools/#toolkits) to construct\nagents that generate HTTP requests.\n\nFor detailed documentation of all API toolkit features and configurations head\nto the API reference for\n[RequestsToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.openapi.toolkit.RequestsToolkit.html).", "riza": "> The Riza Code Interpreter is a WASM-based isolated environment for running\n> Python or JavaScript generated by AI agents.\n\nIn this notebook we'll create an example of an agent that uses Python to solve\na problem that an LLM can't solve on its own: counting the number of 'r's in\nthe word \"strawberry.\"\n\nBefore you get started grab an API key from the [Riza\ndashboard](https://dashboard.riza.io). For more guides and a full API\nreference head over to the [Riza Code Interpreter API\ndocumentation](https://docs.riza.io).\n\nMake sure you have the necessary dependencies installed.\n\n    \n    \n    %pip install --upgrade --quiet langchain-community rizaio  \n    \n\nSet up your API keys as an environment variable.\n\n    \n    \n    %env ANTHROPIC_API_KEY=<your_anthropic_api_key_here>  \n    %env RIZA_API_KEY=<your_riza_api_key_here>  \n    \n    \n    \n    from langchain_community.tools.riza.command import ExecPython  \n    \n\n**API\nReference:**[ExecPython](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.riza.command.ExecPython.html)\n\n    \n    \n    from langchain.agents import AgentExecutor, create_tool_calling_agent  \n    from langchain_anthropic import ChatAnthropic  \n    from langchain_core.prompts import ChatPromptTemplate  \n    \n\n**API Reference:**[AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html) | [create_tool_calling_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html) | [ChatAnthropic](https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n\nInitialize the `ExecPython` tool.\n\n    \n    \n    tools = [ExecPython()]  \n    \n\nInitialize an agent using Anthropic's Claude Haiku model.\n\n    \n    \n    llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)  \n      \n    prompt_template = ChatPromptTemplate.from_messages(  \n        [  \n            (  \n                \"system\",  \n                \"You are a helpful assistant. Make sure to use a tool if you need to solve a problem.\",  \n            ),  \n            (\"human\", \"{input}\"),  \n            (\"placeholder\", \"{agent_scratchpad}\"),  \n        ]  \n    )  \n      \n    agent = create_tool_calling_agent(llm, tools, prompt_template)  \n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  \n    \n    \n    \n    # Ask a tough question  \n    result = agent_executor.invoke({\"input\": \"how many rs are in strawberry?\"})  \n    print(result[\"output\"][0][\"text\"])  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m  \n    Invoking: `riza_exec_python` with `{'code': 'word = \"strawberry\"\\nprint(word.count(\"r\"))'}`  \n    responded: [{'id': 'toolu_01JwPLAAqqCNCjVuEnK8Fgut', 'input': {}, 'name': 'riza_exec_python', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"code\": \"word = \\\\\"strawberry\\\\\"\\\\nprint(word.count(\\\\\"r\\\\\"))\"}'}]  \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3m3  \n    \u001b[0m\u001b[32;1m\u001b[1;3m[{'text': '\\n\\nThe word \"strawberry\" contains 3 \"r\" characters.', 'type': 'text', 'index': 0}]\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n      \n      \n    The word \"strawberry\" contains 3 \"r\" characters.", "robocorp": "This notebook covers how to get started with [Robocorp Action\nServer](https://github.com/robocorp/robocorp) action toolkit and LangChain.\n\nRobocorp is the easiest way to extend the capabilities of AI agents,\nassistants and copilots with custom actions.", "salesforce": "Tools for interacting with Salesforce.", "sceneXplain": "[SceneXplain](https://scenex.jina.ai/) is an ImageCaptioning service\naccessible through the SceneXplain Tool.\n\nTo use this tool, you'll need to make an account and fetch your API Token\n[from the website](https://scenex.jina.ai/api). Then you can instantiate the\ntool.\n\n    \n    \n    import os  \n      \n    os.environ[\"SCENEX_API_KEY\"] = \"<YOUR_API_KEY>\"  \n    \n    \n    \n    from langchain.agents import load_tools  \n      \n    tools = load_tools([\"sceneXplain\"])  \n    \n\n**API\nReference:**[load_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html)\n\nOr directly instantiate the tool.\n\n    \n    \n    from langchain_community.tools import SceneXplainTool  \n      \n    tool = SceneXplainTool()  \n    \n\n**API\nReference:**[SceneXplainTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.scenexplain.tool.SceneXplainTool.html)", "scrapegraph": "This notebook provides a quick overview for getting started with ScrapeGraph\n[tools](/docs/integrations/tools/). For detailed documentation of all\nScrapeGraph features and configurations head to the [API\nreference](https://python.langchain.com/docs/integrations/tools/scrapegraph).\n\nFor more information about ScrapeGraph AI:\n\n  * [ScrapeGraph AI Website](https://scrapegraphai.com)\n  * [Open Source Project](https://github.com/ScrapeGraphAI/Scrapegraph-ai)", "searchapi": "This notebook shows examples of how to use SearchApi to search the web. Go to\n<https://www.searchapi.io/> to sign up for a free account and get API key.\n\n    \n    \n    import os  \n      \n    os.environ[\"SEARCHAPI_API_KEY\"] = \"\"  \n    \n    \n    \n    from langchain_community.utilities import SearchApiAPIWrapper  \n    \n\n**API\nReference:**[SearchApiAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.searchapi.SearchApiAPIWrapper.html)\n\n    \n    \n    search = SearchApiAPIWrapper()  \n    \n    \n    \n    search.run(\"Obama's first name?\")  \n    \n    \n    \n    'Barack Hussein Obama II'", "searx_search": "This notebook goes over how to use a self hosted `SearxNG` search API to\nsearch the web.\n\nYou can [check this link](https://docs.searxng.org/dev/search_api.html) for\nmore informations about `Searx API` parameters.\n\n    \n    \n    import pprint  \n      \n    from langchain_community.utilities import SearxSearchWrapper  \n    \n\n**API\nReference:**[SearxSearchWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.searx_search.SearxSearchWrapper.html)\n\n    \n    \n    search = SearxSearchWrapper(searx_host=\"http://127.0.0.1:8888\")  \n    \n\nFor some engines, if a direct `answer` is available the warpper will print the\nanswer instead of the full list of search results. You can use the `results`\nmethod of the wrapper if you want to obtain all the results.\n\n    \n    \n    search.run(\"What is the capital of France\")  \n    \n    \n    \n    'Paris is the capital of France, the largest country of Europe with 550 000 km2 (65 millions inhabitants). Paris has 2.234 million inhabitants end 2011. She is the core of Ile de France region (12 million people).'", "semanticscholar": "This notebook demos how to use the semantic scholar tool with an agent.\n\n    \n    \n    # start by installing semanticscholar api  \n    %pip install --upgrade --quiet  semanticscholar  \n    \n    \n    \n    from langchain import hub  \n    from langchain.agents import AgentExecutor, create_openai_functions_agent  \n    from langchain_openai import ChatOpenAI  \n    \n\n**API Reference:**[hub](https://python.langchain.com/api_reference/langchain/hub/langchain.hub.hub.html) | [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html) | [create_openai_functions_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.openai_functions_agent.base.create_openai_functions_agent.html) | [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n    \n    \n    instructions = \"\"\"You are an expert researcher.\"\"\"  \n    base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")  \n    prompt = base_prompt.partial(instructions=instructions)  \n    \n    \n    \n    llm = ChatOpenAI(temperature=0)  \n    \n    \n    \n    from langchain_community.tools.semanticscholar.tool import SemanticScholarQueryRun  \n      \n    tools = [SemanticScholarQueryRun()]  \n    \n\n**API\nReference:**[SemanticScholarQueryRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.semanticscholar.tool.SemanticScholarQueryRun.html)\n\n    \n    \n    agent = create_openai_functions_agent(llm, tools, prompt)  \n    \n    \n    \n    agent_executor = AgentExecutor(  \n        agent=agent,  \n        tools=tools,  \n        verbose=True,  \n    )  \n    \n    \n    \n    agent_executor.invoke(  \n        {  \n            \"input\": \"What are some biases in the large language models? How have people tried to mitigate them? \"  \n            \"show me a list of papers and techniques. Based on your findings write new research questions \"  \n            \"to work on. Break down the task into subtasks for search. Use the search tool\"  \n        }  \n    )  \n    \n    \n    \n      \n      \n    \u001b[1m> Entering new AgentExecutor chain...\u001b[0m  \n    \u001b[32;1m\u001b[1;3m  \n    Invoking: `semanticscholar` with `{'query': 'biases in large language models'}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3mPublished year: 2023  \n    Title: Biases in Large Language Models: Origins, Inventory, and Discussion  \n    Authors: Roberto Navigli, Simone Conia, Bj\u00f6rn Ross  \n    Astract: In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.  \n      \n      \n    Published year: 2023  \n    Title: Surfacing Biases in Large Language Models using Contrastive Input Decoding  \n    Authors: G. Yona, Or Honovich, Itay Laish, Roee Aharoni  \n    Astract: Ensuring that large language models (LMs) are fair, robust and useful requires an understanding of how different modifications to their inputs impact the model's behaviour. In the context of open-text generation tasks, however, such an evaluation is not trivial. For example, when introducing a model with an input text and a perturbed,\"contrastive\"version of it, meaningful differences in the next-token predictions may not be revealed with standard decoding strategies. With this motivation in mind, we propose Contrastive Input Decoding (CID): a decoding algorithm to generate text given two inputs, where the generated text is likely given one input but unlikely given the other. In this way, the contrastive generations can highlight potentially subtle differences in how the LM output differs for the two inputs in a simple and interpretable manner. We use CID to highlight context-specific biases that are hard to detect with standard decoding strategies and quantify the effect of different input perturbations.  \n      \n      \n    Published year: 2023  \n    Title: Benchmarking Cognitive Biases in Large Language Models as Evaluators  \n    Authors: Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, Dongyeop Kang  \n    Astract: Large Language Models (LLMs) have recently been shown to be effective as automatic evaluators with simple prompting and in-context learning. In this work, we assemble 15 LLMs of four different size ranges and evaluate their output responses by preference ranking from the other LLMs as evaluators, such as System Star is better than System Square. We then evaluate the quality of ranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators (CoBBLEr), a benchmark to measure six different cognitive biases in LLM evaluation outputs, such as the Egocentric bias where a model prefers to rank its own outputs highly in evaluation. We find that LLMs are biased text quality evaluators, exhibiting strong indications on our bias benchmark (average of 40% of comparisons across all models) within each of their evaluations that question their robustness as evaluators. Furthermore, we examine the correlation between human and machine preferences and calculate the average Rank-Biased Overlap (RBO) score to be 49.6%, indicating that machine preferences are misaligned with humans. According to our findings, LLMs may still be unable to be utilized for automatic annotation aligned with human preferences. Our project page is at: https://minnesotanlp.github.io/cobbler.  \n      \n      \n    Published year: 2023  \n    Title: Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models  \n    Authors: Emilio Ferrara  \n    Astract: As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications\u001b[0m\u001b[32;1m\u001b[1;3m  \n    Invoking: `semanticscholar` with `{'query': 'mitigating biases in large language models'}`  \n      \n      \n    \u001b[0m\u001b[36;1m\u001b[1;3mPublished year: 2023  \n    Title: Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models  \n    Authors: Emilio Ferrara  \n    Astract: As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.  \n      \n      \n    Published year: 2021  \n    Title: Towards Understanding and Mitigating Social Biases in Language Models  \n    Authors: P. Liang, Chiyu Wu, Louis-Philippe Morency, R. Salakhutdinov  \n    Astract: As machine learning methods are deployed in real-world settings such as healthcare, legal systems, and social science, it is crucial to recognize how they shape social biases and stereotypes in these sensitive decision-making processes. Among such real-world deployments are large-scale pretrained language models (LMs) that can be potentially dangerous in manifesting undesirable representational biases - harmful biases resulting from stereotyping that propagate negative generalizations involving gender, race, religion, and other social constructs. As a step towards improving the fairness of LMs, we carefully define several sources of representational biases before proposing new benchmarks and metrics to measure them. With these tools, we propose steps towards mitigating social biases during text generation. Our empirical results and human evaluation demonstrate effectiveness in mitigating bias while retaining crucial contextual information for high-fidelity text generation, thereby pushing forward the performance-fairness Pareto frontier.  \n      \n      \n    Published year: 2023  \n    Title: In-Contextual Bias Suppression for Large Language Models  \n    Authors: Daisuke Oba, Masahiro Kaneko, D. Bollegala  \n    Astract: Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender bias. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of the LLMs, which are computationally costly. Moreover, one might not even have access to the internal parameters for performing debiasing such as in the case of commercially available LLMs such as GPT-4. To address this challenge we propose bias suppression, a novel alternative to debiasing that does not require access to model parameters. We show that text-based preambles, generated from manually designed templates covering counterfactual statements, can accurately suppress gender biases in LLMs. Moreover, we find that descriptive sentences for occupations can further suppress gender biases. Interestingly, we find that bias suppression has a minimal adverse effect on downstream task performance, while effectively mitigating the gender biases.  \n      \n      \n    Published year: 2023  \n    ``````output  \n    Title: The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large\u001b[0m\u001b[32;1m\u001b[1;3mBased on my findings, here are some papers and techniques related to mitigating biases in large language models:  \n      \n    1. \"Biases in Large Language Models: Origins, Inventory, and Discussion\" by Roberto Navigli, Simone Conia, Bj\u00f6rn Ross: This paper discusses the issue of bias in large language models, including data selection bias and various types of social bias. It explores directions for measuring, reducing, and tackling bias in language models.  \n      \n    2. \"Surfacing Biases in Large Language Models using Contrastive Input Decoding\" by G. Yona, Or Honovich, Itay Laish, Roee Aharoni: This paper proposes a decoding algorithm called Contrastive Input Decoding (CID) to highlight context-specific biases in language models. It aims to reveal meaningful differences in model behavior when given different inputs.  \n      \n    3. \"Benchmarking Cognitive Biases in Large Language Models as Evaluators\" by Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, Dongyeop Kang: This work evaluates the biases in large language models used as automatic evaluators. It introduces the Cognitive Bias Benchmark for LLMs as Evaluators (CoBBLEr) to measure different cognitive biases in model evaluation outputs.  \n      \n    4. \"Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models\" by Emilio Ferrara: This paper explores the challenges and risks associated with biases in large-scale language models. It discusses the origins of biases and the ethical implications of biased model outputs. It also provides an overview of current approaches for identifying, quantifying, and mitigating biases in language models.  \n      \n    5. \"Towards Understanding and Mitigating Social Biases in Language Models\" by P. Liang, Chiyu Wu, Louis-Philippe Morency, R. Salakhutdinov: This work focuses on mitigating social biases in language models. It proposes new benchmarks and metrics to measure representational biases and suggests steps towards mitigating biases during text generation.  \n      \n    6. \"In-Contextual Bias Suppression for Large Language Models\" by Daisuke Oba, Masahiro Kaneko, D. Bollegala: This paper presents a novel approach called bias suppression to mitigate gender biases in language models. It uses text-based preambles and descriptive sentences to suppress biases without requiring access to model parameters.  \n      \n    Based on these papers, here are some research questions to work on:  \n      \n    1. How can we further improve the effectiveness of bias suppression techniques in large language models?  \n    2. What are the long-term effects of biases in language models on downstream applications and user experiences?  \n    3. How can we develop more comprehensive benchmarks and metrics to measure and evaluate biases in language models?  \n    4. What are the ethical considerations and trade-offs involved in mitigating biases in language models?  \n    5. How can we ensure transparency and accountability in the deployment of language models to minimize biases?  \n    6. What are the potential biases introduced by fine-tuning language models on specific domains or datasets, and how can we address them?  \n      \n    To break down the task into subtasks for further search, you can focus on the following topics:  \n      \n    1. Techniques for measuring and quantifying biases in large language models.  \n    2. Approaches for mitigating biases during text generation in language models.  \n    3. Evaluation methods and benchmarks for assessing biases in language models.  \n    4. Ethical considerations and implications of biases in language models.  \n    5. Impact of biases in language models on downstream applications and user experiences.  \n    6. Bias suppression techniques that do not require access to model parameters.  \n      \n    Using the search tool, you can explore these subtopics and find more specific papers and techniques related to each subtask.\u001b[0m  \n      \n    \u001b[1m> Finished chain.\u001b[0m  \n    \n    \n    \n    {'input': 'What are some biases in the large language models? How have people tried to mitigate them? show me a list of papers and techniques. Based on your findings write new research questions to work on. Break down the task into subtasks for search. Use the search tool',  \n     'output': 'Based on my findings, here are some papers and techniques related to mitigating biases in large language models:\\n\\n1. \"Biases in Large Language Models: Origins, Inventory, and Discussion\" by Roberto Navigli, Simone Conia, Bj\u00f6rn Ross: This paper discusses the issue of bias in large language models, including data selection bias and various types of social bias. It explores directions for measuring, reducing, and tackling bias in language models.\\n\\n2. \"Surfacing Biases in Large Language Models using Contrastive Input Decoding\" by G. Yona, Or Honovich, Itay Laish, Roee Aharoni: This paper proposes a decoding algorithm called Contrastive Input Decoding (CID) to highlight context-specific biases in language models. It aims to reveal meaningful differences in model behavior when given different inputs.\\n\\n3. \"Benchmarking Cognitive Biases in Large Language Models as Evaluators\" by Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, Dongyeop Kang: This work evaluates the biases in large language models used as automatic evaluators. It introduces the Cognitive Bias Benchmark for LLMs as Evaluators (CoBBLEr) to measure different cognitive biases in model evaluation outputs.\\n\\n4. \"Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models\" by Emilio Ferrara: This paper explores the challenges and risks associated with biases in large-scale language models. It discusses the origins of biases and the ethical implications of biased model outputs. It also provides an overview of current approaches for identifying, quantifying, and mitigating biases in language models.\\n\\n5. \"Towards Understanding and Mitigating Social Biases in Language Models\" by P. Liang, Chiyu Wu, Louis-Philippe Morency, R. Salakhutdinov: This work focuses on mitigating social biases in language models. It proposes new benchmarks and metrics to measure representational biases and suggests steps towards mitigating biases during text generation.\\n\\n6. \"In-Contextual Bias Suppression for Large Language Models\" by Daisuke Oba, Masahiro Kaneko, D. Bollegala: This paper presents a novel approach called bias suppression to mitigate gender biases in language models. It uses text-based preambles and descriptive sentences to suppress biases without requiring access to model parameters.\\n\\nBased on these papers, here are some research questions to work on:\\n\\n1. How can we further improve the effectiveness of bias suppression techniques in large language models?\\n2. What are the long-term effects of biases in language models on downstream applications and user experiences?\\n3. How can we develop more comprehensive benchmarks and metrics to measure and evaluate biases in language models?\\n4. What are the ethical considerations and trade-offs involved in mitigating biases in language models?\\n5. How can we ensure transparency and accountability in the deployment of language models to minimize biases?\\n6. What are the potential biases introduced by fine-tuning language models on specific domains or datasets, and how can we address them?\\n\\nTo break down the task into subtasks for further search, you can focus on the following topics:\\n\\n1. Techniques for measuring and quantifying biases in large language models.\\n2. Approaches for mitigating biases during text generation in language models.\\n3. Evaluation methods and benchmarks for assessing biases in language models.\\n4. Ethical considerations and implications of biases in language models.\\n5. Impact of biases in language models on downstream applications and user experiences.\\n6. Bias suppression techniques that do not require access to model parameters.\\n\\nUsing the search tool, you can explore these subtopics and find more specific papers and techniques related to each subtask.'}", "serpapi": "This notebook goes over how to use the SerpAPI component to search the web.\n\n    \n    \n    from langchain_community.utilities import SerpAPIWrapper  \n    \n\n**API\nReference:**[SerpAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.serpapi.SerpAPIWrapper.html)\n\n    \n    \n    search = SerpAPIWrapper()  \n    \n    \n    \n    search.run(\"Obama's first name?\")  \n    \n    \n    \n    'Barack Hussein Obama II'", "slack": "This will help you getting started with the Slack\n[toolkit](/docs/concepts/tools/#toolkits). For detailed documentation of all\nSlackToolkit features and configurations head to the [API\nreference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.slack.toolkit.SlackToolkit.html).", "spark_sql": "This notebook shows how to use agents to interact with `Spark SQL`. Similar to\n[SQL Database Agent](/docs/integrations/tools/sql_database/), it is designed\nto address general inquiries about `Spark SQL` and facilitate error recovery.\n\n**NOTE: Note that, as this agent is in active development, all answers might\nnot be correct. Additionally, it is not guaranteed that the agent won't\nperform DML statements on your Spark cluster given certain questions. Be\ncareful running it on sensitive data!**", "sql_database": "This will help you getting started with the SQL Database\n[toolkit](/docs/concepts/tools/#toolkits). For detailed documentation of all\n`SQLDatabaseToolkit` features and configurations head to the [API\nreference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html).\n\nTools within the `SQLDatabaseToolkit` are designed to interact with a `SQL`\ndatabase.\n\nA common application is to enable agents to answer questions using data in a\nrelational database, potentially in an iterative fashion (e.g., recovering\nfrom errors).\n\n**\u26a0\ufe0f Security note \u26a0\ufe0f**\n\nBuilding Q&A systems of SQL databases requires executing model-generated SQL\nqueries. There are inherent risks in doing this. Make sure that your database\nconnection permissions are always scoped as narrowly as possible for your\nchain/agent's needs. This will mitigate though not eliminate the risks of\nbuilding a model-driven system. For more on general security best practices,\n[see here](/docs/security/).", "stackexchange": "> [Stack Exchange](https://stackexchange.com/) is a network of question-and-\n> answer (Q&A) websites on topics in diverse fields, each site covering a\n> specific topic, where questions, answers, and users are subject to a\n> reputation award process. The reputation system allows the sites to be self-\n> moderating.\n\nThe `StackExchange` component integrates the StackExchange API into LangChain\nallowing access to the [StackOverflow](https://stackoverflow.com/) site of the\nStack Excchange network. Stack Overflow focuses on computer programming.\n\nThis notebook goes over how to use the `StackExchange` component.\n\nWe first have to install the python package stackapi which implements the\nStack Exchange API.\n\n    \n    \n    pip install --upgrade stackapi  \n    \n    \n    \n    from langchain_community.utilities import StackExchangeAPIWrapper  \n      \n    stackexchange = StackExchangeAPIWrapper()  \n      \n    stackexchange.run(\"zsh: command not found: python\")  \n    \n\n**API\nReference:**[StackExchangeAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.stackexchange.StackExchangeAPIWrapper.html)", "steam": "> [Steam (Wikipedia)](https://en.wikipedia.org/wiki/Steam_\\(service\\)) is a\n> video game digital distribution service and storefront developed by `Valve\n> Corporation`. It provides game updates automatically for Valve's games, and\n> expanded to distributing third-party titles. `Steam` offers various\n> features, like game server matchmaking with Valve Anti-Cheat measures,\n> social networking, and game streaming services.\n\n> [Steam](https://store.steampowered.com/about/) is the ultimate destination\n> for playing, discussing, and creating games.\n\nSteam toolkit has two tools:\n\n  * `Game Details`\n  * `Recommended Games`\n\nThis notebook provides a walkthrough of using Steam API with LangChain to\nretrieve Steam game recommendations based on your current Steam Game Inventory\nor to gather information regarding some Steam Games which you provide.", "stripe": "This notebook provides a quick overview for getting started with Stripe's\nagent toolkit.\n\nYou can read more about `StripeAgentToolkit` in [Stripe's launch\nblog](https://stripe.dev/blog/adding-payments-to-your-agentic-workflows) or on\nthe project's [PyPi page](https://pypi.org/project/stripe-agent-toolkit/).", "tableau": "This notebook provides a quick overview for getting started with\n[Tableau](https://help.tableau.com/current/api/vizql-data-service/en-\nus/index.html).", "taiga": "This notebook provides a quick overview for getting started with Taiga tooling\nin [langchain_taiga](https://github.com/Shikenso-Analytics/langchain-\ntaiga/blob/main/docs/tools.ipynb). For more details on each tool and\nconfiguration, see the docstrings in your repository or relevant doc pages.", "tavily_extract": "[Tavily](https://tavily.com) is a search engine built specifically for AI\nagents (LLMs), delivering real-time, accurate, and factual results at speed.\nTavily offers an [Extract](https://docs.tavily.com/api-\nreference/endpoint/extract) endpoint that can be used to extract content from\na URLs.", "tavily_search": "[Tavily's Search API](https://tavily.com) is a search engine built\nspecifically for AI agents (LLMs), delivering real-time, accurate, and factual\nresults at speed.", "tilores": "This notebook covers how to get started with the\n[Tilores](/docs/integrations/providers/tilores/) tools. For a more complex\nexample you can checkout our [customer insights chatbot\nexample](https://github.com/tilotech/identity-rag-customer-insights-chatbot).", "twilio": "This notebook goes over how to use the [Twilio](https://www.twilio.com) API\nwrapper to send a message through SMS or [Twilio Messaging\nChannels](https://www.twilio.com/docs/messaging/channels).\n\nTwilio Messaging Channels facilitates integrations with 3rd party messaging\napps and lets you send messages through WhatsApp Business Platform (GA),\nFacebook Messenger (Public Beta) and Google Business Messages (Private Beta).", "upstage_groundedness_check": "This notebook covers how to get started with Upstage groundedness check\nmodels.", "valthera": "Enable AI agents to engage users when they're most likely to respond.", "valyu_context": "> [Valyu](https://www.valyu.network/) allows AI applications and agents to\n> search the internet and proprietary data sources for relevant LLM ready\n> information.\n\nThis notebook goes over how to use Valyu context tool in LangChain.\n\nFirst, get an Valyu API key and add it as an environment variable. Get $10\nfree credit by [signing up here](https://exchange.valyu.network/).", "wikidata": "> [Wikidata](https://wikidata.org/) is a free and open knowledge base that can\n> be read and edited by both humans and machines. Wikidata is one of the\n> world's largest open knowledge bases.\n\nFirst, you need to install `wikibase-rest-api-client` and `mediawikiapi`\npython packages.\n\n    \n    \n    %pip install --upgrade --quiet wikibase-rest-api-client mediawikiapi  \n    \n    \n    \n    from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun  \n      \n    wikidata = WikidataQueryRun(api_wrapper=WikidataAPIWrapper())  \n      \n    print(wikidata.run(\"Alan Turing\"))  \n    \n\n**API Reference:**[WikidataAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.wikidata.WikidataAPIWrapper.html) | [WikidataQueryRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.wikidata.tool.WikidataQueryRun.html)\n    \n    \n    Result Q7251:  \n    Label: Alan Turing  \n    Description: English computer scientist (1912\u20131954)  \n    Aliases: Alan M. Turing, Alan Mathieson Turing, Turing, Alan Mathison Turing  \n    instance of: human  \n    country of citizenship: United Kingdom  \n    occupation: computer scientist, mathematician, university teacher, cryptographer, logician, statistician, marathon runner, artificial intelligence researcher  \n    sex or gender: male  \n    date of birth: 1912-06-23  \n    date of death: 1954-06-07  \n    sport: athletics  \n    place of birth: Maida Vale, Warrington Lodge  \n    educated at: King's College, Princeton University, Sherborne School, Hazlehurst Community Primary School  \n    employer: Victoria University of Manchester, Government Communications Headquarters, University of Cambridge, National Physical Laboratory (United Kingdom)  \n    place of death: Wilmslow  \n    field of work: cryptanalysis, computer science, mathematics, logic, cryptography  \n    cause of death: cyanide poisoning  \n    notable work: On Computable Numbers, with an Application to the Entscheidungsproblem, Computing Machinery and Intelligence, Intelligent Machinery, halting problem, Turing machine, Turing test, Turing completeness, Church-Turing thesis, universal Turing machine, Symmetric Turing machine, non-deterministic Turing machine, Bombe, probabilistic Turing machine, Turing degree  \n    religion or worldview: atheism  \n    mother: Ethel Sara Stoney  \n    father: Julius Mathison Turing  \n    doctoral student: Robin Gandy, Beatrice Helen Worsley  \n    student: Robin Gandy  \n      \n    Result Q28846012:  \n    Label: Alan Turing  \n    Description: fictional analogon of Alan Turing (1912-1954)  \n    Aliases: Alan Mathison Turing  \n    instance of: fictional human  \n    sex or gender: male", "wikipedia": "> [Wikipedia](https://wikipedia.org/) is a multilingual free online\n> encyclopedia written and maintained by a community of volunteers, known as\n> Wikipedians, through open collaboration and using a wiki-based editing\n> system called MediaWiki. `Wikipedia` is the largest and most-read reference\n> work in history.\n\nFirst, you need to install `wikipedia` python package.\n\n    \n    \n    %pip install --upgrade --quiet  wikipedia  \n    \n    \n    \n    from langchain_community.tools import WikipediaQueryRun  \n    from langchain_community.utilities import WikipediaAPIWrapper  \n    \n\n**API Reference:**[WikipediaQueryRun](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.wikipedia.tool.WikipediaQueryRun.html) | [WikipediaAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.wikipedia.WikipediaAPIWrapper.html)\n    \n    \n    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())  \n    \n    \n    \n    wikipedia.run(\"HUNTER X HUNTER\")  \n    \n    \n    \n    'Page: Hunter \u00d7 Hunter\\nSummary: Hunter \u00d7 Hunter (stylized as HUNTER\u00d7HUNTER and pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s sh\u014dnen manga magazine Weekly Sh\u014dnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 37 tank\u014dbon volumes as of November 2022. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\\nHunter \u00d7 Hunter was adapted into a 62-episode anime television series produced by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter \u00d7 Hunter.\\nThe manga has been translated into English and released in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim\\'s Toonami programming block from April 2016 to June 2019.\\nHunter \u00d7 Hunter has been a huge critical and financial success and has become one of the best-selling manga series of all time, having over 84 million copies in circulation by July 2022.\\n\\nPage: Hunter \u00d7 Hunter (2011 TV series)\\nSummary: Hunter \u00d7 Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi\\'s manga series Hunter \u00d7 Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father\\'s footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\\nThis new Hunter \u00d7 Hunter anime was announced on July 24, 2011. It is a complete reboot starting from the beginning of the original manga, with no connection to the first anime television series from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi K\u014djina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim\\'s Toonami programming block on April 17, 2016, and ended on June 23, 2019.The anime series\\' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus\\' voc'", "wolfram_alpha": "This notebook goes over how to use the wolfram alpha component.\n\nFirst, you need to set up your Wolfram Alpha developer account and get your\nAPP ID:\n\n  1. Go to wolfram alpha and sign up for a developer account [here](https://developer.wolframalpha.com/)\n  2. Create an app and get your APP ID\n  3. pip install wolframalpha\n\nThen we will need to set some environment variables:\n\n  1. Save your APP ID into WOLFRAM_ALPHA_APPID env variable\n\n    \n    \n    pip install wolframalpha  \n    \n    \n    \n    import os  \n      \n    os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"\"  \n    \n    \n    \n    from langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper  \n    \n\n**API\nReference:**[WolframAlphaAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.wolfram_alpha.WolframAlphaAPIWrapper.html)\n\n    \n    \n    wolfram = WolframAlphaAPIWrapper()  \n    \n    \n    \n    wolfram.run(\"What is 2x+5 = -3x + 7?\")  \n    \n    \n    \n    'x = 2/5'", "writer": "This notebook provides a quick overview for getting started with Writer\n[tools](https://python.langchain.com/docs/concepts/tools/). For detailed\ndocumentation of all Writer features and configurations head to the [Writer\ndocs](https://dev.writer.com/home).", "yahoo_finance_news": "This notebook goes over how to use the `yahoo_finance_news` tool with an\nagent.", "you": "The [you.com API](https://api.you.com) is a suite of tools designed to help\ndevelopers ground the output of LLMs in the most recent, most accurate, most\nrelevant information that may not have been included in their training\ndataset.", "youtube": "> [YouTube Search](https://github.com/joetats/youtube_search) package searches\n> `YouTube` videos avoiding using their heavily rate-limited API.\n>\n> It uses the form on the `YouTube` homepage and scrapes the resulting page.\n\nThis notebook shows how to use a tool to search YouTube.\n\nAdapted from <https://github.com/venuv/langchain_yt_tools>\n\n    \n    \n    %pip install --upgrade --quiet  youtube_search  \n    \n    \n    \n    from langchain_community.tools import YouTubeSearchTool  \n    \n\n**API\nReference:**[YouTubeSearchTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.youtube.search.YouTubeSearchTool.html)\n\n    \n    \n    tool = YouTubeSearchTool()  \n    \n    \n    \n    tool.run(\"lex fridman\")  \n    \n    \n    \n    \"['/watch?v=VcVfceTsD0A&pp=ygUMbGV4IGZyaWVkbWFu', '/watch?v=gPfriiHBBek&pp=ygUMbGV4IGZyaWVkbWFu']\"  \n    \n\nYou can also specify the number of results that are returned\n\n    \n    \n    tool.run(\"lex friedman,5\")  \n    \n    \n    \n    \"['/watch?v=VcVfceTsD0A&pp=ygUMbGV4IGZyaWVkbWFu', '/watch?v=YVJ8gTnDC4Y&pp=ygUMbGV4IGZyaWVkbWFu', '/watch?v=Udh22kuLebg&pp=ygUMbGV4IGZyaWVkbWFu', '/watch?v=gPfriiHBBek&pp=ygUMbGV4IGZyaWVkbWFu', '/watch?v=L_Guz73e6fw&pp=ygUMbGV4IGZyaWVkbWFu']\"", "zapier": "**Deprecated** This API will be sunset on 2023-11-17:\n<https://nla.zapier.com/start/>\n\n> [Zapier Natural Language Actions](https://nla.zapier.com/start/) gives you\n> access to the 5k+ apps, 20k+ actions on Zapier's platform through a natural\n> language API interface.\n>\n> NLA supports apps like `Gmail`, `Salesforce`, `Trello`, `Slack`, `Asana`,\n> `HubSpot`, `Google Sheets`, `Microsoft Teams`, and thousands more apps:\n> <https://zapier.com/apps> `Zapier NLA` handles ALL the underlying API auth\n> and translation from natural language --> underlying API call --> return\n> simplified output for LLMs. The key idea is you, or your users, expose a set\n> of actions via an oauth-like setup window, which you can then query and\n> execute via a REST API.\n\nNLA offers both API Key and OAuth for signing NLA API requests.\n\n  1. Server-side (API Key): for quickly getting started, testing, and production scenarios where LangChain will only use actions exposed in the developer's Zapier account (and will use the developer's connected accounts on Zapier.com)\n\n  2. User-facing (Oauth): for production scenarios where you are deploying an end-user facing application and LangChain needs access to end-user's exposed actions and connected accounts on Zapier.com\n\nThis quick start focus mostly on the server-side use case for brevity. Jump to\nExample Using OAuth Access Token to see a short example how to set up Zapier\nfor user-facing situations. Review [full docs](https://nla.zapier.com/start/)\nfor full user-facing oauth developer support.\n\nThis example goes over how to use the Zapier integration with a\n`SimpleSequentialChain`, then an `Agent`. In code, below:\n\n    \n    \n    import os  \n      \n    # get from https://platform.openai.com/  \n    os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\", \"\")  \n      \n    # get from https://nla.zapier.com/docs/authentication/ after logging in):  \n    os.environ[\"ZAPIER_NLA_API_KEY\"] = os.environ.get(\"ZAPIER_NLA_API_KEY\", \"\")", "zenguard": "[](https://colab.research.google.com/github/langchain-\nai/langchain/blob/master/docs/docs/integrations/tools/zenguard.ipynb)\n\nThis tool lets you quickly set up [ZenGuard AI](https://www.zenguard.ai/) in\nyour Langchain-powered application. The ZenGuard AI provides ultrafast\nguardrails to protect your GenAI application from:\n\n  * Prompts Attacks\n  * Veering of the pre-defined topics\n  * PII, sensitive info, and keywords leakage.\n  * Toxicity\n  * Etc.\n\nPlease, also check out our [open-source Python\nClient](https://github.com/ZenGuard-AI/fast-llm-security-\nguardrails?tab=readme-ov-file) for more inspiration.\n\nHere is our main website - <https://www.zenguard.ai/>\n\nMore [Docs](https://docs.zenguard.ai/start/intro/)"}